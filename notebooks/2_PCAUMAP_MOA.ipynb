{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/umap/distances.py:1063: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/usr/local/lib/python3.8/dist-packages/umap/distances.py:1071: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/usr/local/lib/python3.8/dist-packages/umap/distances.py:1086: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/usr/local/lib/python3.8/dist-packages/umap/umap_.py:660: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "2024-03-01 15:35:21.708951: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/scratch2-shared/david/colopaint3D/notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import PLSCanonical, PLSRegression, CCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_validate, cross_val_score\n",
    "# from sklearn.manifold import TSNE\n",
    "import matplotlib  as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "from matplotlib.patches import Ellipse\n",
    "import matplotlib.transforms as transforms\n",
    "%matplotlib inline\n",
    "import os, shutil, glob\n",
    "from random import randint\n",
    "import seaborn as sns; sns.set_style(\"white\")\n",
    "import umap as umap\n",
    "\n",
    "# import plotnine as gg\n",
    "# from cytominer_eval import evaluate\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "figformat = 'png'\n",
    "dpi = 300\n",
    "statarg = 'single'\n",
    "OutputDir = f'./output/spher_colo52_v1/2_PCAUMAP'\n",
    "if not os.path.exists(OutputDir): \n",
    "    os.makedirs(OutputDir)\n",
    "FeatureDir = './output/spher_colo52_v1/1_FeaturesImages'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = ['PB000137', 'PB000138', 'PB000139', 'PB000140', 'PB000141', 'PB000142']\n",
    "statmets = ['MedianCell', 'MeanCell']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData(filename, statmet='SingleCell'):\n",
    "    read_data = pd.read_parquet(f'{FeatureDir}/{statmet}/{filename}.parquet')\n",
    "    cbar = pd.DataFrame()\n",
    "    read_data.reset_index(inplace=True, drop = True)\n",
    "    training_data = read_data.copy()\n",
    "    loc_data = training_data[['Nuclei_Location_Center_X','Nuclei_Location_Center_Y']]\n",
    "    training_data = training_data.loc[:,~training_data.columns.str.contains('Location', case=True)]\n",
    "    training_data = training_data.loc[:,~training_data.columns.str.contains('ImageNumber_', case=True)]\n",
    "    training_data = training_data.loc[:,~training_data.columns.str.contains('Parent', case=True)]\n",
    "    training_data = training_data.loc[:,~training_data.columns.str.contains('Children', case=True)]\n",
    "    training_data = training_data.loc[:,~training_data.columns.str.contains('_ObjectNumber', case=True)]\n",
    "    training_data = training_data.loc[:,~training_data.columns.str.contains('_Object_Number', case=True)]\n",
    "    training_data = training_data.loc[:,~training_data.columns.str.contains('_Y', case=True)]\n",
    "    training_data = training_data.loc[:,~training_data.columns.str.contains('_X', case=True)]\n",
    "    training_data = training_data.copy()\n",
    "\n",
    "    toNpy = training_data.loc[:,~training_data.columns.str.contains('Metadata_|onehot')]\n",
    "    toNpy.reset_index(inplace=True, drop=True)\n",
    "    toNpy = toNpy.copy()\n",
    "    dataNpy = toNpy.to_numpy()\n",
    "    colnames = toNpy.columns\n",
    "    \n",
    "    dataLabel = oneHot(training_data)\n",
    "\n",
    "    return dataNpy, dataLabel\n",
    "\n",
    "def oneHot(training_data):\n",
    "    ### New Onehot\n",
    "    target = pd.DataFrame()\n",
    "    onehot_val = list(range(len(training_data['Metadata_cmpd_cmpdname'].unique())))\n",
    "    onehot_dict = dict(zip(training_data['Metadata_cmpd_cmpdname'].unique(), onehot_val))\n",
    "    target['onehot'] = training_data['Metadata_cmpd_cmpdname'].apply(lambda x: onehot_dict.get(x, -1))\n",
    "    training_data['onehot'] = target['onehot']\n",
    "\n",
    "    dataLabel = pd.DataFrame()\n",
    "    dataLabel['Metadata_cmpd_cmpdname'] = training_data['Metadata_cmpd_cmpdname']\n",
    "    dataLabel['Metadata__cmpd_pathway'] = training_data['Metadata_cmpd_pathway']\n",
    "    dataLabel['onehot'] = training_data['onehot']\n",
    "\n",
    "    # dataUMAP = pd.DataFrame()\n",
    "    # dataUMAP['Metadata_Cmpd'] = training_data['Metadata_Cmpd']\n",
    "    # dataUMAP['onehot'] = training_data['onehot']\n",
    "    return dataLabel\n",
    "\n",
    "def makePCA(dataN, dataPCA, name='', statmet='SingleCell' , n_components=2):\n",
    "    pca_model = PCA(n_components=  2)\n",
    "    pca_model = pca_model.fit(dataN)\n",
    "    pcaOut = pca_model.transform(dataN)\n",
    "    dataPCA['pc1'] = pcaOut[:,0]\n",
    "    dataPCA['pc2'] = pcaOut[:,1]\n",
    "    dataPCA = dataPCA.copy()\n",
    "\n",
    "    # cmap = sns.color_palette(\"hls\", n_colors=11)\n",
    "    # cmap = sns.color_palette(\"Set3\", n_colors=12)\n",
    "    # cmap = cmap[:20]\n",
    "    # hue = dataPCA['Metadata_Moa']\n",
    "\n",
    "    cmap = sns.color_palette(\"husl\", n_colors=20)\n",
    "    hue = dataPCA['Metadata_Moa']\n",
    "    # hue = training_data['cluster']\n",
    "\n",
    "    fig = plt.figure(figsize=[14, 5])\n",
    "    ax = fig.add_subplot(121)\n",
    "    ax.set_xlabel('PC 1', fontsize = 10)\n",
    "    ax.set_ylabel('PC 2', fontsize = 10)\n",
    "    ax.spines['top'].set_color('w')\n",
    "    ax.spines['right'].set_color('w')\n",
    "    ax.spines['left'].set_color('grey')\n",
    "    ax.spines['bottom'].set_color('grey')\n",
    "    sns.scatterplot(x=\"pc1\", y=\"pc2\",\n",
    "                        palette=cmap, hue=hue,\n",
    "                        marker='.',\n",
    "                        data=dataPCA).set(title=f'PCA {name} All'\n",
    "                )\n",
    "\n",
    "\n",
    "    noInert = dataPCA[~(dataPCA['Metadata_Moa'] == 'dmso')]\n",
    "    noInert = noInert[~(noInert['Metadata_Moa'] == 'sorb')]\n",
    "    noInert = noInert[~(noInert['Metadata_Moa'] == 'etop')]\n",
    "    noInert = noInert[~(noInert['Metadata_Moa'] == 'stau')]\n",
    "    noInert = noInert[~(noInert['Metadata_Moa'] == 'fenb')]\n",
    "    noInert = noInert[~(noInert['Metadata_Moa'] == 'Others')]\n",
    "    ax.set_facecolor('w')\n",
    "    ax.get_legend().remove()\n",
    "    # ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "    ax = fig.add_subplot(122)\n",
    "    ax.set_xlabel('PC 1', fontsize = 10)\n",
    "    ax.set_ylabel('PC 2', fontsize = 10)\n",
    "    ax.spines['top'].set_color('w')\n",
    "    ax.spines['right'].set_color('w')\n",
    "    ax.spines['left'].set_color('grey')\n",
    "    ax.spines['bottom'].set_color('grey')\n",
    "    sns.scatterplot(x=\"pc1\", y=\"pc2\",\n",
    "                        palette=cmap, hue=hue,\n",
    "                        marker='.',\n",
    "                        data=noInert).set(title=f'PCA {name} no Inert'\n",
    "                )\n",
    "    ax.set_facecolor('w')\n",
    "    # ax.get_legend().remove()\n",
    "    ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "    if not os.path.exists(f'{OutputDir}/{statmet}/'): \n",
    "        os.makedirs(f'{OutputDir}/{statmet}/')\n",
    "    plt.savefig(f'{OutputDir}/{statmet}/{name}_pca.png')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    return dataPCA\n",
    "\n",
    "def makeUMAP(dataN, dataUMAP, name='', statmet='SingleCell' , nn = 100, is_supervised=True, n_components=2, min_dist=0.2, spread= 5, n_epochs=None, metric='cosine', use_pca=True):\n",
    "    umap_model = umap.UMAP(n_neighbors=nn\n",
    "                        , min_dist=min_dist\n",
    "                        , spread= spread\n",
    "                        , n_epochs=n_epochs\n",
    "                        , metric=metric\n",
    "                        )\n",
    "    if use_pca:\n",
    "        pca_model = PCA(n_components=700)\n",
    "        pca_model = pca_model.fit(dataN)\n",
    "        dataN = pca_model.transform(dataN)\n",
    "    if is_supervised:\n",
    "        umapOut = umap_model.fit_transform(dataN, y=dataUMAP['onehot'])\n",
    "        isSup = 'Supervised'\n",
    "    else:\n",
    "        umapOut = umap_model.fit_transform(dataN)\n",
    "        isSup = 'Unsupervised'\n",
    "    dataUMAP['umap1'] = umapOut[:,0]\n",
    "    dataUMAP['umap2'] = umapOut[:,1]\n",
    "    dataUMAP = dataUMAP.copy()\n",
    "\n",
    "    # cmap = sns.color_palette(\"hls\", n_colors=11)\n",
    "    # cmap = sns.color_palette(\"Set3\", n_colors=12)\n",
    "    # cmap = cmap[:20]\n",
    "    # hue = dataUMAP['Metadata_Moa']\n",
    "    cmap = sns.color_palette(\"husl\", n_colors=20)\n",
    "    hue = dataUMAP['Metadata_Moa']\n",
    "    # hue = training_data['cluster']\n",
    "\n",
    "    fig = plt.figure(figsize=[14, 5])\n",
    "    ax = fig.add_subplot(121)\n",
    "    ax.set_xlabel('UMAP 1', fontsize = 10)\n",
    "    ax.set_ylabel('UMAP 2', fontsize = 10)\n",
    "    ax.spines['top'].set_color('w')\n",
    "    ax.spines['right'].set_color('w')\n",
    "    ax.spines['left'].set_color('grey')\n",
    "    ax.spines['bottom'].set_color('grey')\n",
    "    sns.scatterplot(x=\"umap1\", y=\"umap2\",\n",
    "                        palette=cmap, hue=hue,\n",
    "                        marker='.',\n",
    "                        data=dataUMAP).set(title=f'UMAP {isSup} {name} all'\n",
    "                )\n",
    "\n",
    "\n",
    "    noInert = dataUMAP[~(dataUMAP['Metadata_Moa'] == 'dmso')]\n",
    "    noInert = noInert[~(noInert['Metadata_Moa'] == 'sorb')]\n",
    "    noInert = noInert[~(noInert['Metadata_Moa'] == 'etop')]\n",
    "    noInert = noInert[~(noInert['Metadata_Moa'] == 'stau')]\n",
    "    noInert = noInert[~(noInert['Metadata_Moa'] == 'fenb')]\n",
    "    noInert = noInert[~(noInert['Metadata_Moa'] == 'Others')]\n",
    "    ax.set_facecolor('w')\n",
    "    ax.get_legend().remove()\n",
    "\n",
    "    ax = fig.add_subplot(122)\n",
    "    ax.set_xlabel('UMAP 1', fontsize = 10)\n",
    "    ax.set_ylabel('UMAP 2', fontsize = 10)\n",
    "    ax.spines['top'].set_color('w')\n",
    "    ax.spines['right'].set_color('w')\n",
    "    ax.spines['left'].set_color('grey')\n",
    "    ax.spines['bottom'].set_color('grey')\n",
    "    sns.scatterplot(x=\"umap1\", y=\"umap2\",\n",
    "                        palette=cmap, hue=hue,\n",
    "                        marker='.',\n",
    "                        data=noInert).set(title=f'UMAP {isSup} {name} no Inert'\n",
    "                )\n",
    "    # ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "    ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "    # ax.get_legend().remove() \n",
    "    ax.set_facecolor('w')\n",
    "    if not os.path.exists(f'{OutputDir}/{statmet}'): \n",
    "        os.makedirs(f'{OutputDir}/{statmet}')\n",
    "    plt.savefig(f'{OutputDir}/{statmet}/{name}_umap{nn}nn_{isSup}.png')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    return dataUMAP\n",
    "\n",
    "def makeMultiPlot(dataN, dataL, model_type='UMAP', name='', statmet='SingleCell' , nn = 100, is_supervised=True, n_components=5, min_dist=0.2, spread= 5, n_epochs=None, metric='cosine',):\n",
    "    \n",
    "    if model_type == 'UMAP':\n",
    "        model_type = model_type+f'{nn}nn'\n",
    "        umap_model = umap.UMAP(n_neighbors=nn\n",
    "                        , min_dist=min_dist\n",
    "                        , spread= spread\n",
    "                        , n_epochs=n_epochs\n",
    "                        , metric=metric,\n",
    "                        n_components=n_components\n",
    "                        )\n",
    "        if is_supervised:\n",
    "            dataOut = umap_model.fit_transform(dataN, y=dataL['onehot'])\n",
    "            isSup = 'Supervised'\n",
    "        else:\n",
    "            dataOut = umap_model.fit_transform(dataL)\n",
    "            isSup = 'Unsupervised'\n",
    "    elif model_type == 'PCA':\n",
    "        pca_model = PCA(n_components=n_components)\n",
    "        pca_model = pca_model.fit(dataN)\n",
    "        dataOut = pca_model.transform(dataN)\n",
    "        isSup = ''\n",
    "    else:\n",
    "        raise ValueError(\"method not implemented\")\n",
    "    \n",
    "    for i in range(n_components):\n",
    "        dataL[f'{model_type}{i}'] = dataOut[:,i]\n",
    "        \n",
    "    dataL = dataL.copy()\n",
    "    # print(dataL.colnames.unique())\n",
    "    # cmap = sns.color_palette(\"hls\", n_colors=11)\n",
    "    cmap = sns.color_palette(\"Set3\", n_colors=12)\n",
    "    cmap = cmap[:11]\n",
    "    hue = dataL['Metadata_Cmpd']\n",
    "    # hue = training_data['cluster']\n",
    "\n",
    "    noInert = dataL[~(dataL['Metadata_Cmpd'] == 'dmso')]\n",
    "    noInert = noInert[~(noInert['Metadata_Cmpd'] == 'sorb')]\n",
    "\n",
    "\n",
    "    fig, axes = plt.subplots(n_components, n_components, figsize=(n_components*4, n_components*4))\n",
    "\n",
    "    for i in range(n_components):\n",
    "        for j in range(n_components):\n",
    "            ax = axes[i][j]\n",
    "\n",
    "            # Setting spines\n",
    "            ax.spines['top'].set_color('w')\n",
    "            ax.spines['right'].set_color('w')\n",
    "            ax.spines['left'].set_color('grey')\n",
    "            ax.spines['bottom'].set_color('grey')\n",
    "\n",
    "            # Plotting scatter plots\n",
    "            sns.scatterplot(\n",
    "                x=f\"{model_type}{i}\", y=f\"{model_type}{j}\",\n",
    "                palette=cmap, hue=hue,\n",
    "                marker='.',\n",
    "                data=dataL,\n",
    "                ax=ax\n",
    "            ).set(title=f'{model_type} {i+1} vs {model_type} {j+1}')\n",
    "            \n",
    "            ax.set_facecolor('w')\n",
    "            if j != n_components - 1:  # Remove legend except for the last column\n",
    "                ax.get_legend().remove()\n",
    "    if not os.path.exists(f'{OutputDir}/{statmet}_{nn}nn_{n_components}dims'): \n",
    "        os.makedirs(f'{OutputDir}/{statmet}_{nn}nn_{n_components}dims')\n",
    "    plt.savefig(f'{OutputDir}/{statmet}/{name}_{model_type}_{isSup}.png')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Well-C16-z12-CONC.ome.tiff'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m filename \u001b[38;5;241m=\u001b[39m filenames[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      6\u001b[0m dataNpy, dataL \u001b[38;5;241m=\u001b[39m readData(filename)\n\u001b[0;32m----> 7\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[43mmakePCA\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataNpy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# _ = makeUMAP(dataNpy, dataL, name=filename)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m _ \u001b[38;5;241m=\u001b[39m makeUMAP(dataNpy, dataL, name\u001b[38;5;241m=\u001b[39mfilename, nn\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m150\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 47\u001b[0m, in \u001b[0;36mmakePCA\u001b[0;34m(dataN, dataPCA, name, statmet, n_components)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmakePCA\u001b[39m(dataN, dataPCA, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, statmet\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSingleCell\u001b[39m\u001b[38;5;124m'\u001b[39m , n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m     46\u001b[0m     pca_model \u001b[38;5;241m=\u001b[39m PCA(n_components\u001b[38;5;241m=\u001b[39m  \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m---> 47\u001b[0m     pca_model \u001b[38;5;241m=\u001b[39m \u001b[43mpca_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataN\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     pcaOut \u001b[38;5;241m=\u001b[39m pca_model\u001b[38;5;241m.\u001b[39mtransform(dataN)\n\u001b[1;32m     49\u001b[0m     dataPCA[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpc1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pcaOut[:,\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/decomposition/_pca.py:434\u001b[0m, in \u001b[0;36mPCA.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    418\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model with X.\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \n\u001b[1;32m    420\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;124;03m        Returns the instance itself.\u001b[39;00m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 434\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/decomposition/_pca.py:483\u001b[0m, in \u001b[0;36mPCA._fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    479\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPCA does not support sparse input. See \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    480\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTruncatedSVD for a possible alternative.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    481\u001b[0m     )\n\u001b[0;32m--> 483\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;66;03m# Handle n_components==None\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/base.py:604\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    602\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 604\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    606\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/validation.py:917\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    915\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    916\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 917\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    920\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    921\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/_array_api.py:380\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    378\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 380\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Well-C16-z12-CONC.ome.tiff'"
     ]
    }
   ],
   "source": [
    "# min_dist=0.2\n",
    "# spread= 5\n",
    "# n_epochs=None\n",
    "# metric='cosine'\n",
    "filename = filenames[0]\n",
    "dataNpy, dataL = readData(filename)\n",
    "_ = makePCA(dataNpy, dataL, name=filename)\n",
    "# _ = makeUMAP(dataNpy, dataL, name=filename)\n",
    "_ = makeUMAP(dataNpy, dataL, name=filename, nn=150)\n",
    "# _ = makeUMAP(dataNpy, dataL, name=filename, nn=300, is_supervised=False)\n",
    "# for filename in filenames:\n",
    "#     dataNpy, dataL = readData(filename)\n",
    "#     _ = makePCA(dataNpy, dataL, name=filename)\n",
    "#     # _ = makeUMAP(dataNpy, dataL, name=filename)\n",
    "#     _ = makeUMAP(dataNpy, dataL, name=filename, nn=250)\n",
    "#     _ = makeUMAP(dataNpy, dataL, name=filename, nn=300, is_supervised=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# for statmet in statmets:\n",
    "#     for filename in filenames:\n",
    "#         dataNpy, dataL = readData(filename, statmet=statmet)\n",
    "#         _ = makePCA(dataNpy, dataL, name=filename, statmet=statmet)\n",
    "#         # _ = makeUMAP(dataNpy, dataL, name=filename, statmet=statmet)\n",
    "#         _ = makeUMAP(dataNpy, dataL, name=filename, statmet=statmet, nn=150)\n",
    "#         # _ = makeUMAP(dataNpy, dataL, name=filename, statmet=statmet, is_supervised=False)\n",
    "#         _ = makeUMAP(dataNpy, dataL, name=filename, statmet=statmet, nn=150, is_supervised=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for filename in filenames:\n",
    "#     dataNpy, dataL = readData(filename)\n",
    "#     _ = makeMultiPlot(dataNpy, dataL, model_type='PCA', n_components=5)\n",
    "#     _ = makeMultiPlot(dataNpy, dataL, model_type='UMAP', n_components=5)\n",
    "#     _ = makeMultiPlot(dataNpy, dataL, model_type='UMAP', is_supervised=False, n_components=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for filename in filenames:\n",
    "#     dataNpy, dataL = readData(filename, statmet='Mean')\n",
    "#     _ = makeMultiPlot(dataNpy, dataL, model_type='PCA', statmet='Mean', n_components=5, nn=100)\n",
    "#     _ = makeMultiPlot(dataNpy, dataL, model_type='UMAP', statmet='Mean', n_components=5, nn=100)\n",
    "#     _ = makeMultiPlot(dataNpy, dataL, model_type='UMAP', statmet='Mean', is_supervised=False, n_components=5, nn=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for filename in filenames:\n",
    "#     dataNpy, dataL = readData(filename, statmet='Median')\n",
    "#     _ = makeMultiPlot(dataNpy, dataL, model_type='PCA', statmet='Median', n_components=5, nn=100)\n",
    "#     _ = makeMultiPlot(dataNpy, dataL, model_type='UMAP', statmet='Median', n_components=5, nn=100)\n",
    "#     _ = makeMultiPlot(dataNpy, dataL, model_type='UMAP', statmet='Median', is_supervised=False, n_components=5, nn=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
