{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/share/data/analyses/christa/colopaint3D/spher_colo52_v1\n",
      "/share/data/analyses/christa/colopaint3D/spher_colo52_v1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Pycytominer\n",
    "from pycytominer import feature_select\n",
    "from pycytominer import normalize\n",
    "from pycytominer import aggregate\n",
    "\n",
    "# Set current working directory\n",
    "print(os.getcwd())\n",
    "os.chdir('/share/data/analyses/christa/colopaint3D/spher_colo52_v1/')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some function definitions\n",
    "\n",
    "def list_features(df):\n",
    "    # List features\n",
    "    list_of_selected_features = list(df.columns.values)\n",
    "    list_of_metadata = list(df.columns[df.columns.str.contains(\"Metadata_\")])\n",
    "    list_of_selected_features = list(set(list_of_selected_features) - set(list_of_metadata))\n",
    "    \n",
    "    return list_of_selected_features, list_of_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_line = 'HT29'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all files in directory\n",
    "dir = '1_FeaturesImages_none/SingleSlice/'\n",
    "\n",
    "\n",
    "files = os.listdir(dir)\n",
    "\n",
    "name = dir\n",
    "\n",
    "# Select all files with HCT116 in the name as well as MedianAgg_meanstd\n",
    "files = [file for file in files if cell_line in file and 'MedianAgg' in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the parquet file into a pandas dataframe\n",
    "\n",
    "# Load all files\n",
    "data = []\n",
    "for file in files:\n",
    "    data.append(pd.read_parquet(dir + file))\n",
    "\n",
    "data = pd.concat(data)\n",
    "\n",
    "# Load metadata (I am missing the concentrations)\n",
    "metadata = pd.read_csv('spher_colo52-metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prepare the metadata\n",
    "\n",
    "dataset = data.copy()\n",
    "\n",
    "# Merge data with metadata to get the concentrations\n",
    "dataset = dataset.merge(metadata[['plate_well', 'cmpd_conc']], left_on='Metadata_PlateWell', right_on = 'plate_well')\n",
    "dataset = dataset.drop(columns=['plate_well'])\n",
    "dataset['Metadata_cmpd_conc'] = dataset['cmpd_conc'].rename('Metadata_cmpd_conc')\n",
    "\n",
    "# Remove all columns with 'FileName' or 'PathName' in the name\n",
    "dataset = dataset.loc[:,~dataset.columns.str.contains('FileName|PathName|ObjectNumber|ImageNumber|AcqID')]\n",
    "dataset['Metadata_PlateWell'] = dataset['Metadata_Well'].astype(str) + '_' + dataset['Metadata_Barcode']\n",
    "# # Add a short name for the compound\n",
    "dataset['Metadata_name'] = dataset['Metadata_cmpd_cmpdname'].str[:5] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize each slice for each plate separately\n",
    "dataset[\"Metadata_plate_slice\"] = (\n",
    "    dataset[\"Metadata_Barcode\"] + \"_\" + dataset[\"Metadata_Site\"].astype(str)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PB000140_0\n",
      "PB000140_1\n",
      "PB000140_2\n",
      "PB000140_3\n",
      "PB000140_4\n",
      "PB000140_5\n",
      "PB000140_6\n",
      "PB000140_7\n",
      "PB000140_8\n",
      "PB000140_9\n",
      "PB000140_10\n",
      "PB000140_11\n",
      "PB000141_0\n",
      "PB000141_1\n",
      "PB000141_2\n",
      "PB000141_3\n",
      "PB000141_4\n",
      "PB000141_5\n",
      "PB000141_6\n",
      "PB000141_7\n",
      "PB000141_8\n",
      "PB000141_9\n",
      "PB000141_10\n",
      "PB000141_11\n",
      "PB000142_0\n",
      "PB000142_1\n",
      "PB000142_2\n",
      "PB000142_3\n",
      "PB000142_4\n",
      "PB000142_5\n",
      "PB000142_6\n",
      "PB000142_7\n",
      "PB000142_8\n",
      "PB000142_9\n",
      "PB000142_10\n",
      "PB000142_11\n",
      "PB000139_0\n",
      "PB000139_1\n",
      "PB000139_2\n",
      "PB000139_3\n",
      "PB000139_4\n",
      "PB000139_5\n",
      "PB000139_6\n",
      "PB000139_7\n",
      "PB000139_8\n",
      "PB000139_9\n",
      "PB000139_10\n",
      "PB000139_11\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Normalize separately per 1) plate and 2) cell line\n",
    "#\n",
    "\n",
    "units = dataset[\"Metadata_plate_slice\"].unique() # Per slice in each plate\n",
    "\n",
    "# Itnitialize an empty dataframe\n",
    "normalized = pd.DataFrame(columns=dataset.columns.values)\n",
    "\n",
    "for unit in units:\n",
    "    \n",
    "    print(unit)\n",
    "    annotated_temp = dataset[dataset['Metadata_plate_slice'] == unit]\n",
    "\n",
    "    # Normalize: choose between standardize, robustize, mad_robustize, spherize \n",
    "    normalized_temp = normalize(annotated_temp, \n",
    "                                features=list_features(dataset)[0],image_features=False, \n",
    "                                meta_features=\"infer\", samples=\"Metadata_cmpd_cmpdname == 'dmso'\", \n",
    "                                method=\"standardize\")\n",
    "    normalized = pd.concat([normalized, normalized_temp], ignore_index=True)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate profiles across z-slices\n",
    "\n",
    "features = list_features(normalized)[0]\n",
    "metadata_cols = [col for col in normalized.columns if col not in features + ['Metadata_Site', 'Metadata_PlateWell','Metadata_plate_slice']]\n",
    "\n",
    "aggregated_df = normalized.groupby(['Metadata_PlateWell']).agg(\n",
    "    {**{col: 'first' for col in metadata_cols},  # Keep the first occurrence of metadata columns\n",
    "    **{col: 'median' for col in features}}  # Aggregate features by mean (or any other function)\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(773, 670)\n"
     ]
    }
   ],
   "source": [
    "# Feature selection: \"variance_threshold\", \"correlation_threshold\", \"drop_na_columns\", \"blocklist\", \"drop_outliers\", \"noise_removal\",\n",
    "to_clip_df = feature_select(aggregated_df, features=list_features(normalized)[0], operation=[\"variance_threshold\", \"correlation_threshold\",\"drop_na_columns\", \"blocklist\"])\n",
    "\n",
    "# Instead of removing the outliers, we can clip them\n",
    "selected_df = pd.concat([to_clip_df[list_features(to_clip_df)[1]], to_clip_df[list_features(to_clip_df)[0]].clip(lower=-40, upper=40, axis=1)], axis=1)\n",
    "print(selected_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data\n",
    "OutputDir = '1_FeaturesImages_none/'\n",
    "\n",
    "selected_df.to_csv(('{}selected_data_{}.csv').format(OutputDir, cell_line), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
