{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/share/data/analyses/christa/colopaint3D_fork/spher_colo52_v1/2_Processing\n",
      "/share/data/analyses/christa/colopaint3D_fork/spher_colo52_v1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Pycytominer\n",
    "from pycytominer import feature_select\n",
    "from pycytominer import normalize\n",
    "from pycytominer import aggregate\n",
    "\n",
    "# Set current working directory\n",
    "print(os.getcwd())\n",
    "os.chdir('/share/data/analyses/christa/colopaint3D_fork/spher_colo52_v1/')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some function definitions #TODO: I have a better one than this one\n",
    "\n",
    "def list_features(df):\n",
    "    # List features\n",
    "    list_of_selected_features = list(df.columns.values)\n",
    "    list_of_metadata = list(df.columns[df.columns.str.contains(\"Metadata_\")])\n",
    "    list_of_selected_features = list(set(list_of_selected_features) - set(list_of_metadata))\n",
    "    \n",
    "    return list_of_selected_features, list_of_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_line = 'HCT116' # HT29 or HCT116\n",
    "data_type = 'aggregates' # aggregates, 2D or MIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all files in directory\n",
    "dir = '1_Data/FeaturesImages_100125_none/SingleSlice/'\n",
    "\n",
    "files = os.listdir(dir)\n",
    "\n",
    "name = dir\n",
    "\n",
    "# Select all files with HCT116 in the name as well as MedianAgg_meanstd\n",
    "files = [file for file in files if cell_line in file and 'MedianAgg' in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the parquet file into a pandas dataframe\n",
    "\n",
    "# Load all files\n",
    "data = []\n",
    "for file in files:\n",
    "    data.append(pd.read_parquet(dir + file))\n",
    "\n",
    "data = pd.concat(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prepare the metadata\n",
    "dataset = data.copy()\n",
    "dataset['Metadata_name'] = dataset['Metadata_cmpdname'].str[:5] \n",
    "\n",
    "# Normalize each slice for each plate separately\n",
    "dataset[\"Metadata_plate_slice\"] = (\n",
    "    dataset[\"Metadata_Barcode\"] + \"_\" + dataset[\"Metadata_Site\"].astype(str)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PB000137_0\n",
      "PB000138_0\n",
      "PB000140_0\n",
      "PB000139_0\n",
      "PB000140_1\n",
      "PB000137_1\n",
      "PB000138_1\n",
      "PB000139_1\n",
      "PB000138_2\n",
      "PB000140_2\n",
      "PB000137_2\n",
      "PB000139_2\n",
      "PB000138_3\n",
      "PB000140_3\n",
      "PB000137_3\n",
      "PB000139_3\n",
      "PB000138_4\n",
      "PB000137_4\n",
      "PB000140_4\n",
      "PB000139_4\n",
      "PB000140_5\n",
      "PB000138_5\n",
      "PB000137_5\n",
      "PB000139_5\n",
      "PB000138_6\n",
      "PB000137_6\n",
      "PB000140_6\n",
      "PB000139_6\n",
      "PB000138_7\n",
      "PB000139_7\n",
      "PB000140_7\n",
      "PB000137_7\n",
      "PB000137_8\n",
      "PB000140_8\n",
      "PB000138_8\n",
      "PB000139_8\n",
      "PB000137_9\n",
      "PB000138_9\n",
      "PB000139_9\n",
      "PB000140_9\n",
      "PB000138_10\n",
      "PB000139_10\n",
      "PB000137_10\n",
      "PB000140_10\n",
      "PB000137_11\n",
      "PB000140_11\n",
      "PB000138_11\n",
      "PB000139_11\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Normalize separately per 1) plate and 2) cell line\n",
    "#\n",
    "\n",
    "units = dataset[\"Metadata_plate_slice\"].unique() # Per slice in each plate\n",
    "\n",
    "# Itnitialize an empty dataframe\n",
    "normalized = pd.DataFrame(columns=dataset.columns.values)\n",
    "\n",
    "for unit in units:\n",
    "    \n",
    "    print(unit)\n",
    "    annotated_temp = dataset[dataset['Metadata_plate_slice'] == unit]\n",
    "\n",
    "    # Normalize: choose between standardize, robustize, mad_robustize, spherize \n",
    "    normalized_temp = normalize(annotated_temp, \n",
    "                                features=list_features(dataset)[0],image_features=False, \n",
    "                                meta_features=\"infer\", samples=\"Metadata_cmpdname == 'dmso'\", \n",
    "                                method=\"standardize\")\n",
    "    normalized = pd.concat([normalized, normalized_temp], ignore_index=True)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate profiles across z-slices\n",
    "\n",
    "features = list_features(normalized)[0]\n",
    "metadata_cols = [col for col in normalized.columns if col not in features + ['Metadata_Site', 'Metadata_PlateWell','Metadata_plate_slice']]\n",
    "\n",
    "aggregated_df = normalized.groupby(['Metadata_PlateWell']).agg(\n",
    "    {**{col: 'first' for col in metadata_cols},  # Keep the first occurrence of metadata columns\n",
    "    **{col: 'median' for col in features}}  # Aggregate features by mean (or any other function)\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(834, 613)\n"
     ]
    }
   ],
   "source": [
    "# Feature selection: \"variance_threshold\", \"correlation_threshold\", \"drop_na_columns\", \"blocklist\", \"drop_outliers\", \"noise_removal\",\n",
    "to_clip_df = feature_select(aggregated_df, features=list_features(normalized)[0], operation=[\"variance_threshold\", \"correlation_threshold\",\"drop_na_columns\", \"blocklist\"])\n",
    "\n",
    "# Instead of removing the outliers, we can clip them\n",
    "selected_df = pd.concat([to_clip_df[list_features(to_clip_df)[1]], to_clip_df[list_features(to_clip_df)[0]].clip(lower=-40, upper=40, axis=1)], axis=1)\n",
    "print(selected_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data\n",
    "OutputDir = '1_Data/results/'\n",
    "if not os.path.exists(OutputDir): \n",
    "    os.makedirs(OutputDir)\n",
    "\n",
    "# selected_df.to_csv(('{}selected_data_{}_{}.csv').format(OutputDir, data_type, cell_line), index=False)\n",
    "\n",
    "# Save as parquet\n",
    "selected_df.to_parquet(('{}selected_data_{}_{}.parquet').format(OutputDir, data_type, cell_line))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
