{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/share/data/analyses/christa/colopaint3D/spher_colo52_v1/2_Processing\n",
      "/share/data/analyses/christa/colopaint3D/spher_colo52_v1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Pycytominer\n",
    "from pycytominer import feature_select\n",
    "from pycytominer import normalize\n",
    "# from pycytominer import aggregate\n",
    "\n",
    "# Set current working directory\n",
    "print(os.getcwd())\n",
    "os.chdir('/share/data/analyses/christa/colopaint3D/spher_colo52_v1/')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def list_features(df):\n",
    "    # List features\n",
    "    list_of_selected_features = list(df.columns.values)\n",
    "    list_of_metadata = list(df.columns[df.columns.str.contains(\"Metadata_\")])\n",
    "    list_of_selected_features = list(set(list_of_selected_features) - set(list_of_metadata))\n",
    "    \n",
    "    return list_of_selected_features, list_of_metadata\n",
    "\n",
    "\n",
    "def standardize_mean(df):\n",
    "    # df = df.with_row_count('index')\n",
    "    df_mean = pl.DataFrame()\n",
    "    for i in range(df.select(pl.col('Metadata_Site')).max().item()):\n",
    "        df_slice = df.filter(pl.col('Metadata_Site')==i)\n",
    "        df_slice_DMSO=df_slice.filter(pl.col('Metadata_cmpd_cmpdname')=='dmso')\n",
    "        assert df_slice_DMSO.shape[0]>0, \"did not find any wells 'treated' with DMSO\"\n",
    "        mu = df_slice_DMSO.select(float_columns).mean()\n",
    "        std = df_slice_DMSO.select(float_columns).std()\n",
    "        # replace 0 with 1 (specifically not clip) to avoid div by zero\n",
    "        std = std.select([pl.col(c).replace({0: 1}, default=pl.col(c)) for c in std.columns])\n",
    "        for i,col in enumerate(std.columns):\n",
    "            if std[col].is_null().any():\n",
    "                raise RuntimeError(f\"some std value in column {col,i} is nan?!\")\n",
    "            if std[col].is_infinite().any():\n",
    "                raise RuntimeError(f\"some std value in column {col,i} is infinite?!\")\n",
    "            if (std[col]==0).any():\n",
    "                raise RuntimeError(f\"unexpected 0 in column {col}\")\n",
    "        print_time(\"calculated DMSO distribution for one slice\")\n",
    "        df_standardized_slice = df_slice.with_columns([(pl.col(c) - mu[c]) / (std[c]+0.01) for c in mu.columns])\n",
    "        found_nan=False\n",
    "        # checking nans:\n",
    "        for i,col in enumerate(mu.columns):\n",
    "            if df_standardized_slice[col].is_null().any():\n",
    "                found_nan=True\n",
    "                print(f\"some value in column {col,i} is nan\")\n",
    "        if found_nan:\n",
    "            raise RuntimeError(\"found nan\")\n",
    "        df_mean_slice=df_slice.with_columns([df_standardized_slice[c] for c in df_standardized_slice.columns])\n",
    "        df_mean = pl.concat([df_mean, df_mean_slice])\n",
    "    # df_mean\n",
    "    return df_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_line = 'HCT116' # HT29 or HCT116\n",
    "data_type = 'aggregates'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the normalized per slice data \n",
    "# Save the data\n",
    "OutputDir = '1_Data/results/'\n",
    "if not os.path.exists(OutputDir): \n",
    "    os.makedirs(OutputDir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List all files in directory\n",
    "dir = '1_Data/FeaturesImages_150125_none/SingleSlice/'\n",
    "\n",
    "files = os.listdir(dir)\n",
    "\n",
    "name = dir\n",
    "\n",
    "# Select all files with HCT116 in the name as well as MedianAgg_meanstd\n",
    "files = [file for file in files if cell_line in file and 'MedianAgg' in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the parquet file into a pandas dataframe\n",
    "\n",
    "# Load all files\n",
    "data = []\n",
    "for file in files:\n",
    "    data.append(pd.read_parquet(dir + file))\n",
    "\n",
    "data = pd.concat(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata (I am missing the concentrations)\n",
    "metadata = pd.read_csv('1_Data/spher_colo52-metadata.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Prepare the metadata\n",
    "dataset = data.copy()\n",
    "\n",
    "# Merge data with metadata to get the concentrations\n",
    "dataset = dataset.merge(metadata[['plate_well', 'cmpd_conc']], left_on='Metadata_PlateWell', right_on = 'plate_well')\n",
    "dataset = dataset.drop(columns=['plate_well'])\n",
    "# dataset['Metadata_cmpd_conc'] = dataset['cmpd_conc'].rename('Metadata_cmpd_conc')\n",
    "\n",
    "# # Add a short name for the compound\n",
    "dataset['Metadata_name'] = dataset['Metadata_cmpdname'].str[:5]\n",
    "# Normalize each slice for each plate separately\n",
    "dataset[\"Metadata_plate_slice\"] = (\n",
    "    dataset[\"Metadata_Barcode\"] + \"_\" + dataset[\"Metadata_Site\"].astype(str)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PB000140_0\n",
      "PB000140_10\n",
      "PB000140_11\n",
      "PB000140_1\n",
      "PB000140_2\n",
      "PB000140_3\n",
      "PB000140_4\n",
      "PB000140_5\n",
      "PB000140_6\n",
      "PB000140_7\n",
      "PB000140_8\n",
      "PB000140_9\n",
      "PB000137_0\n",
      "PB000137_10\n",
      "PB000137_11\n",
      "PB000137_1\n",
      "PB000137_2\n",
      "PB000137_3\n",
      "PB000137_4\n",
      "PB000137_5\n",
      "PB000137_6\n",
      "PB000137_7\n",
      "PB000137_8\n",
      "PB000137_9\n",
      "PB000138_0\n",
      "PB000138_10\n",
      "PB000138_11\n",
      "PB000138_1\n",
      "PB000138_2\n",
      "PB000138_3\n",
      "PB000138_4\n",
      "PB000138_5\n",
      "PB000138_6\n",
      "PB000138_7\n",
      "PB000138_8\n",
      "PB000138_9\n",
      "PB000139_0\n",
      "PB000139_10\n",
      "PB000139_11\n",
      "PB000139_1\n",
      "PB000139_2\n",
      "PB000139_3\n",
      "PB000139_4\n",
      "PB000139_5\n",
      "PB000139_6\n",
      "PB000139_7\n",
      "PB000139_8\n",
      "PB000139_9\n",
      "(9919, 813)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Normalize separately per 1) plate and 2) cell line\n",
    "#\n",
    "\n",
    "units = dataset[\"Metadata_plate_slice\"].unique() # Per slice in each plate\n",
    "\n",
    "# Itnitialize an empty dataframe\n",
    "normalized = pd.DataFrame(columns=dataset.columns.values)\n",
    "\n",
    "for unit in units:\n",
    "    \n",
    "    print(unit)\n",
    "    annotated_temp = dataset[dataset['Metadata_plate_slice'] == unit]\n",
    "\n",
    "    # Normalize: choose between standardize, robustize, mad_robustize, spherize \n",
    "    normalized_temp = normalize(annotated_temp, \n",
    "                                features=list_features(dataset)[0],image_features=False, \n",
    "                                meta_features=\"infer\", samples=\"Metadata_cmpdname == 'dmso'\", \n",
    "                                method=\"standardize\")\n",
    "    normalized = pd.concat([normalized, normalized_temp], ignore_index=True)\n",
    "\n",
    "to_clip_df = feature_select(normalized, features=list_features(normalized)[0], operation=[\"variance_threshold\", \"correlation_threshold\",\"drop_na_columns\", \"blocklist\"])\n",
    "# Instead of removing the outliers, we can clip them\n",
    "selected_df = pd.concat([to_clip_df[list_features(to_clip_df)[1]], to_clip_df[list_features(to_clip_df)[0]].clip(lower=-40, upper=40, axis=1)], axis=1)\n",
    "print(selected_df.shape)\n",
    "selected_df.to_csv(('{}normalized_data_{}.csv').format(OutputDir, cell_line), index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PB000140\n",
      "PB000137\n",
      "PB000138\n",
      "PB000139\n",
      "(9919, 707)\n"
     ]
    }
   ],
   "source": [
    "## Normalize per plate \n",
    "#\n",
    "# Normalize separately per 1) plate and 2) cell line\n",
    "#\n",
    "\n",
    "units = dataset[\"Metadata_Barcode\"].unique() # Per slice in each plate\n",
    "\n",
    "# Itnitialize an empty dataframe\n",
    "normalized_noslice = pd.DataFrame(columns=dataset.columns.values)\n",
    "\n",
    "for unit in units:\n",
    "    \n",
    "    print(unit)\n",
    "    annotated_temp = dataset[dataset['Metadata_Barcode'] == unit]\n",
    "\n",
    "    # Normalize: choose between standardize, robustize, mad_robustize, spherize \n",
    "    normalized_temp = normalize(annotated_temp, \n",
    "                                features=list_features(dataset)[0],image_features=False, \n",
    "                                meta_features=\"infer\", samples=\"Metadata_cmpdname == 'dmso'\", \n",
    "                                method=\"standardize\")\n",
    "    normalized_noslice = pd.concat([normalized_noslice, normalized_temp], ignore_index=True)\n",
    "\n",
    "to_clip_df = feature_select(normalized_noslice, features=list_features(normalized_noslice)[0], operation=[\"variance_threshold\", \"correlation_threshold\",\"drop_na_columns\", \"blocklist\"])\n",
    "# Instead of removing the outliers, we can clip them\n",
    "selected_df = pd.concat([to_clip_df[list_features(to_clip_df)[1]], to_clip_df[list_features(to_clip_df)[0]].clip(lower=-40, upper=40, axis=1)], axis=1)\n",
    "print(selected_df.shape)\n",
    "selected_df.to_csv(('{}normalized_data_no_slice_{}.csv').format(OutputDir, cell_line), index=False)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
