{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/share/data/analyses/christa/colopaint3D_fork/spher_colo52_v1/1_Data'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import polars as pl # like pandas, but much faster\n",
    "import polars.selectors as cs\n",
    "import numpy as np\n",
    "import os, shutil, glob\n",
    "from random import randint\n",
    "import re, math\n",
    "import datetime\n",
    "import gc\n",
    "from pathlib import Path\n",
    "\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sourceDir = '/share/data/cellprofiler/automation/results'\n",
    "rootDir = '/share/data/analyses/christa/colopaint3D_fork/spher_colo52_v1/1_Data/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 1)\n",
      "┌───────────────────┐\n",
      "│ feature_names     │\n",
      "│ ---               │\n",
      "│ str               │\n",
      "╞═══════════════════╡\n",
      "│ featICF_nuclei    │\n",
      "│ featICF_cells     │\n",
      "│ featICF_cytoplasm │\n",
      "└───────────────────┘\n"
     ]
    }
   ],
   "source": [
    "OutputDir = 'FeaturesImages_150125_none'\n",
    "if not os.path.exists(OutputDir): \n",
    "    os.makedirs(OutputDir)\n",
    "NameContains = ''\n",
    "InputFolders = pl.read_csv(f'{rootDir}filemap.csv')\n",
    "print(InputFolders )\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current date and time : \n",
      "2025-01-15 11:46:35\n"
     ]
    }
   ],
   "source": [
    "now = datetime.datetime.now()\n",
    "print ('Current date and time : ')\n",
    "print (now.strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['index','layout_id','cmpd_code', 'solvent','cmpd_conc','cmpd_conc_unit','stock_conc','stock_conc_unit','cmpd_vol', 'cmpd_vol_unit', 'well_vol', 'well_vol_unit', 'article_id','pubchemID', 'smiles', 'inkey', 'clinical_status']\n",
    "\n",
    "use_clipping = False\n",
    "\n",
    "std_mean = True\n",
    "\n",
    "make_slices = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ObjectList = ['featICF_nuclei', 'featICF_cells', 'featICF_cytoplasm']\n",
    "\n",
    "def print_time(msg=None):\n",
    "    now = datetime.datetime.now()\n",
    "    print(now.strftime('%Y-%m-%d %H:%M:%S'),msg or \"\")\n",
    "float_columns=[pl.col(pl.Float32),pl.col(pl.Float64)]\n",
    "\n",
    "def aggregate_mean(df_in):\n",
    "    df_agg = df_in\n",
    "    df_float_columns=set(list(df_agg.select(float_columns).columns))\n",
    "    group_by_columns=['Metadata_PlateWell', 'Metadata_Barcode','Metadata_Well']\n",
    "    other_columns=set(list(df_agg.columns))-df_float_columns-set(group_by_columns)\n",
    "    # # group by mean for all float features, and group by first for all non-float columns (indices and string metadata)\n",
    "    group_by_aggregates=[\n",
    "        *[pl.mean(x) for x in list(df_float_columns)],\n",
    "        *[pl.first(x) for x in list(other_columns)]\n",
    "    ]\n",
    "    df_agg_mean=df_agg.group_by(group_by_columns).agg(group_by_aggregates)\n",
    "    return df_agg_mean\n",
    "\n",
    "def aggregate_median(df_in):\n",
    "    df_agg = df_in\n",
    "    df_float_columns=set(list(df_agg.select(float_columns).columns))\n",
    "    group_by_columns=['Metadata_Barcode','Metadata_Well']\n",
    "    other_columns=set(list(df_agg.columns))-df_float_columns-set(group_by_columns)\n",
    "    group_by_aggregates=[\n",
    "        *[pl.median(x) for x in list(df_float_columns)],\n",
    "        *[pl.first(x) for x in list(other_columns)]\n",
    "    ]\n",
    "    df_agg_median=df_agg.group_by(group_by_columns).agg(group_by_aggregates)\n",
    "    return df_agg_median\n",
    "\n",
    "def standardize_mean(df):\n",
    "    df = df.with_row_count('index')\n",
    "    df_mean = pl.DataFrame()\n",
    "    for i in range(df.select(pl.col('Metadata_Site')).max().item()):\n",
    "        df_slice = df.filter(pl.col('Metadata_Site')==i)\n",
    "        df_slice_DMSO=df_slice.filter(pl.col('Metadata_cmpd_cmpdname')=='dmso')\n",
    "        assert df_slice_DMSO.shape[0]>0, \"did not find any wells 'treated' with DMSO\"\n",
    "        mu = df_slice_DMSO.select(float_columns).mean()\n",
    "        std = df_slice_DMSO.select(float_columns).std()\n",
    "        # replace 0 with 1 (specifically not clip) to avoid div by zero\n",
    "        std = std.select([pl.col(c).replace({0: 1}, default=pl.col(c)) for c in std.columns])\n",
    "        for i,col in enumerate(std.columns):\n",
    "            if std[col].is_null().any():\n",
    "                raise RuntimeError(f\"some std value in column {col,i} is nan?!\")\n",
    "            if std[col].is_infinite().any():\n",
    "                raise RuntimeError(f\"some std value in column {col,i} is infinite?!\")\n",
    "            if (std[col]==0).any():\n",
    "                raise RuntimeError(f\"unexpected 0 in column {col}\")\n",
    "        print_time(\"calculated DMSO distribution for one slice\")\n",
    "        df_standardized_slice = df_slice.with_columns([(pl.col(c) - mu[c]) / (std[c]+0.01) for c in mu.columns])\n",
    "        found_nan=False\n",
    "        # checking nans:\n",
    "        for i,col in enumerate(mu.columns):\n",
    "            if df_standardized_slice[col].is_null().any():\n",
    "                found_nan=True\n",
    "                print(f\"some value in column {col,i} is nan\")\n",
    "        if found_nan:\n",
    "            raise RuntimeError(\"found nan\")\n",
    "        df_mean_slice=df_slice.with_columns([df_standardized_slice[c] for c in df_standardized_slice.columns])   \n",
    "        df_mean = pl.concat([df_mean, df_mean_slice])\n",
    "    # df_mean\n",
    "    return df_mean\n",
    "\n",
    "def standardize_mad(df):\n",
    "    df_DMSO=df.filter(pl.col('Metadata_cmpd_cmpdname')=='dmso')\n",
    "    assert df_DMSO.shape[0]>0, \"did not find any wells 'treated' with DMSO\"\n",
    "    median = df_DMSO.select(float_columns).median()\n",
    "    # Check for null or infinite medians and raise errors if found\n",
    "    for col in median.columns:\n",
    "        if median[col].is_null().any():\n",
    "            raise RuntimeError(f\"some median value in column {col} is nan?!\")\n",
    "        if median[col].is_infinite().any():\n",
    "            raise RuntimeError(f\"some median value in column {col} is infinite?!\")\n",
    "    # mad = df_DMSO.select([(pl.col(c) - pl.col(c).median()).abs().alias(c) for c in float_columns])\n",
    "    mad = pl.concat([df.select((pl.col(c)-pl.col(c).median()).abs().median()) for c in df.select(float_columns).columns], how='horizontal')\n",
    "    # mad = df_DMSO.select([pl.abs(pl.col(c) - median[c]).median().alias(c) for c in float_columns])\n",
    "    # Ensure MAD values are not zero to avoid division by zero\n",
    "    # Here we replace 0 with a small value (e.g., 0.01) instead of 1 to maintain the scale of MAD\n",
    "    # mad = mad.select([pl.when(pl.col(c) == 0).then(0.01).otherwise(pl.col(c)).alias(c) for c in mad.columns])\n",
    "    mad = mad.select([pl.col(c).replace({0: 0.01}, default=pl.col(c)) for c in mad.columns])\n",
    "\n",
    "    # Check for null, infinite, or unexpected zero values in MAD and raise errors if found\n",
    "    for i, col in enumerate(mad.columns):\n",
    "        if mad[col].is_null().any():\n",
    "            raise RuntimeError(f\"some MAD value in column {col,i} is nan?!\")\n",
    "        if mad[col].is_infinite().any():\n",
    "            raise RuntimeError(f\"some MAD value in column {col,i} is infinite?!\")\n",
    "        if (mad[col] == 0).any():\n",
    "            raise RuntimeError(f\"unexpected 0 in column {col}\")\n",
    "    print_time(\"calculated DMSO distribution\")\n",
    "    df_standardized = df.with_columns([(pl.col(c) - median[c]) / (mad[c]) for c in median.columns])\n",
    "    # CHecking for nans:\n",
    "    found_nan = False\n",
    "    for i,col in enumerate(median.columns):\n",
    "        if df_standardized[col].is_null().any():\n",
    "            found_nan=True\n",
    "            print(f\"some value in column {col,i} is nan\")\n",
    "    if found_nan:\n",
    "        raise RuntimeError(\"found nan\")\n",
    "    df_mad=df.with_columns([df_standardized[c] for c in df_standardized.columns])   \n",
    "    return df_mad\n",
    "\n",
    "def generate_slices(df, outdir, arg):\n",
    "    df_sAgg = pl.DataFrame()\n",
    "    for i in range(df.select(pl.col('Metadata_Site')).max().item()):\n",
    "        df_slice = df.filter(pl.col('Metadata_Site')==i)\n",
    "        df_slice_mean = aggregate_mean(df_slice)\n",
    "        df_slice_mean.write_parquet(f'{outdir}/{df.select(pl.col(\"Metadata_cmpd_cell_line\")).unique().item()}_Slice{i}MeanAgg_{arg}.parquet')\n",
    "        df_slice_median = aggregate_median(df_slice)\n",
    "        df_slice_median.write_parquet(f'{outdir}/{df.select(pl.col(\"Metadata_cmpd_cell_line\")).unique().item()}_Slice{i}MedianAgg_{arg}.parquet')\n",
    "        del df_slice\n",
    "        del df_slice_median\n",
    "        df_sAgg = pl.concat([df_sAgg, df_slice_mean])\n",
    "    return df_sAgg\n",
    "\n",
    "def data_processing(metaEx, cl, ObjectList, OutputDir, sliceLim=13):\n",
    "    #Filtering Metadata and generating dirlist\n",
    "    metaEx = metaEx.filter(pl.col('cell_line')==cl)\n",
    "    barcodes = metaEx.select(pl.col('barcode')).unique()\n",
    "    barcodes = barcodes['barcode']\n",
    "    barcodes.to_list()\n",
    "    dirlist = [f'{sourceDir}/{barcode}' for barcode in barcodes]\n",
    "\n",
    "    print('Starting Processing')\n",
    "    df = pl.DataFrame()\n",
    "    for BaseDir in dirlist:\n",
    "        mdf_op = metaEx.filter(pl.col('barcode') == BaseDir.split('/')[-1])\n",
    "        image_id = mdf_op.select(pl.col('image_id')).unique().to_series().to_list()[-1]\n",
    "        cp_id = mdf_op.select(pl.col('cp_id')).unique().to_series().to_list()[-1]\n",
    "        print(f'{BaseDir}/{image_id}/{cp_id}')\n",
    "        BaseDir = f'{BaseDir}/{image_id}/{cp_id}'\n",
    "\n",
    "\n",
    "        # nuclei = pl.read_parquet(BaseDir+f'/{ObjectList[0]}.parquet').add_prefix('Nuclei_').reset_index()\n",
    "        # cytoplasm = pl.read_parquet(BaseDir+f'/{ObjectList[1]}.parquet').add_prefix('Cytoplasm_').reset_index()\n",
    "        # cells = pl.read_parquet(BaseDir+f'/{ObjectList[2]}.parquet').add_prefix('Cells_').reset_index()\n",
    "        # f_df=pl.read_parquet(f)\n",
    "        # f_df=f_df.rename({x:f'{feature_set_name}_{x}' for x in f_df.columns})\n",
    "        \n",
    "\n",
    "        nuclei = pl.read_parquet(BaseDir+f'/{ObjectList[0]}.parquet')\n",
    "        nuclei=nuclei.rename({x:f'Nuclei_{x}' for x in nuclei.columns})\n",
    "        cytoplasm = pl.read_parquet(BaseDir+f'/{ObjectList[1]}.parquet')\n",
    "        cytoplasm=cytoplasm.rename({x:f'Cytoplasm_{x}' for x in cytoplasm.columns})\n",
    "        cells = pl.read_parquet(BaseDir+f'/{ObjectList[2]}.parquet')\n",
    "        cells=cells.rename({x:f'Cells_{x}' for x in cells.columns})\n",
    "        # step 1: Take the mean values of 'multiple nuclei' belonging to one cell\n",
    "\n",
    "        nuclei = nuclei.group_by([\n",
    "            \"Nuclei_Metadata_Barcode\",\"Nuclei_Metadata_Well\",\n",
    "            \"Nuclei_Parent_cells\", 'Nuclei_Metadata_Site'\n",
    "        ]).mean()\n",
    "\n",
    "        df_one = cytoplasm.join(nuclei,\n",
    "                    how='left', \n",
    "                    right_on=['Nuclei_Metadata_Well', 'Nuclei_Metadata_Site', 'Nuclei_Parent_cells', 'Nuclei_Metadata_Barcode'],\n",
    "                    left_on = ['Cytoplasm_Metadata_Well','Cytoplasm_Metadata_Site', 'Cytoplasm_ObjectNumber', 'Cytoplasm_Metadata_Barcode'])\n",
    "                    \n",
    "        df_one = df_one.join(cells, how='left', \n",
    "                        left_on=['Cytoplasm_Metadata_Well','Cytoplasm_Metadata_Site','Cytoplasm_ObjectNumber', 'Cytoplasm_Metadata_Barcode'],\n",
    "                        right_on = ['Cells_Metadata_Well','Cells_Metadata_Site',\"Cells_ObjectNumber\", 'Cells_Metadata_Barcode'])\n",
    "\n",
    "        # print_time(\"initial merging\")\n",
    "        print('part1')\n",
    "\n",
    "        # deduplicate barcode/well/site - renamed cytoplasm_Metadata* to Metadata* and removes nuclei_* etc\n",
    "        unique_metadata_feature_names=['Metadata_Barcode','Metadata_Well','Metadata_Site']\n",
    "        df_one=df_one.rename({f'Cytoplasm_{suffix}':suffix for suffix in unique_metadata_feature_names})\n",
    "        # df = df.filter(pl.col(''))       \n",
    "        # for some reason, the site is parsed as float, even though it really should be an int\n",
    "        if df_one['Metadata_Site'].dtype in [np.dtype('float32'), np.dtype('float64')]:\n",
    "            # sometimes, for some reason, site indices are inf/nan\n",
    "            site_is_nan_mask=np.isnan(df_one['Metadata_Site'])\n",
    "            site_is_inf_mask=np.isinf(df_one['Metadata_Site'])\n",
    "            \n",
    "            try:\n",
    "                num_sites_nan=np.sum(site_is_nan_mask)\n",
    "                num_sites_inf=np.sum(site_is_inf_mask)\n",
    "                assert num_sites_nan==0, f\"found nan site values (n = {num_sites_nan})\"\n",
    "                assert num_sites_inf==0, f\"found inf site values (n = {num_sites_inf})\"\n",
    "            except AssertionError as e:\n",
    "                print(f\"info - this issue was automatically circumvented in the code : {e}\")\n",
    "                df_one=df_one[~(site_is_inf_mask|site_is_nan_mask)]\n",
    "                \n",
    "            num_metadata_site_entries_nonint=np.sum(np.abs(df_one['Metadata_Site']%1.0)>1e-6)\n",
    "            assert num_metadata_site_entries_nonint==0, f\"ERROR : {num_metadata_site_entries_nonint} imaging sites don't have integer indices. that should not be the case, and likely indicates a bug.\"\n",
    "            \n",
    "            #Should use np.round, no? TODO ask patrick. Truncation Errors are annoying.\n",
    "            df_one['Metadata_Site'] = df_one['Metadata_Site'].astype(np.dtype('int32'))\n",
    "        \n",
    "        #Adding Compound Metadata to each row\n",
    "        df_one = df_one.join(mdf_op.rename({x:f\"Metadata_cmpd_{x}\" for x in mdf_op.columns}),left_on='Metadata_Well',right_on='Metadata_cmpd_well_id')\n",
    "        df_one = df_one.filter(pl.col('Metadata_Site')<sliceLim)\n",
    "        df = pl.concat([df, df_one])\n",
    "        plate_name = f'processed metadata for {BaseDir.split(\"/\")[-1]}'\n",
    "        print(plate_name)\n",
    "    df = df.sort(pl.col('Metadata_Site'))\n",
    "    ###Here should be workable to unify by cell line.\n",
    "    df = df.with_columns((pl.col(\"Metadata_Barcode\") + \"_\" + pl.col(\"Metadata_Well\")).alias(\"Metadata_PlateWell\"))\n",
    "    print(df.select(pl.col('Metadata_cmpd_cell_line')).to_series().unique().to_list())\n",
    "    df = df.filter(pl.col('Metadata_cmpd_cell_line')==cl)\n",
    "    print(df.select(pl.col('Metadata_cmpd_cell_line')).to_series().unique().to_list())\n",
    "    ###End\n",
    "    # drop all rows that contain nan\n",
    "    num_rows_before_nan_trim = df.shape[0]\n",
    "    for col in df.select([pl.col(pl.Float32),pl.col(pl.Float64)]).columns:\n",
    "        before_drop=df.shape[0]\n",
    "        df=df.filter(pl.col(col).is_not_null())\n",
    "        after_drop=df.shape[0]\n",
    "\n",
    "        num_values_dropped=before_drop-after_drop\n",
    "        if num_values_dropped>0:\n",
    "           print(f\"dropped {num_values_dropped} rows due to NaNs in column {col}\")\n",
    "\n",
    "    num_rows_after_nan_trim = df.shape[0]\n",
    "    print_time(\"dropped NaNs\")\n",
    "    # Clip outliers\n",
    "    use_clipping = False\n",
    "    if use_clipping:\n",
    "        print('clipping values....')\n",
    "        float_cols = [c for c_name,c_dtype in zip(df.columns,df.dtypes) if \"float\" in str(c_dtype)]\n",
    "        lower_quantile = df.select(float_cols).quantile(0.01)\n",
    "        upper_quantile = df.select(float_cols).quantile(0.99)\n",
    "        print(\"calced quantiles\")\n",
    "        for col in float_cols:\n",
    "            df = df.with_column(\n",
    "                pl.col(col).clip(lower=lower_quantile[col],upper=upper_quantile[col])\n",
    "            )\n",
    "        print(\"clipped\")\n",
    "\n",
    "    # # # df_mean=df.with_columns([df_standardized[c] for c in df_standardized.columns])\n",
    "    # df_mean = standardize_mean(df)\n",
    "    # df_mean = df\n",
    "    \n",
    "    ScOut = f'{OutputDir}/SingleCell/'\n",
    "    if not os.path.exists(ScOut): \n",
    "        os.makedirs(ScOut)\n",
    "    df.write_parquet(f'{ScOut}/{df.select(pl.col(\"Metadata_cmpd_cell_line\")).unique().item()}_mean.parquet')\n",
    "\n",
    "    if make_slices:\n",
    "        slicesOut = f'{OutputDir}/SingleSlice/'\n",
    "        if not os.path.exists(slicesOut): \n",
    "            os.makedirs(slicesOut)\n",
    "        df = generate_slices(df, slicesOut, 'meanstd')\n",
    "    \n",
    "\n",
    "    #Generating the output directories\n",
    "    aggOut = f'{OutputDir}/WellAggregates/'\n",
    "    if not os.path.exists(aggOut): \n",
    "        os.makedirs(aggOut)\n",
    "    \n",
    "\n",
    "    # df_agg_mean = aggregate_mean(df)\n",
    "    # df_agg_mean.write_parquet(f'{aggOut}/{df.select(pl.col(\"Metadata_cmpd_cell_line\")).unique().item()}_MeanAgg_meanstd.parquet')\n",
    "    df_agg_median = aggregate_median(df)\n",
    "    df_agg_median.write_parquet(f'{aggOut}/{df.select(pl.col(\"Metadata_cmpd_cell_line\")).unique().item()}_MedianAgg_meanstd.parquet')\n",
    "    del df_agg_median\n",
    "    # del df_agg_mean\n",
    "    # del df_mean\n",
    "    print_time(\"binned mean data per well\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaEx = pl.read_csv(f'{rootDir}spher_colo52-metadata.csv')\n",
    "metaEx = metaEx.drop(cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>well_id</th><th>image_id</th><th>cp_id</th><th>barcode</th><th>plate_well</th><th>cmpdname</th><th>pert_type</th><th>target</th><th>pathway</th><th>target_type</th><th>cell_line</th></tr><tr><td>str</td><td>i64</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;B02&quot;</td><td>4185</td><td>5532</td><td>&quot;PB000137&quot;</td><td>&quot;PB000137_B02&quot;</td><td>&quot;PD0325901&quot;</td><td>&quot;trt&quot;</td><td>&quot;MEK&quot;</td><td>&quot;MAPK&quot;</td><td>&quot;Targeted&quot;</td><td>&quot;HCT116&quot;</td></tr><tr><td>&quot;B03&quot;</td><td>4185</td><td>5532</td><td>&quot;PB000137&quot;</td><td>&quot;PB000137_B03&quot;</td><td>&quot;Paclitaxel&quot;</td><td>&quot;trt&quot;</td><td>&quot;Autophagy,Micr…</td><td>&quot;Cytoskeletal S…</td><td>&quot;Cytotoxic&quot;</td><td>&quot;HCT116&quot;</td></tr><tr><td>&quot;B04&quot;</td><td>4185</td><td>5532</td><td>&quot;PB000137&quot;</td><td>&quot;PB000137_B04&quot;</td><td>&quot;Olaparib (AZD2…</td><td>&quot;trt&quot;</td><td>&quot;PARP&quot;</td><td>&quot;DNA Damage&quot;</td><td>&quot;Targeted&quot;</td><td>&quot;HCT116&quot;</td></tr><tr><td>&quot;B05&quot;</td><td>4185</td><td>5532</td><td>&quot;PB000137&quot;</td><td>&quot;PB000137_B05&quot;</td><td>&quot;SB216763&quot;</td><td>&quot;trt&quot;</td><td>&quot;GSK-3&quot;</td><td>&quot;PI3K/Akt/mTOR&quot;</td><td>&quot;Targeted&quot;</td><td>&quot;HCT116&quot;</td></tr><tr><td>&quot;B06&quot;</td><td>4185</td><td>5532</td><td>&quot;PB000137&quot;</td><td>&quot;PB000137_B06&quot;</td><td>&quot;Vorinostat (SA…</td><td>&quot;trt&quot;</td><td>&quot;Autophagy,HDAC…</td><td>&quot;Epigenetics&quot;</td><td>&quot;Targeted&quot;</td><td>&quot;HCT116&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 11)\n",
       "┌─────────┬──────────┬───────┬──────────┬───┬──────────────┬─────────────┬─────────────┬───────────┐\n",
       "│ well_id ┆ image_id ┆ cp_id ┆ barcode  ┆ … ┆ target       ┆ pathway     ┆ target_type ┆ cell_line │\n",
       "│ ---     ┆ ---      ┆ ---   ┆ ---      ┆   ┆ ---          ┆ ---         ┆ ---         ┆ ---       │\n",
       "│ str     ┆ i64      ┆ i64   ┆ str      ┆   ┆ str          ┆ str         ┆ str         ┆ str       │\n",
       "╞═════════╪══════════╪═══════╪══════════╪═══╪══════════════╪═════════════╪═════════════╪═══════════╡\n",
       "│ B02     ┆ 4185     ┆ 5532  ┆ PB000137 ┆ … ┆ MEK          ┆ MAPK        ┆ Targeted    ┆ HCT116    │\n",
       "│ B03     ┆ 4185     ┆ 5532  ┆ PB000137 ┆ … ┆ Autophagy,Mi ┆ Cytoskeleta ┆ Cytotoxic   ┆ HCT116    │\n",
       "│         ┆          ┆       ┆          ┆   ┆ crotubule    ┆ l Signaling ┆             ┆           │\n",
       "│         ┆          ┆       ┆          ┆   ┆ Associated   ┆             ┆             ┆           │\n",
       "│ B04     ┆ 4185     ┆ 5532  ┆ PB000137 ┆ … ┆ PARP         ┆ DNA Damage  ┆ Targeted    ┆ HCT116    │\n",
       "│ B05     ┆ 4185     ┆ 5532  ┆ PB000137 ┆ … ┆ GSK-3        ┆ PI3K/Akt/mT ┆ Targeted    ┆ HCT116    │\n",
       "│         ┆          ┆       ┆          ┆   ┆              ┆ OR          ┆             ┆           │\n",
       "│ B06     ┆ 4185     ┆ 5532  ┆ PB000137 ┆ … ┆ Autophagy,HD ┆ Epigenetics ┆ Targeted    ┆ HCT116    │\n",
       "│         ┆          ┆       ┆          ┆   ┆ AC           ┆             ┆             ┆           │\n",
       "└─────────┴──────────┴───────┴──────────┴───┴──────────────┴─────────────┴─────────────┴───────────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metaEx.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadmso = metaEx.filter(pl.col('Compound_ID')=='DMSO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>well_id</th><th>image_id</th><th>cp_id</th><th>barcode</th><th>plate_well</th><th>cmpdname</th><th>pert_type</th><th>target</th><th>pathway</th><th>target_type</th><th>cell_line</th></tr><tr><td>str</td><td>i64</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;B02&quot;</td><td>4185</td><td>5532</td><td>&quot;PB000137&quot;</td><td>&quot;PB000137_B02&quot;</td><td>&quot;PD0325901&quot;</td><td>&quot;trt&quot;</td><td>&quot;MEK&quot;</td><td>&quot;MAPK&quot;</td><td>&quot;Targeted&quot;</td><td>&quot;HCT116&quot;</td></tr><tr><td>&quot;B03&quot;</td><td>4185</td><td>5532</td><td>&quot;PB000137&quot;</td><td>&quot;PB000137_B03&quot;</td><td>&quot;Paclitaxel&quot;</td><td>&quot;trt&quot;</td><td>&quot;Autophagy,Micr…</td><td>&quot;Cytoskeletal S…</td><td>&quot;Cytotoxic&quot;</td><td>&quot;HCT116&quot;</td></tr><tr><td>&quot;B04&quot;</td><td>4185</td><td>5532</td><td>&quot;PB000137&quot;</td><td>&quot;PB000137_B04&quot;</td><td>&quot;Olaparib (AZD2…</td><td>&quot;trt&quot;</td><td>&quot;PARP&quot;</td><td>&quot;DNA Damage&quot;</td><td>&quot;Targeted&quot;</td><td>&quot;HCT116&quot;</td></tr><tr><td>&quot;B05&quot;</td><td>4185</td><td>5532</td><td>&quot;PB000137&quot;</td><td>&quot;PB000137_B05&quot;</td><td>&quot;SB216763&quot;</td><td>&quot;trt&quot;</td><td>&quot;GSK-3&quot;</td><td>&quot;PI3K/Akt/mTOR&quot;</td><td>&quot;Targeted&quot;</td><td>&quot;HCT116&quot;</td></tr><tr><td>&quot;B06&quot;</td><td>4185</td><td>5532</td><td>&quot;PB000137&quot;</td><td>&quot;PB000137_B06&quot;</td><td>&quot;Vorinostat (SA…</td><td>&quot;trt&quot;</td><td>&quot;Autophagy,HDAC…</td><td>&quot;Epigenetics&quot;</td><td>&quot;Targeted&quot;</td><td>&quot;HCT116&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 11)\n",
       "┌─────────┬──────────┬───────┬──────────┬───┬──────────────┬─────────────┬─────────────┬───────────┐\n",
       "│ well_id ┆ image_id ┆ cp_id ┆ barcode  ┆ … ┆ target       ┆ pathway     ┆ target_type ┆ cell_line │\n",
       "│ ---     ┆ ---      ┆ ---   ┆ ---      ┆   ┆ ---          ┆ ---         ┆ ---         ┆ ---       │\n",
       "│ str     ┆ i64      ┆ i64   ┆ str      ┆   ┆ str          ┆ str         ┆ str         ┆ str       │\n",
       "╞═════════╪══════════╪═══════╪══════════╪═══╪══════════════╪═════════════╪═════════════╪═══════════╡\n",
       "│ B02     ┆ 4185     ┆ 5532  ┆ PB000137 ┆ … ┆ MEK          ┆ MAPK        ┆ Targeted    ┆ HCT116    │\n",
       "│ B03     ┆ 4185     ┆ 5532  ┆ PB000137 ┆ … ┆ Autophagy,Mi ┆ Cytoskeleta ┆ Cytotoxic   ┆ HCT116    │\n",
       "│         ┆          ┆       ┆          ┆   ┆ crotubule    ┆ l Signaling ┆             ┆           │\n",
       "│         ┆          ┆       ┆          ┆   ┆ Associated   ┆             ┆             ┆           │\n",
       "│ B04     ┆ 4185     ┆ 5532  ┆ PB000137 ┆ … ┆ PARP         ┆ DNA Damage  ┆ Targeted    ┆ HCT116    │\n",
       "│ B05     ┆ 4185     ┆ 5532  ┆ PB000137 ┆ … ┆ GSK-3        ┆ PI3K/Akt/mT ┆ Targeted    ┆ HCT116    │\n",
       "│         ┆          ┆       ┆          ┆   ┆              ┆ OR          ┆             ┆           │\n",
       "│ B06     ┆ 4185     ┆ 5532  ┆ PB000137 ┆ … ┆ Autophagy,HD ┆ Epigenetics ┆ Targeted    ┆ HCT116    │\n",
       "│         ┆          ┆       ┆          ┆   ┆ AC           ┆             ┆             ┆           │\n",
       "└─────────┴──────────┴───────┴──────────┴───┴──────────────┴─────────────┴─────────────┴───────────┘"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metaEx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HCT116', 'HT29']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metaEx.select(pl.col(['cell_line'])).unique().to_series().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HT29', 'HCT116']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metaEx.select(pl.col(['cell_line'])).unique().to_series().to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ObjectList = ['featICF_nuclei', 'featICF_cells', 'featICF_cytoplasm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Processing\n",
      "/share/data/cellprofiler/automation/results/PB000137/4185/5532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part1\n",
      "processed metadata for 5532\n",
      "/share/data/cellprofiler/automation/results/PB000138/4188/5547\n",
      "part1\n",
      "processed metadata for 5547\n",
      "/share/data/cellprofiler/automation/results/PB000139/4186/5533\n",
      "part1\n",
      "processed metadata for 5533\n",
      "/share/data/cellprofiler/automation/results/PB000140/4189/5573\n",
      "part1\n",
      "processed metadata for 5573\n",
      "['HCT116']\n",
      "['HCT116']\n",
      "dropped 1 rows due to NaNs in column Cytoplasm_AreaShape_FormFactor\n",
      "dropped 3 rows due to NaNs in column Cytoplasm_Correlation_Costes_CONC_HOECHST\n",
      "dropped 1 rows due to NaNs in column Cytoplasm_Correlation_Costes_MITO_HOECHST\n",
      "dropped 25 rows due to NaNs in column Cytoplasm_Neighbors_AngleBetweenNeighbors_Adjacent\n",
      "dropped 4 rows due to NaNs in column Cytoplasm_Neighbors_FirstClosestDistance_Adjacent\n",
      "dropped 36 rows due to NaNs in column Nuclei_Neighbors_AngleBetweenNeighbors_Adjacent\n",
      "dropped 4 rows due to NaNs in column Nuclei_Neighbors_FirstClosestDistance_Adjacent\n",
      "dropped 30 rows due to NaNs in column Cells_AreaShape_Area\n",
      "dropped 11 rows due to NaNs in column Cells_AreaShape_FormFactor\n",
      "dropped 28 rows due to NaNs in column Cells_AreaShape_Zernike_0_0\n",
      "2025-01-15 11:47:48 dropped NaNs\n",
      "2025-01-15 11:52:11 binned mean data per well\n"
     ]
    }
   ],
   "source": [
    "data_processing(metaEx, 'HCT116', ObjectList, OutputDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Processing\n",
      "/share/data/cellprofiler/automation/results/PB000142/4191/5574\n",
      "part1\n",
      "processed metadata for 5574\n",
      "/share/data/cellprofiler/automation/results/PB000139/4186/5533\n",
      "part1\n",
      "processed metadata for 5533\n",
      "/share/data/cellprofiler/automation/results/PB000141/4187/5546\n",
      "part1\n",
      "processed metadata for 5546\n",
      "/share/data/cellprofiler/automation/results/PB000140/4189/5573\n",
      "part1\n",
      "processed metadata for 5573\n",
      "['HT29']\n",
      "['HT29']\n",
      "dropped 1 rows due to NaNs in column Cytoplasm_Correlation_Costes_CONC_HOECHST\n",
      "dropped 26 rows due to NaNs in column Cytoplasm_Neighbors_AngleBetweenNeighbors_Adjacent\n",
      "dropped 2 rows due to NaNs in column Cytoplasm_Neighbors_FirstClosestDistance_Adjacent\n",
      "dropped 53 rows due to NaNs in column Nuclei_Neighbors_AngleBetweenNeighbors_Adjacent\n",
      "dropped 2 rows due to NaNs in column Nuclei_Neighbors_FirstClosestDistance_Adjacent\n",
      "dropped 28 rows due to NaNs in column Cells_AreaShape_Area\n",
      "dropped 20 rows due to NaNs in column Cells_AreaShape_FormFactor\n",
      "dropped 25 rows due to NaNs in column Cells_AreaShape_Zernike_0_0\n",
      "2024-09-11 10:19:45 dropped NaNs\n",
      "2024-09-11 10:20:48 binned mean data per well\n"
     ]
    }
   ],
   "source": [
    "data_processing(metaEx, 'HT29', ObjectList, OutputDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current date and time : \n",
      "2024-09-11 10:20:49\n"
     ]
    }
   ],
   "source": [
    "now = datetime.datetime.now()\n",
    "print ('Current date and time : ')\n",
    "print (now.strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5574"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metaEx.select(pl.col('cp_id')).max().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
