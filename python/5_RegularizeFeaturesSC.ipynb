{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/scratch2-shared/david/colopaint3D/python'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import polars as pl # like pandas, but much faster\n",
    "import polars.selectors as cs\n",
    "import numpy as np\n",
    "import os, shutil, glob\n",
    "from random import randint\n",
    "import re, math\n",
    "import datetime\n",
    "import gc\n",
    "from pathlib import Path\n",
    "\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sourceDir = '/share/data/cellprofiler/automation/results'\n",
    "rootDir = '/home/jovyan/scratch2-shared/david/colopaint3D'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 1)\n",
      "┌───────────────────┐\n",
      "│ feature_names     │\n",
      "│ ---               │\n",
      "│ str               │\n",
      "╞═══════════════════╡\n",
      "│ featICF_nuclei    │\n",
      "│ featICF_cells     │\n",
      "│ featICF_cytoplasm │\n",
      "└───────────────────┘\n"
     ]
    }
   ],
   "source": [
    "OutputDir = 'data/1_FeaturesImages'\n",
    "if not os.path.exists(OutputDir): \n",
    "    os.makedirs(OutputDir)\n",
    "NameContains = ''\n",
    "InputFolders = pl.read_csv('../settings/filemap.csv')\n",
    "print(InputFolders )\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current date and time : \n",
      "2024-10-24 11:51:03\n"
     ]
    }
   ],
   "source": [
    "now = datetime.datetime.now()\n",
    "print ('Current date and time : ')\n",
    "print (now.strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['index','layout_id','cmpd_code', 'solvent','cmpd_conc','cmpd_conc_unit','stock_conc','stock_conc_unit','cmpd_vol', 'cmpd_vol_unit', 'well_vol', 'well_vol_unit', 'article_id','pubchemID', 'smiles', 'inkey', 'clinical_status']\n",
    "\n",
    "use_clipping = False\n",
    "\n",
    "std_mean = True\n",
    "\n",
    "make_slices = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ObjectList = ['featICF_nuclei', 'featICF_cells', 'featICF_cytoplasm']\n",
    "\n",
    "def print_time(msg=None):\n",
    "    now = datetime.datetime.now()\n",
    "    print(now.strftime('%Y-%m-%d %H:%M:%S'),msg or \"\")\n",
    "float_columns=[pl.col(pl.Float32),pl.col(pl.Float64)]\n",
    "\n",
    "def aggregate_mean(df_in):\n",
    "    df_agg = df_in\n",
    "    df_float_columns=set(list(df_agg.select(float_columns).columns))\n",
    "    group_by_columns=['Metadata_PlateWell', 'Metadata_Barcode','Metadata_Well']\n",
    "    other_columns=set(list(df_agg.columns))-df_float_columns-set(group_by_columns)\n",
    "    # # group by mean for all float features, and group by first for all non-float columns (indices and string metadata)\n",
    "    group_by_aggregates=[\n",
    "        *[pl.mean(x) for x in list(df_float_columns)],\n",
    "        *[pl.first(x) for x in list(other_columns)]\n",
    "    ]\n",
    "    df_agg_mean=df_agg.group_by(group_by_columns).agg(group_by_aggregates)\n",
    "    return df_agg_mean\n",
    "\n",
    "def aggregate_median(df_in):\n",
    "    df_agg = df_in\n",
    "    df_float_columns=set(list(df_agg.select(float_columns).columns))\n",
    "    group_by_columns=['Metadata_Barcode','Metadata_Well']\n",
    "    other_columns=set(list(df_agg.columns))-df_float_columns-set(group_by_columns)\n",
    "    group_by_aggregates=[\n",
    "        *[pl.median(x) for x in list(df_float_columns)],\n",
    "        *[pl.first(x) for x in list(other_columns)]\n",
    "    ]\n",
    "    df_agg_median=df_agg.group_by(group_by_columns).agg(group_by_aggregates)\n",
    "    return df_agg_median\n",
    "\n",
    "def standardize_mean(df):\n",
    "    # df = df.with_row_count('index')\n",
    "    df_mean = pl.DataFrame()\n",
    "    for i in range(df.select(pl.col('Metadata_Site')).max().item()):\n",
    "        df_slice = df.filter(pl.col('Metadata_Site')==i)\n",
    "        df_slice_DMSO=df_slice.filter(pl.col('Metadata_cmpd_cmpdname')=='dmso')\n",
    "        assert df_slice_DMSO.shape[0]>0, \"did not find any wells 'treated' with DMSO\"\n",
    "        mu = df_slice_DMSO.select(float_columns).mean()\n",
    "        std = df_slice_DMSO.select(float_columns).std()\n",
    "        # replace 0 with 1 (specifically not clip) to avoid div by zero\n",
    "        std = std.select([pl.col(c).replace({0: 1}, default=pl.col(c)) for c in std.columns])\n",
    "        for i,col in enumerate(std.columns):\n",
    "            if std[col].is_null().any():\n",
    "                raise RuntimeError(f\"some std value in column {col,i} is nan?!\")\n",
    "            if std[col].is_infinite().any():\n",
    "                raise RuntimeError(f\"some std value in column {col,i} is infinite?!\")\n",
    "            if (std[col]==0).any():\n",
    "                raise RuntimeError(f\"unexpected 0 in column {col}\")\n",
    "        print_time(\"calculated DMSO distribution for one slice\")\n",
    "        df_standardized_slice = df_slice.with_columns([(pl.col(c) - mu[c]) / (std[c]+0.01) for c in mu.columns])\n",
    "        found_nan=False\n",
    "        # checking nans:\n",
    "        for i,col in enumerate(mu.columns):\n",
    "            if df_standardized_slice[col].is_null().any():\n",
    "                found_nan=True\n",
    "                print(f\"some value in column {col,i} is nan\")\n",
    "        if found_nan:\n",
    "            raise RuntimeError(\"found nan\")\n",
    "        df_mean_slice=df_slice.with_columns([df_standardized_slice[c] for c in df_standardized_slice.columns])   \n",
    "        df_mean = pl.concat([df_mean, df_mean_slice])\n",
    "    # df_mean\n",
    "    return df_mean\n",
    "\n",
    "def standardize_mean_noslice(df):\n",
    "    df_DMSO=df.filter(pl.col('Metadata_cmpd_cmpdname')=='dmso')\n",
    "    assert df_DMSO.shape[0]>0, \"did not find any wells 'treated' with DMSO\"\n",
    "    mu = df_DMSO.select(float_columns).mean()\n",
    "    std = df_DMSO.select(float_columns).std()\n",
    "    # replace 0 with 1 (specifically not clip) to avoid div by zero\n",
    "    std = std.select([pl.col(c).replace({0: 1}, default=pl.col(c)) for c in std.columns])\n",
    "    for i,col in enumerate(std.columns):\n",
    "        if std[col].is_null().any():\n",
    "            raise RuntimeError(f\"some std value in column {col,i} is nan?!\")\n",
    "        if std[col].is_infinite().any():\n",
    "            raise RuntimeError(f\"some std value in column {col,i} is infinite?!\")\n",
    "        if (std[col]==0).any():\n",
    "            raise RuntimeError(f\"unexpected 0 in column {col}\")\n",
    "    print_time(\"calculated DMSO distribution\")\n",
    "    df_standardized = df.with_columns([(pl.col(c) - mu[c]) / (std[c]+0.01) for c in mu.columns])\n",
    "    found_nan=False\n",
    "    # checking nans:\n",
    "    for i,col in enumerate(mu.columns):\n",
    "        if df_standardized[col].is_null().any():\n",
    "            found_nan=True\n",
    "            print(f\"some value in column {col,i} is nan\")\n",
    "    if found_nan:\n",
    "        raise RuntimeError(\"found nan\")\n",
    "    df_mean=df.with_columns([df_standardized[c] for c in df_standardized.columns])\n",
    "    return df_mean\n",
    "\n",
    "def standardize_mean_perplate(df, arg_slice=True):\n",
    "    plate_list = df.select(pl.col('Metadata_Barcode')).to_series().unique().to_list()\n",
    "    df_mean = pl.DataFrame()\n",
    "    print(plate_list)\n",
    "    for plate in plate_list:\n",
    "        print(f'processing barcode {plate}')\n",
    "        df_set = df.filter(pl.col('Metadata_Barcode')==plate)\n",
    "        if arg_slice:\n",
    "            df_set = standardize_mean(df_set)\n",
    "        else:\n",
    "            df_set = standardize_mean_noslice(df)\n",
    "        df_mean = pl.concat([df_mean, df_set])\n",
    "    return df\n",
    "\n",
    "\n",
    "def normalize(df):\n",
    "    df = df.with_row_count('index')\n",
    "    df_norm = pl.DataFrame()\n",
    "    for i in range(df.select(pl.col('Metadata_Site')).max().item()):\n",
    "        df_slice = df.filter(pl.col('Metadata_Site')==i)\n",
    "        df_slice_DMSO=df_slice.filter(pl.col('Metadata_cmpd_cmpdname')=='dmso')\n",
    "        assert df_slice_DMSO.shape[0]>0, \"did not find any wells 'treated' with DMSO\"\n",
    "        maxi = df_slice_DMSO.select(float_columns).max()\n",
    "        mini = df_slice_DMSO.select(float_columns).min()\n",
    "        # replace 0 with 1 (specifically not clip) to avoid div by zero\n",
    "        maxi = maxi.select([pl.col(c).replace({0: 1}, default=pl.col(c)) for c in maxi.columns])\n",
    "        for i,col in enumerate(mini.columns):\n",
    "            if maxi[col].is_null().any():\n",
    "                raise RuntimeError(f\"some std value in column {col,i} is nan?!\")\n",
    "            if maxi[col].is_infinite().any():\n",
    "                raise RuntimeError(f\"some std value in column {col,i} is infinite?!\")\n",
    "            if (maxi[col]==0).any():\n",
    "                raise RuntimeError(f\"unexpected 0 in column {col}\")\n",
    "        print_time(\"calculated DMSO distribution for one slice\")\n",
    "        df_normalized_slice = df_slice.with_columns([(pl.col(c) - mini[c]) / (maxi[c]) for c in maxi.columns])\n",
    "        found_nan=False\n",
    "        # checking nans:\n",
    "        for i,col in enumerate(maxi.columns):\n",
    "            if df_normalized_slice[col].is_null().any():\n",
    "                found_nan=True\n",
    "                print(f\"some value in column {col,i} is nan\")\n",
    "        if found_nan:\n",
    "            raise RuntimeError(\"found nan\")\n",
    "        df_norm_slice=df_slice.with_columns([df_normalized_slice[c] for c in df_normalized_slice.columns])   \n",
    "        df_norm = pl.concat([df_norm, df_norm_slice])\n",
    "    # df_mean\n",
    "    return df_norm\n",
    "\n",
    "def normalize_perplate(df, arg_slice=True):\n",
    "    if not arg_slice:\n",
    "        print('No-Slice not yet implemented for minmax Normalization. Running per slice. Implementing error soon(tm)')\n",
    "    plate_list = df.select(pl.col('Metadata_Barcode')).to_series().unique().to_list()\n",
    "    print(plate_list)\n",
    "    df_mean = pl.DataFrame()\n",
    "    for plate in plate_list:\n",
    "        print(f'processing barcode {plate}')\n",
    "        df_set = df.filter(pl.col('Metadata_Barcode')==plate)\n",
    "        df_set = normalize(df_set)\n",
    "        df_mean = pl.concat([df_mean, df_set])\n",
    "    return df\n",
    "\n",
    "def generate_slices(df, outdir, arg):\n",
    "    df_sAgg = pl.DataFrame()\n",
    "    for i in range(df.select(pl.col('Metadata_Site')).max().item()):\n",
    "        df_slice = df.filter(pl.col('Metadata_Site')==i)\n",
    "        if arg == 'mean':\n",
    "            df_slice_agg = aggregate_mean(df_slice)\n",
    "            # df_slice_agg.write_parquet(f'{outdir}/{df.select(pl.col(\"Metadata_cmpd_cell_line\")).unique().item()}_Slice{i}MeanAgg.parquet')\n",
    "\n",
    "        elif arg == 'median':\n",
    "            df_slice_agg = aggregate_median(df_slice)\n",
    "            # df_slice_agg.write_parquet(f'{outdir}/{df.select(pl.col(\"Metadata_cmpd_cell_line\")).unique().item()}_Slice{i}MedianAgg.parquet')\n",
    "        else:\n",
    "            print('ERROR no valid metric')\n",
    "        del df_slice\n",
    "        df_sAgg = pl.concat([df_sAgg, df_slice_agg])\n",
    "    # df_sAgg.write_parquet(f'{outdir}/{df.select(pl.col(\"Metadata_cmpd_cell_line\")).unique().item()}_Slices_{arg}Agg.parquet')\n",
    "    return df_sAgg\n",
    "\n",
    "def data_processing(metaEx, cl, ObjectList, OutputDir, sliceLim=13, statmet='minmax', per_plate=False, per_slice=True):\n",
    "    OutputDir = f'{OutputDir}_{statmet}'\n",
    "    if not per_slice:\n",
    "        OutputDir = f'{OutputDir}_noslice'\n",
    "    if per_plate:\n",
    "        OutputDir = f'{OutputDir}_PerPlate'\n",
    "    #Filtering Metadata and generating dirlist\n",
    "    metaEx = metaEx.filter(pl.col('cell_line')==cl)\n",
    "    barcodes = metaEx.select(pl.col('barcode')).unique()\n",
    "    barcodes = barcodes['barcode']\n",
    "    barcodes.to_list()\n",
    "    dirlist = [f'{sourceDir}/{barcode}' for barcode in barcodes]\n",
    "\n",
    "    print('Starting Processing')\n",
    "    df = pl.DataFrame()\n",
    "    for BaseDir in dirlist:\n",
    "        mdf_op = metaEx.filter(pl.col('barcode') == BaseDir.split('/')[-1])\n",
    "        image_id = mdf_op.select(pl.col('image_id')).unique().to_series().to_list()[-1]\n",
    "        cp_id = mdf_op.select(pl.col('cp_id')).unique().to_series().to_list()[-1]\n",
    "        print(f'{BaseDir}/{image_id}/{cp_id}')\n",
    "        BaseDir = f'{BaseDir}/{image_id}/{cp_id}'\n",
    "\n",
    "\n",
    "        # nuclei = pl.read_parquet(BaseDir+f'/{ObjectList[0]}.parquet').add_prefix('Nuclei_').reset_index()\n",
    "        # cytoplasm = pl.read_parquet(BaseDir+f'/{ObjectList[1]}.parquet').add_prefix('Cytoplasm_').reset_index()\n",
    "        # cells = pl.read_parquet(BaseDir+f'/{ObjectList[2]}.parquet').add_prefix('Cells_').reset_index()\n",
    "        # f_df=pl.read_parquet(f)\n",
    "        # f_df=f_df.rename({x:f'{feature_set_name}_{x}' for x in f_df.columns})\n",
    "        \n",
    "\n",
    "        nuclei = pl.read_parquet(BaseDir+f'/{ObjectList[0]}.parquet')\n",
    "        nuclei=nuclei.rename({x:f'Nuclei_{x}' for x in nuclei.columns})\n",
    "        cytoplasm = pl.read_parquet(BaseDir+f'/{ObjectList[1]}.parquet')\n",
    "        cytoplasm=cytoplasm.rename({x:f'Cytoplasm_{x}' for x in cytoplasm.columns})\n",
    "        cells = pl.read_parquet(BaseDir+f'/{ObjectList[2]}.parquet')\n",
    "        cells=cells.rename({x:f'Cells_{x}' for x in cells.columns})\n",
    "        # step 1: Take the mean values of 'multiple nuclei' belonging to one cell\n",
    "\n",
    "        nuclei = nuclei.group_by([\n",
    "            \"Nuclei_Metadata_Barcode\",\"Nuclei_Metadata_Well\",\n",
    "            \"Nuclei_Parent_cells\", 'Nuclei_Metadata_Site'\n",
    "        ]).mean()\n",
    "\n",
    "        df_one = cytoplasm.join(nuclei,\n",
    "                    how='left', \n",
    "                    right_on=['Nuclei_Metadata_Well', 'Nuclei_Metadata_Site', 'Nuclei_Parent_cells', 'Nuclei_Metadata_Barcode'],\n",
    "                    left_on = ['Cytoplasm_Metadata_Well','Cytoplasm_Metadata_Site', 'Cytoplasm_ObjectNumber', 'Cytoplasm_Metadata_Barcode'])\n",
    "                    \n",
    "        df_one = df_one.join(cells, how='left', \n",
    "                        left_on=['Cytoplasm_Metadata_Well','Cytoplasm_Metadata_Site','Cytoplasm_ObjectNumber', 'Cytoplasm_Metadata_Barcode'],\n",
    "                        right_on = ['Cells_Metadata_Well','Cells_Metadata_Site',\"Cells_ObjectNumber\", 'Cells_Metadata_Barcode'])\n",
    "\n",
    "        # print_time(\"initial merging\")\n",
    "        print('part1')\n",
    "\n",
    "        # deduplicate barcode/well/site - renamed cytoplasm_Metadata* to Metadata* and removes nuclei_* etc\n",
    "        unique_metadata_feature_names=['Metadata_Barcode','Metadata_Well','Metadata_Site']\n",
    "        df_one=df_one.rename({f'Cytoplasm_{suffix}':suffix for suffix in unique_metadata_feature_names})\n",
    "        # df = df.filter(pl.col(''))       \n",
    "        # for some reason, the site is parsed as float, even though it really should be an int\n",
    "        if df_one['Metadata_Site'].dtype in [np.dtype('float32'), np.dtype('float64')]:\n",
    "            # sometimes, for some reason, site indices are inf/nan\n",
    "            site_is_nan_mask=np.isnan(df_one['Metadata_Site'])\n",
    "            site_is_inf_mask=np.isinf(df_one['Metadata_Site'])\n",
    "            \n",
    "            try:\n",
    "                num_sites_nan=np.sum(site_is_nan_mask)\n",
    "                num_sites_inf=np.sum(site_is_inf_mask)\n",
    "                assert num_sites_nan==0, f\"found nan site values (n = {num_sites_nan})\"\n",
    "                assert num_sites_inf==0, f\"found inf site values (n = {num_sites_inf})\"\n",
    "            except AssertionError as e:\n",
    "                print(f\"info - this issue was automatically circumvented in the code : {e}\")\n",
    "                df_one=df_one[~(site_is_inf_mask|site_is_nan_mask)]\n",
    "                \n",
    "            num_metadata_site_entries_nonint=np.sum(np.abs(df_one['Metadata_Site']%1.0)>1e-6)\n",
    "            assert num_metadata_site_entries_nonint==0, f\"ERROR : {num_metadata_site_entries_nonint} imaging sites don't have integer indices. that should not be the case, and likely indicates a bug.\"\n",
    "            \n",
    "            #Should use np.round, no? TODO ask patrick. Truncation Errors are annoying.\n",
    "            df_one['Metadata_Site'] = df_one['Metadata_Site'].astype(np.dtype('int32'))\n",
    "        \n",
    "        #Adding Compound Metadata to each row\n",
    "        df_one = df_one.join(mdf_op.rename({x:f\"Metadata_cmpd_{x}\" for x in mdf_op.columns}),left_on='Metadata_Well',right_on='Metadata_cmpd_well_id')\n",
    "        df_one = df_one.filter(pl.col('Metadata_Site')<sliceLim)\n",
    "        df = pl.concat([df, df_one])\n",
    "        plate_name = f'processed metadata for {BaseDir.split(\"/\")[-1]}'\n",
    "        print(plate_name)\n",
    "    df = df.sort(pl.col('Metadata_Site'))\n",
    "    ###Here should be workable to unify by cell line.\n",
    "    df = df.with_columns((pl.col(\"Metadata_Barcode\") + \"_\" + pl.col(\"Metadata_Well\")).alias(\"Metadata_PlateWell\"))\n",
    "    print(df.select(pl.col('Metadata_cmpd_cell_line')).to_series().unique().to_list())\n",
    "    df = df.filter(pl.col('Metadata_cmpd_cell_line')==cl)\n",
    "    print(df.select(pl.col('Metadata_cmpd_cell_line')).to_series().unique().to_list())\n",
    "    ###End\n",
    "    # drop all rows that contain nan\n",
    "    num_rows_before_nan_trim = df.shape[0]\n",
    "    for col in df.select([pl.col(pl.Float32),pl.col(pl.Float64)]).columns:\n",
    "        before_drop=df.shape[0]\n",
    "        df=df.filter(pl.col(col).is_not_null())\n",
    "        after_drop=df.shape[0]\n",
    "\n",
    "        num_values_dropped=before_drop-after_drop\n",
    "        if num_values_dropped>0:\n",
    "           print(f\"dropped {num_values_dropped} rows due to NaNs in column {col}\")\n",
    "\n",
    "    num_rows_after_nan_trim = df.shape[0]\n",
    "    print_time(\"dropped NaNs\")\n",
    "    # Clip outliers\n",
    "    use_clipping = False\n",
    "    if use_clipping:\n",
    "        print('clipping values....')\n",
    "        float_cols = [c for c_name,c_dtype in zip(df.columns,df.dtypes) if \"float\" in str(c_dtype)]\n",
    "        lower_quantile = df.select(float_cols).quantile(0.01)\n",
    "        upper_quantile = df.select(float_cols).quantile(0.99)\n",
    "        print(\"calced quantiles\")\n",
    "        for col in float_cols:\n",
    "            df = df.with_column(\n",
    "                pl.col(col).clip(lower=lower_quantile[col],upper=upper_quantile[col])\n",
    "            )\n",
    "        print(\"clipped\")\n",
    "\n",
    "    # # # df_mean=df.with_columns([df_standardized[c] for c in df_standardized.columns])\n",
    "\n",
    "    \n",
    "    ScOut = f'{OutputDir}/SingleCell/'\n",
    "    if not os.path.exists(ScOut): \n",
    "        os.makedirs(ScOut)\n",
    "    df.write_parquet(f'{ScOut}/{df.select(pl.col(\"Metadata_cmpd_cell_line\")).unique().item()}_nonorm.parquet')\n",
    "    if statmet == 'meanstd':\n",
    "        if per_plate:\n",
    "            df2 = standardize_mean_perplate(df, arg_slice=per_slice)\n",
    "        else:\n",
    "            if per_slice:\n",
    "                df2 = standardize_mean(df)\n",
    "            else:\n",
    "                df2 = standardize_mean_noslice(df)\n",
    "    elif statmet == 'minmax':\n",
    "        if per_plate:\n",
    "            df2 = standardize_mean_perplate(df, arg_slice=per_slice)\n",
    "        else:\n",
    "            if per_slice:\n",
    "                df2 = standardize_mean(df)\n",
    "            else:\n",
    "                df2 = standardize_mean_noslice(df)\n",
    "    else:\n",
    "        print('error: unimplemented metric, proceeding without norm/std')\n",
    "    df2.write_parquet(f'{ScOut}/{df2.select(pl.col(\"Metadata_cmpd_cell_line\")).unique().item()}.parquet')\n",
    "    del df2\n",
    "    # if make_slices:\n",
    "    slicesOut = f'{OutputDir}/SingleSlice/'\n",
    "    arg_slice = 'median'\n",
    "    if not os.path.exists(slicesOut): \n",
    "        os.makedirs(slicesOut)\n",
    "    df = generate_slices(df, slicesOut, arg_slice)\n",
    "    print(f'Standardizing per pate:    {per_plate}')\n",
    "    if statmet == 'meanstd':\n",
    "        print('Standardizing by MeanSTD on a per slice basis only')\n",
    "        if per_plate:\n",
    "            print('standardizing per plate and per slice')\n",
    "            df = standardize_mean_perplate(df, per_slice)\n",
    "        else:\n",
    "            if per_slice:\n",
    "                df = standardize_mean(df)\n",
    "            else:\n",
    "                df = standardize_mean_noslice(df)\n",
    "    if statmet == 'minmax':\n",
    "        print('Normalizing to unit on a per slice only')\n",
    "        if per_plate:\n",
    "            print('normalizing to unit per plate and per slice')\n",
    "            df = normalize_perplate(df, per_slice)\n",
    "        else:\n",
    "            if per_slice:\n",
    "                df = normalize(df)\n",
    "            else:\n",
    "                print('No bulk implemented yet. Running per slice. Error TBI soon(tm)')\n",
    "                df = normalize(df)\n",
    "    df.write_parquet(f'{slicesOut}/{df.select(pl.col(\"Metadata_cmpd_cell_line\")).unique().item()}_Slices_{arg_slice}Agg.parquet')\n",
    "    # df_mean = df\n",
    "    \n",
    "\n",
    "    #Generating the output directories\n",
    "    aggOut = f'{OutputDir}/WellAggregates/'\n",
    "    if not os.path.exists(aggOut): \n",
    "        os.makedirs(aggOut)\n",
    "    \n",
    "\n",
    "    # df_agg_mean = aggregate_mean(df)\n",
    "    # df_agg_mean.write_parquet(f'{aggOut}/{df.select(pl.col(\"Metadata_cmpd_cell_line\")).unique().item()}_MeanAgg_meanstd.parquet')\n",
    "    df_agg_median = aggregate_median(df)\n",
    "    df_agg_median.write_parquet(f'{aggOut}/{df.select(pl.col(\"Metadata_cmpd_cell_line\")).unique().item()}_MedianAgg_meanstd.parquet')\n",
    "    del df_agg_median\n",
    "    # del df_agg_mean\n",
    "    # del df_mean\n",
    "    print_time(\"binned mean data per well\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaEx = pl.read_csv(f'{rootDir}/settings/spher-colo52-v1-import-inputFiles-and-PLAIDresults.csv')\n",
    "metaEx = metaEx.drop(cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>well_id</th><th>image_id</th><th>cp_id</th><th>barcode</th><th>plate_well</th><th>cmpdname</th><th>pert_type</th><th>target</th><th>pathway</th><th>target_type</th><th>cell_line</th></tr><tr><td>str</td><td>i64</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;B02&quot;</td><td>4185</td><td>5532</td><td>&quot;PB000137&quot;</td><td>&quot;PB000137_B02&quot;</td><td>&quot;PD0325901&quot;</td><td>&quot;trt&quot;</td><td>&quot;MEK&quot;</td><td>&quot;MAPK&quot;</td><td>&quot;Targeted&quot;</td><td>&quot;HCT116&quot;</td></tr><tr><td>&quot;B03&quot;</td><td>4185</td><td>5532</td><td>&quot;PB000137&quot;</td><td>&quot;PB000137_B03&quot;</td><td>&quot;Paclitaxel&quot;</td><td>&quot;trt&quot;</td><td>&quot;Autophagy,Microtubule Associat…</td><td>&quot;Cytoskeletal Signaling&quot;</td><td>&quot;Cytotoxic&quot;</td><td>&quot;HCT116&quot;</td></tr><tr><td>&quot;B04&quot;</td><td>4185</td><td>5532</td><td>&quot;PB000137&quot;</td><td>&quot;PB000137_B04&quot;</td><td>&quot;Olaparib (AZD2281, Ku-0059436)&quot;</td><td>&quot;trt&quot;</td><td>&quot;PARP&quot;</td><td>&quot;DNA Damage&quot;</td><td>&quot;Targeted&quot;</td><td>&quot;HCT116&quot;</td></tr><tr><td>&quot;B05&quot;</td><td>4185</td><td>5532</td><td>&quot;PB000137&quot;</td><td>&quot;PB000137_B05&quot;</td><td>&quot;SB216763&quot;</td><td>&quot;trt&quot;</td><td>&quot;GSK-3&quot;</td><td>&quot;PI3K/Akt/mTOR&quot;</td><td>&quot;Targeted&quot;</td><td>&quot;HCT116&quot;</td></tr><tr><td>&quot;B06&quot;</td><td>4185</td><td>5532</td><td>&quot;PB000137&quot;</td><td>&quot;PB000137_B06&quot;</td><td>&quot;Vorinostat (SAHA, MK0683)&quot;</td><td>&quot;trt&quot;</td><td>&quot;Autophagy,HDAC&quot;</td><td>&quot;Epigenetics&quot;</td><td>&quot;Targeted&quot;</td><td>&quot;HCT116&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 11)\n",
       "┌─────────┬──────────┬───────┬──────────┬───┬──────────────┬─────────────┬─────────────┬───────────┐\n",
       "│ well_id ┆ image_id ┆ cp_id ┆ barcode  ┆ … ┆ target       ┆ pathway     ┆ target_type ┆ cell_line │\n",
       "│ ---     ┆ ---      ┆ ---   ┆ ---      ┆   ┆ ---          ┆ ---         ┆ ---         ┆ ---       │\n",
       "│ str     ┆ i64      ┆ i64   ┆ str      ┆   ┆ str          ┆ str         ┆ str         ┆ str       │\n",
       "╞═════════╪══════════╪═══════╪══════════╪═══╪══════════════╪═════════════╪═════════════╪═══════════╡\n",
       "│ B02     ┆ 4185     ┆ 5532  ┆ PB000137 ┆ … ┆ MEK          ┆ MAPK        ┆ Targeted    ┆ HCT116    │\n",
       "│ B03     ┆ 4185     ┆ 5532  ┆ PB000137 ┆ … ┆ Autophagy,Mi ┆ Cytoskeleta ┆ Cytotoxic   ┆ HCT116    │\n",
       "│         ┆          ┆       ┆          ┆   ┆ crotubule    ┆ l Signaling ┆             ┆           │\n",
       "│         ┆          ┆       ┆          ┆   ┆ Associat…    ┆             ┆             ┆           │\n",
       "│ B04     ┆ 4185     ┆ 5532  ┆ PB000137 ┆ … ┆ PARP         ┆ DNA Damage  ┆ Targeted    ┆ HCT116    │\n",
       "│ B05     ┆ 4185     ┆ 5532  ┆ PB000137 ┆ … ┆ GSK-3        ┆ PI3K/Akt/mT ┆ Targeted    ┆ HCT116    │\n",
       "│         ┆          ┆       ┆          ┆   ┆              ┆ OR          ┆             ┆           │\n",
       "│ B06     ┆ 4185     ┆ 5532  ┆ PB000137 ┆ … ┆ Autophagy,HD ┆ Epigenetics ┆ Targeted    ┆ HCT116    │\n",
       "│         ┆          ┆       ┆          ┆   ┆ AC           ┆             ┆             ┆           │\n",
       "└─────────┴──────────┴───────┴──────────┴───┴──────────────┴─────────────┴─────────────┴───────────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metaEx.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metaEx.select(pl.col(['cell_line'])).unique().to_series().to_list()\n",
    "# metaEx.select(pl.col(['cell_line'])).unique().to_series().to_list()\n",
    "# metaEx.select(pl.col(['barcode'])).unique().to_series().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ObjectList = ['featICF_nuclei', 'featICF_cells', 'featICF_cytoplasm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Processing\n",
      "/share/data/cellprofiler/automation/results/PB000140/4189/5573\n",
      "part1\n",
      "processed metadata for 5573\n",
      "/share/data/cellprofiler/automation/results/PB000137/4185/5532\n",
      "part1\n",
      "processed metadata for 5532\n",
      "/share/data/cellprofiler/automation/results/PB000139/4186/5533\n",
      "part1\n",
      "processed metadata for 5533\n",
      "/share/data/cellprofiler/automation/results/PB000138/4188/5547\n",
      "part1\n",
      "processed metadata for 5547\n",
      "['HCT116']\n",
      "['HCT116']\n",
      "dropped 1 rows due to NaNs in column Cytoplasm_AreaShape_FormFactor\n",
      "dropped 3 rows due to NaNs in column Cytoplasm_Correlation_Costes_CONC_HOECHST\n",
      "dropped 1 rows due to NaNs in column Cytoplasm_Correlation_Costes_MITO_HOECHST\n",
      "dropped 25 rows due to NaNs in column Cytoplasm_Neighbors_AngleBetweenNeighbors_Adjacent\n",
      "dropped 4 rows due to NaNs in column Cytoplasm_Neighbors_FirstClosestDistance_Adjacent\n",
      "dropped 36 rows due to NaNs in column Nuclei_Neighbors_AngleBetweenNeighbors_Adjacent\n",
      "dropped 4 rows due to NaNs in column Nuclei_Neighbors_FirstClosestDistance_Adjacent\n",
      "dropped 30 rows due to NaNs in column Cells_AreaShape_Area\n",
      "dropped 11 rows due to NaNs in column Cells_AreaShape_FormFactor\n",
      "dropped 28 rows due to NaNs in column Cells_AreaShape_Zernike_0_0\n",
      "2024-10-24 11:53:30 dropped NaNs\n",
      "['PB000139', 'PB000138', 'PB000140', 'PB000137']\n",
      "processing barcode PB000139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330543/2108374218.py:43: DeprecationWarning: The `default` parameter for `replace` is deprecated. Use `replace_strict` instead to set a default while replacing values.\n",
      "  std = std.select([pl.col(c).replace({0: 1}, default=pl.col(c)) for c in std.columns])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-24 11:54:13 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:54:13 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:54:14 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:54:15 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:54:15 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:54:16 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:54:16 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:54:17 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:54:18 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:54:18 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:54:19 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:54:20 calculated DMSO distribution for one slice\n",
      "processing barcode PB000138\n",
      "2024-10-24 11:54:21 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:54:21 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:54:22 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:54:23 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:54:23 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:54:24 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:54:25 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:54:25 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:54:26 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:54:27 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:54:28 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:54:28 calculated DMSO distribution for one slice\n",
      "processing barcode PB000140\n",
      "2024-10-24 11:54:29 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:54:30 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:54:31 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:54:31 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:54:32 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:54:33 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:54:33 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:54:34 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:54:35 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:54:35 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:54:36 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:54:36 calculated DMSO distribution for one slice\n",
      "processing barcode PB000137\n",
      "2024-10-24 11:54:39 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:54:39 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:54:40 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:54:41 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:54:42 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:54:42 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:54:43 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:54:44 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:54:45 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:54:46 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:54:46 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:54:47 calculated DMSO distribution for one slice\n",
      "Standardizing per pate:    True\n",
      "Standardizing by MeanSTD on a per slice basis only\n",
      "standardizing per plate and per slice\n",
      "['PB000138', 'PB000139', 'PB000140', 'PB000137']\n",
      "processing barcode PB000138\n",
      "2024-10-24 11:55:37 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:55:38 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:55:38 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:55:39 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:55:40 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:55:40 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:55:41 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:55:41 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:55:42 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:55:43 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:55:43 calculated DMSO distribution for one slice\n",
      "processing barcode PB000139\n",
      "2024-10-24 11:55:44 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:55:44 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:55:45 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:55:46 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:55:46 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:55:47 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:55:47 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:55:48 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:55:49 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:55:49 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:55:50 calculated DMSO distribution for one slice\n",
      "processing barcode PB000140\n",
      "2024-10-24 11:55:51 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:55:51 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:55:52 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:55:52 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:55:53 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:55:53 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:55:54 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:55:55 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:55:55 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:55:56 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:55:56 calculated DMSO distribution for one slice\n",
      "processing barcode PB000137\n",
      "2024-10-24 11:55:57 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:55:58 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:55:58 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:55:59 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:55:59 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:56:00 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:56:00 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:56:01 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:56:02 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:56:02 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:56:03 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:56:07 binned mean data per well\n"
     ]
    }
   ],
   "source": [
    "data_processing(metaEx, 'HCT116', ObjectList, OutputDir, statmet='meanstd', per_plate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Processing\n",
      "/share/data/cellprofiler/automation/results/PB000139/4186/5533\n",
      "part1\n",
      "processed metadata for 5533\n",
      "/share/data/cellprofiler/automation/results/PB000137/4185/5532\n",
      "part1\n",
      "processed metadata for 5532\n",
      "/share/data/cellprofiler/automation/results/PB000140/4189/5573\n",
      "part1\n",
      "processed metadata for 5573\n",
      "/share/data/cellprofiler/automation/results/PB000138/4188/5547\n",
      "part1\n",
      "processed metadata for 5547\n",
      "['HCT116']\n",
      "['HCT116']\n",
      "dropped 1 rows due to NaNs in column Cytoplasm_AreaShape_FormFactor\n",
      "dropped 3 rows due to NaNs in column Cytoplasm_Correlation_Costes_CONC_HOECHST\n",
      "dropped 1 rows due to NaNs in column Cytoplasm_Correlation_Costes_MITO_HOECHST\n",
      "dropped 25 rows due to NaNs in column Cytoplasm_Neighbors_AngleBetweenNeighbors_Adjacent\n",
      "dropped 4 rows due to NaNs in column Cytoplasm_Neighbors_FirstClosestDistance_Adjacent\n",
      "dropped 36 rows due to NaNs in column Nuclei_Neighbors_AngleBetweenNeighbors_Adjacent\n",
      "dropped 4 rows due to NaNs in column Nuclei_Neighbors_FirstClosestDistance_Adjacent\n",
      "dropped 30 rows due to NaNs in column Cells_AreaShape_Area\n",
      "dropped 11 rows due to NaNs in column Cells_AreaShape_FormFactor\n",
      "dropped 28 rows due to NaNs in column Cells_AreaShape_Zernike_0_0\n",
      "2024-10-24 11:58:48 dropped NaNs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330543/2108374218.py:43: DeprecationWarning: The `default` parameter for `replace` is deprecated. Use `replace_strict` instead to set a default while replacing values.\n",
      "  std = std.select([pl.col(c).replace({0: 1}, default=pl.col(c)) for c in std.columns])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-24 11:59:31 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:59:32 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:59:32 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:59:33 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:59:34 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:59:35 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:59:35 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:59:36 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:59:37 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:59:38 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:59:39 calculated DMSO distribution for one slice\n",
      "2024-10-24 11:59:40 calculated DMSO distribution for one slice\n",
      "Standardizing per pate:    False\n",
      "Standardizing by MeanSTD on a per slice basis only\n",
      "2024-10-24 12:01:00 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:01:00 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:01:01 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:01:02 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:01:02 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:01:03 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:01:04 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:01:04 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:01:05 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:01:06 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:01:06 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:01:11 binned mean data per well\n"
     ]
    }
   ],
   "source": [
    "data_processing(metaEx, 'HCT116', ObjectList, OutputDir, statmet='meanstd', per_plate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Processing\n",
      "/share/data/cellprofiler/automation/results/PB000139/4186/5533\n",
      "part1\n",
      "processed metadata for 5533\n",
      "/share/data/cellprofiler/automation/results/PB000141/4187/5546\n",
      "part1\n",
      "processed metadata for 5546\n",
      "/share/data/cellprofiler/automation/results/PB000142/4191/5574\n",
      "part1\n",
      "processed metadata for 5574\n",
      "/share/data/cellprofiler/automation/results/PB000140/4189/5573\n",
      "part1\n",
      "processed metadata for 5573\n",
      "['HT29']\n",
      "['HT29']\n",
      "dropped 1 rows due to NaNs in column Cytoplasm_Correlation_Costes_CONC_HOECHST\n",
      "dropped 26 rows due to NaNs in column Cytoplasm_Neighbors_AngleBetweenNeighbors_Adjacent\n",
      "dropped 2 rows due to NaNs in column Cytoplasm_Neighbors_FirstClosestDistance_Adjacent\n",
      "dropped 53 rows due to NaNs in column Nuclei_Neighbors_AngleBetweenNeighbors_Adjacent\n",
      "dropped 2 rows due to NaNs in column Nuclei_Neighbors_FirstClosestDistance_Adjacent\n",
      "dropped 28 rows due to NaNs in column Cells_AreaShape_Area\n",
      "dropped 20 rows due to NaNs in column Cells_AreaShape_FormFactor\n",
      "dropped 25 rows due to NaNs in column Cells_AreaShape_Zernike_0_0\n",
      "2024-10-24 12:03:36 dropped NaNs\n",
      "['PB000140', 'PB000142', 'PB000141', 'PB000139']\n",
      "processing barcode PB000140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330543/2108374218.py:43: DeprecationWarning: The `default` parameter for `replace` is deprecated. Use `replace_strict` instead to set a default while replacing values.\n",
      "  std = std.select([pl.col(c).replace({0: 1}, default=pl.col(c)) for c in std.columns])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-24 12:04:01 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:04:02 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:04:02 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:04:03 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:04:04 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:04:04 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:04:05 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:04:06 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:04:06 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:04:07 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:04:08 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:04:08 calculated DMSO distribution for one slice\n",
      "processing barcode PB000142\n",
      "2024-10-24 12:04:09 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:04:10 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:04:10 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:04:11 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:04:12 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:04:12 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:04:13 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:04:14 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:04:14 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:04:15 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:04:16 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:04:16 calculated DMSO distribution for one slice\n",
      "processing barcode PB000141\n",
      "2024-10-24 12:04:17 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:04:18 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:04:19 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:04:19 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:04:20 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:04:21 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:04:21 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:04:22 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:04:23 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:04:23 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:04:24 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:04:25 calculated DMSO distribution for one slice\n",
      "processing barcode PB000139\n",
      "2024-10-24 12:04:26 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:04:26 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:04:27 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:04:27 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:04:28 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:04:29 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:04:29 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:04:30 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:04:31 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:04:31 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:04:32 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:04:32 calculated DMSO distribution for one slice\n",
      "Standardizing per pate:    True\n",
      "Standardizing by MeanSTD on a per slice basis only\n",
      "standardizing per plate and per slice\n",
      "['PB000141', 'PB000140', 'PB000142', 'PB000139']\n",
      "processing barcode PB000141\n",
      "2024-10-24 12:05:03 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:05:04 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:05:05 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:05:05 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:05:06 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:05:06 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:05:07 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:05:07 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:05:08 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:05:09 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:05:09 calculated DMSO distribution for one slice\n",
      "processing barcode PB000140\n",
      "2024-10-24 12:05:10 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:05:11 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:05:11 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:05:12 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:05:12 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:05:13 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:05:14 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:05:14 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:05:15 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:05:15 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:05:16 calculated DMSO distribution for one slice\n",
      "processing barcode PB000142\n",
      "2024-10-24 12:05:17 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:05:18 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:05:18 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:05:19 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:05:19 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:05:20 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:05:21 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:05:21 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:05:22 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:05:22 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:05:23 calculated DMSO distribution for one slice\n",
      "processing barcode PB000139\n",
      "2024-10-24 12:05:24 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:05:24 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:05:25 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:05:25 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:05:26 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:05:27 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:05:27 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:05:28 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:05:28 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:05:29 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:05:30 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:05:34 binned mean data per well\n"
     ]
    }
   ],
   "source": [
    "data_processing(metaEx, 'HT29', ObjectList, OutputDir, statmet='meanstd', per_plate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Processing\n",
      "/share/data/cellprofiler/automation/results/PB000142/4191/5574\n",
      "part1\n",
      "processed metadata for 5574\n",
      "/share/data/cellprofiler/automation/results/PB000141/4187/5546\n",
      "part1\n",
      "processed metadata for 5546\n",
      "/share/data/cellprofiler/automation/results/PB000139/4186/5533\n",
      "part1\n",
      "processed metadata for 5533\n",
      "/share/data/cellprofiler/automation/results/PB000140/4189/5573\n",
      "part1\n",
      "processed metadata for 5573\n",
      "['HT29']\n",
      "['HT29']\n",
      "dropped 1 rows due to NaNs in column Cytoplasm_Correlation_Costes_CONC_HOECHST\n",
      "dropped 26 rows due to NaNs in column Cytoplasm_Neighbors_AngleBetweenNeighbors_Adjacent\n",
      "dropped 2 rows due to NaNs in column Cytoplasm_Neighbors_FirstClosestDistance_Adjacent\n",
      "dropped 53 rows due to NaNs in column Nuclei_Neighbors_AngleBetweenNeighbors_Adjacent\n",
      "dropped 2 rows due to NaNs in column Nuclei_Neighbors_FirstClosestDistance_Adjacent\n",
      "dropped 28 rows due to NaNs in column Cells_AreaShape_Area\n",
      "dropped 20 rows due to NaNs in column Cells_AreaShape_FormFactor\n",
      "dropped 25 rows due to NaNs in column Cells_AreaShape_Zernike_0_0\n",
      "2024-10-24 12:07:55 dropped NaNs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330543/2108374218.py:43: DeprecationWarning: The `default` parameter for `replace` is deprecated. Use `replace_strict` instead to set a default while replacing values.\n",
      "  std = std.select([pl.col(c).replace({0: 1}, default=pl.col(c)) for c in std.columns])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-24 12:08:19 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:08:19 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:08:20 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:08:21 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:08:21 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:08:22 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:08:23 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:08:23 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:08:24 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:08:25 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:08:26 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:08:26 calculated DMSO distribution for one slice\n",
      "Standardizing per pate:    False\n",
      "Standardizing by MeanSTD on a per slice basis only\n",
      "2024-10-24 12:09:08 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:09:08 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:09:09 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:09:10 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:09:10 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:09:11 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:09:12 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:09:12 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:09:13 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:09:13 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:09:14 calculated DMSO distribution for one slice\n",
      "2024-10-24 12:09:19 binned mean data per well\n"
     ]
    }
   ],
   "source": [
    "data_processing(metaEx, 'HT29', ObjectList, OutputDir, statmet='meanstd', per_plate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Processing\n",
      "/share/data/cellprofiler/automation/results/PB000137/4185/5532\n",
      "part1\n",
      "processed metadata for 5532\n",
      "/share/data/cellprofiler/automation/results/PB000140/4189/5573\n",
      "part1\n",
      "processed metadata for 5573\n",
      "/share/data/cellprofiler/automation/results/PB000138/4188/5547\n",
      "part1\n",
      "processed metadata for 5547\n",
      "/share/data/cellprofiler/automation/results/PB000139/4186/5533\n",
      "part1\n",
      "processed metadata for 5533\n",
      "['HCT116']\n",
      "['HCT116']\n",
      "dropped 1 rows due to NaNs in column Cytoplasm_AreaShape_FormFactor\n",
      "dropped 3 rows due to NaNs in column Cytoplasm_Correlation_Costes_CONC_HOECHST\n",
      "dropped 1 rows due to NaNs in column Cytoplasm_Correlation_Costes_MITO_HOECHST\n",
      "dropped 25 rows due to NaNs in column Cytoplasm_Neighbors_AngleBetweenNeighbors_Adjacent\n",
      "dropped 4 rows due to NaNs in column Cytoplasm_Neighbors_FirstClosestDistance_Adjacent\n",
      "dropped 36 rows due to NaNs in column Nuclei_Neighbors_AngleBetweenNeighbors_Adjacent\n",
      "dropped 4 rows due to NaNs in column Nuclei_Neighbors_FirstClosestDistance_Adjacent\n",
      "dropped 30 rows due to NaNs in column Cells_AreaShape_Area\n",
      "dropped 11 rows due to NaNs in column Cells_AreaShape_FormFactor\n",
      "dropped 28 rows due to NaNs in column Cells_AreaShape_Zernike_0_0\n",
      "2024-10-24 13:04:40 dropped NaNs\n",
      "['PB000139', 'PB000138', 'PB000137', 'PB000140']\n",
      "processing barcode PB000139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_330543/2108374218.py:72: DeprecationWarning: The `default` parameter for `replace` is deprecated. Use `replace_strict` instead to set a default while replacing values.\n",
      "  std = std.select([pl.col(c).replace({0: 1}, default=pl.col(c)) for c in std.columns])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute '_df'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdata_processing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetaEx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHCT116\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mObjectList\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOutputDir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatmet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmeanstd\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mper_plate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mper_slice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 289\u001b[0m, in \u001b[0;36mdata_processing\u001b[0;34m(metaEx, cl, ObjectList, OutputDir, sliceLim, statmet, per_plate, per_slice)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m statmet \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeanstd\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m per_plate:\n\u001b[0;32m--> 289\u001b[0m         df2 \u001b[38;5;241m=\u001b[39m \u001b[43mstandardize_mean_perplate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg_slice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mper_slice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    291\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m per_slice:\n",
      "Cell \u001b[0;32mIn[6], line 92\u001b[0m, in \u001b[0;36mstandardize_mean_perplate\u001b[0;34m(df, arg_slice)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     91\u001b[0m         df_set \u001b[38;5;241m=\u001b[39m standardize_mean_noslice(df)\n\u001b[0;32m---> 92\u001b[0m     df_mean \u001b[38;5;241m=\u001b[39m \u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_set\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/polars/functions/eager.py:185\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(items, how, rechunk, parallel)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(first, pl\u001b[38;5;241m.\u001b[39mDataFrame):\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m how \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvertical\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 185\u001b[0m         out \u001b[38;5;241m=\u001b[39m wrap_df(\u001b[43mplr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43melems\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m how \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvertical_relaxed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    187\u001b[0m         out \u001b[38;5;241m=\u001b[39m wrap_ldf(\n\u001b[1;32m    188\u001b[0m             plr\u001b[38;5;241m.\u001b[39mconcat_lf(\n\u001b[1;32m    189\u001b[0m                 [df\u001b[38;5;241m.\u001b[39mlazy() \u001b[38;5;28;01mfor\u001b[39;00m df \u001b[38;5;129;01min\u001b[39;00m elems],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    193\u001b[0m             )\n\u001b[1;32m    194\u001b[0m         )\u001b[38;5;241m.\u001b[39mcollect(no_optimization\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute '_df'"
     ]
    }
   ],
   "source": [
    "data_processing(metaEx, 'HCT116', ObjectList, OutputDir, statmet='meanstd', per_plate=True, per_slice=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processing(metaEx, 'HT29', ObjectList, OutputDir, statmet='meanstd', per_plate=True, per_slice=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current date and time : \n",
      "2024-10-24 12:09:19\n"
     ]
    }
   ],
   "source": [
    "now = datetime.datetime.now()\n",
    "print ('Current date and time : ')\n",
    "print (now.strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5574"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metaEx.select(pl.col('cp_id')).max().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
