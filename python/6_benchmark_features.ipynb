{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colo2d_path = \"path_to_feature_set_1.parquet\"\n",
    "colo3d_path = \"path_to_feature_set_2.parquet\"\n",
    "meta_ex = \"path_to_ground_truth.parquet\"\n",
    "\n",
    "\n",
    "features_1 = pl.read_parquet(colo2d_path).to_numpy()\n",
    "features_2 = pl.read_parquet(colo3d_path).to_numpy()\n",
    "ground_truth = pl.read_parquet(meta_ex).to_numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_knn(features, labels, test_size=0.3, k=5):\n",
    "    \"\"\"\n",
    "    Benchmark features using KNN classification against ground truth.\n",
    "\n",
    "    Args:\n",
    "        features (numpy.ndarray): Feature matrix.\n",
    "        labels (numpy.ndarray): Ground truth labels.\n",
    "        test_size (float): Proportion of data for testing.\n",
    "        k (int): Number of neighbors for KNN.\n",
    "\n",
    "    Returns:\n",
    "        dict: Classification metrics including F1 score and AUC.\n",
    "    \"\"\"\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=test_size, random_state=42)\n",
    "    \n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "\n",
    "    y_pred = knn.predict(X_test)\n",
    "    y_proba = knn.predict_proba(X_test)[:, 1] if len(set(labels)) == 2 else None  # Probability for binary classification\n",
    "    \n",
    "\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    auc = roc_auc_score(y_test, y_proba) if y_proba is not None else None\n",
    "\n",
    "    return {\n",
    "        \"classification_report\": report,\n",
    "        \"auc\": auc,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_1 = benchmark_knn(features_1, ground_truth)\n",
    "\n",
    "results_2 = benchmark_knn(features_2, ground_truth)\n",
    "\n",
    "\n",
    "print(\"colo2D Results:\")\n",
    "print(\"Classification Report:\", results_1[\"classification_report\"])\n",
    "if results_1[\"auc\"] is not None:\n",
    "    print(\"AUC:\", results_1[\"auc\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"colo3D Results:\")\n",
    "print(\"Classification Report:\", results_2[\"classification_report\"])\n",
    "if results_2[\"auc\"] is not None:\n",
    "    print(\"AUC:\", results_2[\"auc\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
