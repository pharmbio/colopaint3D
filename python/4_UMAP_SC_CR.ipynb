{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-24 14:02:56.850593: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/scratch2-shared/david/colopaint3D/python'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# import pandas as pd \n",
    "import polars as pl\n",
    "# import scanpy as sc\n",
    "import numpy as np\n",
    "import typing as tp\n",
    "import re\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "# from sklearn.cross_decomposition import PLSCanonical, PLSRegression, CCA\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.model_selection import cross_validate, cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "from matplotlib.patches import Ellipse\n",
    "import matplotlib.transforms as transforms\n",
    "%matplotlib inline\n",
    "import os, shutil, glob\n",
    "import seaborn as sns; sns.set_style(\"white\")\n",
    "import umap as umap\n",
    "# import pacmap as umap\n",
    "# import hdbscan as hdb\n",
    "\n",
    "# import plotnine as gg\n",
    "# from cytominer_eval import evaluate\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "figformat = 'pdf'\n",
    "dpi = 300\n",
    "statarg = 'single'\n",
    "OutputDir = f'./data/2_PCAUMAP'\n",
    "if not os.path.exists(OutputDir): \n",
    "    os.makedirs(OutputDir)\n",
    "feat_base = './data/1_FeaturesImages_meanstd_PerPlate'\n",
    "# feat_agg = '/share/data/analyses/christa/colopaint3D/spher_colo52_v1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = ['SingleCell/HCT116_nonorm', 'SingleCell/HCT116']\n",
    "\n",
    "statmet = 'SingleCell'\n",
    "\n",
    "statmets = ['SingleCell', 'Aggregates']\n",
    "\n",
    "dropcols = ['Nuclei_Location_Center_X',\n",
    "            'Nuclei_Location_Center_Y',\n",
    "            'Location',\n",
    "            'ImageNumber_',\n",
    "            'Parent',\n",
    "            'Children',\n",
    "            '_ObjectNumber',\n",
    "            '_Object_Number',\n",
    "            '_Y',\n",
    "            '_X' \n",
    "            ]\n",
    "\n",
    "\n",
    "cons = ['pos_con', 'neg_con']\n",
    "nodmso = ['trt']\n",
    "wdmso = ['pos_con']\n",
    "float_columns=[pl.col(pl.Float32),pl.col(pl.Float64)]\n",
    "str_columns = [pl.col(pl.String)]\n",
    "str_columns = [pl.col(pl.Int64),pl.col(pl.Int32)]\n",
    "feat_sc = f'{feat_base}/{statmet}'\n",
    "ignore_labels = ['water','water+','flup','dmso']\n",
    "frac_wells = 0.15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = {'MAPK': (0.12156862745098039, 0.4666666666666667, 0.7058823529411765),\n",
    "        'Cell Cycle': (0.6823529411764706, 0.7803921568627451, 0.9098039215686274),\n",
    "        'DNA Damage': (1.0, 0.4980392156862745, 0.054901960784313725),\n",
    "        'PI3K/Akt/mTOR': (1.0, 0.7333333333333333, 0.47058823529411764),\n",
    "        'Epigenetics': (0.17254901960784313, 0.6274509803921569, 0.17254901960784313),\n",
    "        'Stem Cells & Wnt': (0.596078431372549,\n",
    "        0.8745098039215686,\n",
    "        0.5411764705882353),\n",
    "        'Angiogenesis': (0.8392156862745098, 0.15294117647058825, 0.1568627450980392),\n",
    "        'Protein Tyrosine Kinase': (1.0, 0.596078431372549, 0.5882352941176471),\n",
    "        'Apoptosis': (0.5803921568627451, 0.403921568627451, 0.7411764705882353),\n",
    "        'JAK/STAT': (0.7725490196078432, 0.6901960784313725, 0.8352941176470589),\n",
    "        'Cytoskeletal Signaling': (0.5490196078431373,\n",
    "        0.33725490196078434,\n",
    "        0.29411764705882354),\n",
    "        'TGF-beta/Smad': (0.7686274509803922, 0.611764705882353, 0.5803921568627451),\n",
    "        'Others': (0.8901960784313725, 0.4666666666666667, 0.7607843137254902),\n",
    "        'Proteases': (0.9686274509803922, 0.7137254901960784, 0.8235294117647058)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData(filename, feat_dir, statmet='SingleCell', filetype='parquet'):\n",
    "    if filetype=='parquet':\n",
    "        df = pl.read_parquet(f'{feat_dir}/{filename}.parquet')\n",
    "    elif filetype=='csv':\n",
    "        df = pl.read_csv(f'{feat_dir}/{filename}.csv')\n",
    "    \n",
    "    #Ensuring no NaN labels exist for Pathways\n",
    "    df = replace_nan_labels(df)\n",
    "\n",
    "    ##This here is important!!!!!!\n",
    "    # df=df.select([c for c in df.columns if not is_meta_column(c)])\n",
    "    # dataNpy = df.to_numpy(df.select(float_columns))\n",
    "    ##\n",
    "    df = df.filter(~pl.col('Metadata_cmpd_pathway').is_in(ignore_labels))\n",
    "    df = df.filter(~pl.col('Metadata_cmpd_pert_type').is_in(cons))\n",
    "    onehot_list = df.select(['Metadata_cmpd_pathway'])['Metadata_cmpd_pathway'].unique().to_list()\n",
    "    onehot_mapping = {name: i for i, name in enumerate(onehot_list)}\n",
    "    df = df.with_columns(df['Metadata_cmpd_pathway'].map_elements(lambda name: oneHot(name, onehot_mapping), return_dtype=pl.Boolean).alias('Metadata_onehot'))\n",
    "    \n",
    "\n",
    "    df = df.with_columns(\n",
    "    pl.when(\n",
    "        pl.col(\"Metadata_onehot\").map_elements(lambda s: np.random.rand() < frac_wells, return_dtype=pl.Boolean)\n",
    "    )\n",
    "    .then(-1)\n",
    "    .otherwise(pl.col(\"Metadata_onehot\"))\n",
    "    .alias(\"Metadata_semi\")\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "def replace_nan_labels(df):\n",
    "    df = df.with_columns(\n",
    "    pl.when(pl.col('Metadata_cmpd_pathway').is_null())\n",
    "      .then(pl.col('Metadata_cmpd_cmpdname'))\n",
    "      .otherwise(pl.col('Metadata_cmpd_pathway'))\n",
    "      .alias('Metadata_cmpd_pathway')\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def modify_half_of_each_class(group):\n",
    "    # Sample 50% of the rows from the group\n",
    "    sample_size = int(group.shape[0] * 0.5)\n",
    "    sampled_indices = np.random.choice(group.shape[0], size=sample_size, replace=False)\n",
    "    \n",
    "    # Set those rows to -1\n",
    "    group = group.with_columns(\n",
    "        pl.when(pl.Series(np.isin(np.arange(group.shape[0]), sampled_indices)))\n",
    "        .then(-1)\n",
    "        .otherwise(pl.col(\"Metadata_onehot\"))\n",
    "        .alias(\"Metadata_semi\")\n",
    "    )\n",
    "    return group\n",
    "\n",
    "\n",
    "# this is code from Dan\n",
    "def is_meta_column(\n",
    "    c:str,\n",
    "    allowlist:tp.List[str]=[\"Metadata_AcqID\",\"Metadata_Site\"],\n",
    "    denylist:tp.List[str]=[\"Metadata_Well\",\"Metadata_barcode\"],\n",
    ")->bool:\n",
    "    \"\"\"\n",
    "        allowlist:\n",
    "            the function will return False for these, no matter if they are metadata or not\n",
    "        denylist:\n",
    "            the function will return True for these, no matter if they are metadata or not\n",
    "    \"\"\"\n",
    "    if c in allowlist:\n",
    "        return False\n",
    "    if c in denylist:\n",
    "        return True\n",
    "    for ex in '''\n",
    "        Metadata\n",
    "        Plate\n",
    "        Well\n",
    "    '''.split():\n",
    "        if re.search(ex, c):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def oneHot(row, mapping):\n",
    "    return mapping.get(row, -1)\n",
    "\n",
    "def makePCA(df, cmap,name='', n_components=2):\n",
    "    dataN=df.select([c for c in df.columns if not is_meta_column(c)]).select(float_columns).to_numpy()\n",
    "    pca_model = PCA(n_components=n_components)\n",
    "    pca_model = pca_model.fit(dataN)\n",
    "    pcaOut = pca_model.transform(dataN)\n",
    "    df = df.with_columns([\n",
    "    pl.Series('pc1', pcaOut[:, 0]),  \n",
    "    pl.Series('pc2', pcaOut[:, 1])   \n",
    "    ])\n",
    "\n",
    "    hue = df['Metadata_Site'].to_list()\n",
    "    # cmap = sns.color_palette(\"tab20\", n_colors=len(df['Metadata_pathway'].unique().to_list()))\n",
    "    # cmap = cmap\n",
    "    fig = plt.figure(\n",
    "    # figsize=[14, 5]\n",
    "    )\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_xlabel('PC 1', fontsize = 10)\n",
    "    ax.set_ylabel('PC 2', fontsize = 10)\n",
    "    ax.spines['top'].set_color('w')\n",
    "    ax.spines['right'].set_color('w')\n",
    "    ax.spines['left'].set_color('grey')\n",
    "    ax.spines['bottom'].set_color('grey')\n",
    "    sns.scatterplot(x=df['pc1'].to_list(),\n",
    "                    y=df['pc2'].to_list(),\n",
    "                    palette=cmap, hue=hue,\n",
    "                    marker='.',\n",
    "                    ).set(title=f'PCA {name} All'\n",
    "                )\n",
    "    ax.set_facecolor('w')\n",
    "    ax.get_legend().remove()\n",
    "    ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    return df\n",
    "\n",
    "def makeUMAP(df, cmap, name='', statmet='SingleCell', nn = 200, sup_mode=True, n_components=100, min_dist=0.1, spread= 1, n_epochs=None, metric='cosine', use_pca=True, random_state=42):\n",
    "    if sup_mode=='traintest':\n",
    "        dfN = df.filter(pl.col('Metadata_semi')!=-1)\n",
    "        dfY = df.filter(pl.col('Metadata_semi')==-1)\n",
    "        dataN=dfN.select([c for c in dfN.columns if not is_meta_column(c)]).select(float_columns).to_numpy().astype(np.float32)\n",
    "        dataY=dfY.select([c for c in dfN.columns if not is_meta_column(c)]).select(float_columns).to_numpy().astype(np.float32)\n",
    "    else:\n",
    "        dataN=df.select([c for c in df.columns if not is_meta_column(c)]).select(float_columns).to_numpy().astype(np.float32)\n",
    "\n",
    "    umap_model = umap.UMAP(n_neighbors=nn\n",
    "                        , min_dist=min_dist\n",
    "                        , spread= spread\n",
    "                        , n_epochs=n_epochs\n",
    "                        , metric=metric\n",
    "                        , n_jobs=-1\n",
    "                        , random_state=random_state\n",
    "                        )\n",
    "    # umap_model = umap.PaCMAP(n_components=2,MN_ratio=0.5, FP_ratio=2.0, distance='angular')\n",
    "    if sup_mode=='traintest':\n",
    "        umapOut = umap_model.fit_transform(dataN, y=dfN['Metadata_onehot'].to_list())\n",
    "        umapPred = umap_model.transform(dataY)\n",
    "        dfN = dfN.with_columns([\n",
    "        pl.Series('umap1', umapOut[:, 0]),  \n",
    "        pl.Series('umap2', umapOut[:, 1])   \n",
    "        ])\n",
    "        dfY = dfY.with_columns([\n",
    "        pl.Series('umap1', umapPred[:, 0]),  \n",
    "        pl.Series('umap2', umapPred[:, 1])   \n",
    "        ])\n",
    "        df = pl.concat([dfN, dfY])\n",
    "        isSup = 'Semi-Supervised train-test'\n",
    "    else:\n",
    "        if use_pca:\n",
    "            pca_model = PCA(n_components=n_components)\n",
    "            pca_model = pca_model.fit(dataN)\n",
    "            dataN = pca_model.transform(dataN)\n",
    "        if sup_mode=='supervised':\n",
    "            umapOut = umap_model.fit_transform(dataN, y=df['Metadata_onehot'].to_list())\n",
    "            isSup = 'Supervised'\n",
    "        elif sup_mode=='semi':\n",
    "            umapOut = umap_model.fit_transform(dataN, y=df['Metadata_semi'].to_list())\n",
    "            isSup = 'Semi-Supervised with partial labeling'\n",
    "        else:\n",
    "            umapOut = umap_model.fit_transform(dataN)\n",
    "            isSup = 'Unsupervised'\n",
    "        df = df.with_columns([\n",
    "        pl.Series('umap1', umapOut[:, 0]),  \n",
    "        pl.Series('umap2', umapOut[:, 1])   \n",
    "        ])\n",
    "\n",
    "    \n",
    "    # cmap = sns.color_palette(\"tab20\", n_colors=len(df['Metadata_pathway'].unique().to_list()))\n",
    "\n",
    "    fig = plt.figure(\n",
    "    # figsize=[14, 5]\n",
    "    )\n",
    "    ax = fig.add_subplot()\n",
    "    ax.set_xlabel('UMAP 1', fontsize = 10)\n",
    "    ax.set_ylabel('UMAP 2', fontsize = 10)\n",
    "    ax.spines['top'].set_color('w')\n",
    "    ax.spines['right'].set_color('w')\n",
    "    ax.spines['left'].set_color('grey')\n",
    "    ax.spines['bottom'].set_color('grey')\n",
    "    if sup_mode == 'supervised' or sup_mode == 'unsupervised':\n",
    "        hue = df['Metadata_Site'].to_list()\n",
    "        sns.scatterplot(x=df['umap1'].to_list(),\n",
    "                        y=df['umap2'].to_list(),\n",
    "                        palette=cmap, hue=hue,\n",
    "                        marker='.',\n",
    "                        ).set(title=f'umap {df.select(pl.col(\"Metadata_cell_line\")).unique().item(0, 0)} {sup_mode}'\n",
    "                    )\n",
    "    else:\n",
    "        df_s1 = df.filter(pl.col('Metadata_semi')!=-1)\n",
    "        df_s1 = df_s1.select(pl.col(['umap1', 'umap2','Metadata_cmpd_pathway', 'Metadata_onehot', 'Metadata_semi']))\n",
    "        hue = df_s1['Metadata_Site'].to_list()\n",
    "        sns.scatterplot(x=df_s1['umap1'].to_list(),\n",
    "                        y=df_s1['umap2'].to_list(),\n",
    "                        palette=cmap, hue=hue,\n",
    "                        marker='.',\n",
    "                        ax=ax\n",
    "                        ).set(title=f'umap {df.select(pl.col(\"Metadata_cell_line\")).unique().item(0, 0)} {sup_mode}'\n",
    "                    )\n",
    "        df_s2 = df.filter(pl.col('Metadata_semi')==-1)\n",
    "        df_s2 = df_s2.select(pl.col(['umap1', 'umap2','Metadata_cmpd_pathway', 'Metadata_onehot', 'Metadata_semi']))\n",
    "        hue = df_s2['Metadata_Site'].to_list()\n",
    "        sns.scatterplot(x=df_s2['umap1'].to_list(),\n",
    "                        y=df_s2['umap2'].to_list(),\n",
    "                        palette=cmap, hue=hue,\n",
    "                        marker='o',\n",
    "                        ax=ax,\n",
    "                        s=30, alpha=0.7\n",
    "                        ).set(title=f'umap {df.select(pl.col(\"Metadata_cell_line\")).unique().item(0, 0)} {sup_mode}'\n",
    "                    )\n",
    "\n",
    "    ax.set_facecolor('w')\n",
    "    ax.get_legend().remove()\n",
    "    ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "    # if not os.path.exists(f'{OutputDir}/{statmet}'):\n",
    "    #     os.makedirs(f'{OutputDir}/{statmet}')\n",
    "    # plt.savefig(f'{OutputDir}/{statmet}/{name}_umap{nn}nn_{isSup}.png')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    return df\n",
    "\n",
    "def filter_and_clean(df):\n",
    "    df_3d = scrub(df.filter(pl.col('Metadata_data_type')=='aggregates'))\n",
    "    # print(df_3d.head(), df.head())\n",
    "    df_2d = scrub(df.filter(pl.col('Metadata_data_type')=='2D'))\n",
    "    df_mip = scrub(df.filter(pl.col('Metadata_data_type')=='MIP'))\n",
    "    return df_3d, df_2d, df_mip\n",
    "\n",
    "def scrub(df):\n",
    "    float_columns=[pl.col(pl.Float32),pl.col(pl.Float64)]\n",
    "    df_floats=df.select([c for c in df.columns if not is_meta_column(c)]).select(float_columns)\n",
    "\n",
    "    df_bool = df_floats.select(pl.all().is_nan().all())\n",
    "    cols_to_drop = [col for col, is_all_nan in zip(df_floats.columns, df_bool.row(0)) if is_all_nan] \n",
    "    df = df.drop(cols_to_drop)\n",
    "\n",
    "    #Checking if NaNs remains after column scrubbing\n",
    "    df_floats=df.select([c for c in df.columns if not is_meta_column(c)]).select(float_columns)\n",
    "    has_nan = df_floats.select(pl.all().is_nan().any()).row(0)[0]\n",
    "    print(f'Has NaNs after column scrubbing:  {has_nan}')\n",
    "    num_rows_before_nan_trim = df.shape[0]\n",
    "    if has_nan:\n",
    "        for col in df.select([pl.col(pl.Float32),pl.col(pl.Float64)]).columns:\n",
    "            before_drop=df.shape[0]\n",
    "            df=df.filter(pl.col(col).is_not_null())\n",
    "            after_drop=df.shape[0]\n",
    "\n",
    "            num_values_dropped=before_drop-after_drop\n",
    "            if num_values_dropped>0:\n",
    "                print(f\"dropped {num_values_dropped} rows due to NaNs in column {col}\")\n",
    "        #Checking if NaNs remains after row scrubbing\n",
    "        df_floats=df.select([c for c in df.columns if not is_meta_column(c)]).select(float_columns)\n",
    "        has_nan = df_floats.select(pl.all().is_nan().any()).row(0)[0]\n",
    "        print(f'Has NaNs after row scrubbing:  {has_nan}')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename1 = filenames[0]\n",
    "# df = pl.read_parquet(f'{feat_pp}/{filename}.parquet')\n",
    "df1 = readData(filename1, feat_dir=feat_base, filetype='parquet')\n",
    "# cmap = sns.color_palette(\"YlOrRd\", n_colors=len(df1['Metadata_Site'].unique().to_list()))\n",
    "# df['Metadata_cmpd_pathway'].unique().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SingleCell/HCT116_nonorm\n"
     ]
    }
   ],
   "source": [
    "# Take a subset of cells\n",
    "df_sub = df1.sample(n=int(0.01 * df1.shape[0]))\n",
    "print(filename1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "UFuncTypeError",
     "evalue": "ufunc 'correct_alternative_cosine' did not contain a loop with signature matching types <class 'numpy.dtype[float32]'> -> None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmakeUMAP\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_sub\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msup_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msupervised\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcmap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_pca\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[35], line 158\u001b[0m, in \u001b[0;36mmakeUMAP\u001b[0;34m(df, cmap, name, statmet, nn, sup_mode, n_components, min_dist, spread, n_epochs, metric, use_pca, random_state)\u001b[0m\n\u001b[1;32m    156\u001b[0m     dataN \u001b[38;5;241m=\u001b[39m pca_model\u001b[38;5;241m.\u001b[39mtransform(dataN)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sup_mode\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupervised\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 158\u001b[0m     umapOut \u001b[38;5;241m=\u001b[39m \u001b[43mumap_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMetadata_onehot\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m     isSup \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSupervised\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m sup_mode\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msemi\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/umap/umap_.py:2772\u001b[0m, in \u001b[0;36mUMAP.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   2742\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   2743\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit X into an embedded space and return that transformed\u001b[39;00m\n\u001b[1;32m   2744\u001b[0m \u001b[38;5;124;03m    output.\u001b[39;00m\n\u001b[1;32m   2745\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2770\u001b[0m \u001b[38;5;124;03m        Local radii of data points in the embedding (log-transformed).\u001b[39;00m\n\u001b[1;32m   2771\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2772\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   2774\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dens:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/umap/umap_.py:2516\u001b[0m, in \u001b[0;36mUMAP.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   2510\u001b[0m     nn_metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_distance_func\n\u001b[1;32m   2511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mknn_dists \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2512\u001b[0m     (\n\u001b[1;32m   2513\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_knn_indices,\n\u001b[1;32m   2514\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_knn_dists,\n\u001b[1;32m   2515\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_knn_search_index,\n\u001b[0;32m-> 2516\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[43mnearest_neighbors\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2518\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_n_neighbors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnn_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2520\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_metric_kwds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2521\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mangular_rp_forest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2523\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlow_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2524\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_pynndescent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2525\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2527\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2528\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_knn_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mknn_indices\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/umap/umap_.py:342\u001b[0m, in \u001b[0;36mnearest_neighbors\u001b[0;34m(X, n_neighbors, metric, metric_kwds, angular, random_state, low_memory, use_pynndescent, n_jobs, verbose)\u001b[0m\n\u001b[1;32m    326\u001b[0m     n_iters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mround\u001b[39m(np\u001b[38;5;241m.\u001b[39mlog2(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]))))\n\u001b[1;32m    328\u001b[0m     knn_search_index \u001b[38;5;241m=\u001b[39m NNDescent(\n\u001b[1;32m    329\u001b[0m         X,\n\u001b[1;32m    330\u001b[0m         n_neighbors\u001b[38;5;241m=\u001b[39mn_neighbors,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    340\u001b[0m         compressed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    341\u001b[0m     )\n\u001b[0;32m--> 342\u001b[0m     knn_indices, knn_dists \u001b[38;5;241m=\u001b[39m \u001b[43mknn_search_index\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mneighbor_graph\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;28mprint\u001b[39m(ts(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished Nearest Neighbor Search\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pynndescent/pynndescent_.py:1564\u001b[0m, in \u001b[0;36mNNDescent.neighbor_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1560\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distance_correction \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1562\u001b[0m     result \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1563\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_neighbor_graph[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcopy(),\n\u001b[0;32m-> 1564\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_distance_correction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_neighbor_graph\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1565\u001b[0m     )\n\u001b[1;32m   1566\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1567\u001b[0m     result \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_neighbor_graph[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcopy(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_neighbor_graph[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mcopy())\n",
      "\u001b[0;31mUFuncTypeError\u001b[0m: ufunc 'correct_alternative_cosine' did not contain a loop with signature matching types <class 'numpy.dtype[float32]'> -> None"
     ]
    }
   ],
   "source": [
    "results = makeUMAP(df_sub,nn=200, sup_mode='supervised', cmap=cmap, use_pca=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename2 = filenames[1]\n",
    "# df = pl.read_parquet(f'{feat_pp}/{filename}.parquet')\n",
    "df2 = readData(filename2, feat_dir=feat_bk, filetype='parquet')\n",
    "cmap = sns.color_palette(\"YlOrRd\", n_colors=len(df2['Metadata_Site'].unique().to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = makePCA(df2,cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename3 = filenames[0]\n",
    "# df = pl.read_parquet(f'{feat_pp}/{filename}.parquet')\n",
    "df3 = readData(filename3, feat_dir=feat_fe, filetype='parquet')\n",
    "cmap = sns.color_palette(\"YlOrRd\", n_colors=len(df3['Metadata_Site'].unique().to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = makePCA(df3,cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename4 = filenames[1]\n",
    "# df = pl.read_parquet(f'{feat_pp}/{filename}.parquet')\n",
    "df4 = readData(filename4, feat_dir=feat_fe, filetype='parquet')\n",
    "cmap = sns.color_palette(\"YlOrRd\", n_colors=len(df4['Metadata_Site'].unique().to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = makePCA(df4,cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "colovenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
