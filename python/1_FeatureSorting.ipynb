{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/scratch2-shared/david/colopaint3D/python'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import polars as pl # like pandas, but much faster\n",
    "import polars.selectors as cs\n",
    "import numpy as np\n",
    "import os, shutil, glob\n",
    "from random import randint\n",
    "import re, math\n",
    "import datetime\n",
    "import gc\n",
    "from pathlib import Path\n",
    "\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sourceDir = '/share/data/cellprofiler/automation/results'\n",
    "rootDir = '/home/jovyan/scratch2-shared/david/colopaint3D'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 1)\n",
      "┌───────────────────┐\n",
      "│ feature_names     │\n",
      "│ ---               │\n",
      "│ str               │\n",
      "╞═══════════════════╡\n",
      "│ featICF_nuclei    │\n",
      "│ featICF_cells     │\n",
      "│ featICF_cytoplasm │\n",
      "└───────────────────┘\n"
     ]
    }
   ],
   "source": [
    "OutputDir = 'data/1_FeaturesImages'\n",
    "if not os.path.exists(OutputDir): \n",
    "    os.makedirs(OutputDir)\n",
    "NameContains = ''\n",
    "InputFolders = pl.read_csv('../settings/filemap.csv')\n",
    "print(InputFolders )\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current date and time : \n",
      "2024-08-09 15:05:25\n"
     ]
    }
   ],
   "source": [
    "now = datetime.datetime.now()\n",
    "print ('Current date and time : ')\n",
    "print (now.strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_time(msg=None):\n",
    "    now = datetime.datetime.now()\n",
    "    print(now.strftime('%Y-%m-%d %H:%M:%S'),msg or \"\")\n",
    "float_columns=[pl.col(pl.Float32),pl.col(pl.Float64)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaEx = pl.read_csv(f'{rootDir}/settings/spher-colo52-v1-import-inputFiles-and-PLAIDresults.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaEx.head()\n",
    "barcodes = metaEx.select(pl.col('barcode')).unique()\n",
    "barcodes = barcodes['barcode']\n",
    "barcodes.to_list()\n",
    "dirlist = [f'{sourceDir}/{barcode}' for barcode in barcodes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadmso = metaEx.filter(pl.col('Compound_ID')=='DMSO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 28)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>index</th><th>layout_id</th><th>well_id</th><th>image_id</th><th>cp_id</th><th>barcode</th><th>plate_well</th><th>cmpd_code</th><th>cmpdname</th><th>solvent</th><th>cmpd_conc</th><th>cmpd_conc_unit</th><th>stock_conc</th><th>stock_conc_unit</th><th>cmpd_vol</th><th>cmpd_vol_unit</th><th>well_vol</th><th>well_vol_unit</th><th>pert_type</th><th>article_id</th><th>target</th><th>pathway</th><th>pubchemID</th><th>smiles</th><th>inkey</th><th>target_type</th><th>clinical_status</th><th>cell_line</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>i64</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>str</td><td>f64</td><td>str</td><td>f64</td><td>str</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>0</td><td>&quot;spher-colo52-v…</td><td>&quot;B02&quot;</td><td>4185</td><td>5532</td><td>&quot;PB000137&quot;</td><td>&quot;PB000137_B02&quot;</td><td>&quot;colo-006&quot;</td><td>&quot;PD0325901&quot;</td><td>&quot;dmso&quot;</td><td>3.0</td><td>&quot;µM&quot;</td><td>10.0</td><td>&quot;mM&quot;</td><td>30.0</td><td>&quot;nl&quot;</td><td>40.0</td><td>&quot;µl&quot;</td><td>&quot;trt&quot;</td><td>&quot;S1036&quot;</td><td>&quot;MEK&quot;</td><td>&quot;MAPK&quot;</td><td>9.826528e6</td><td>&quot;OCC(O)CONC(=O)…</td><td>&quot;SUDAHWBOROXANE…</td><td>&quot;Targeted&quot;</td><td>&quot;Phase 2&quot;</td><td>&quot;HCT116&quot;</td></tr><tr><td>1</td><td>&quot;spher-colo52-v…</td><td>&quot;B03&quot;</td><td>4185</td><td>5532</td><td>&quot;PB000137&quot;</td><td>&quot;PB000137_B03&quot;</td><td>&quot;colo-018&quot;</td><td>&quot;Paclitaxel&quot;</td><td>&quot;dmso&quot;</td><td>0.1</td><td>&quot;µM&quot;</td><td>0.1</td><td>&quot;mM&quot;</td><td>100.0</td><td>&quot;nl&quot;</td><td>40.0</td><td>&quot;µl&quot;</td><td>&quot;trt&quot;</td><td>&quot;S1150&quot;</td><td>&quot;Autophagy,Micr…</td><td>&quot;Cytoskeletal S…</td><td>441276.0</td><td>&quot;CC(=O)OC1C(=O)…</td><td>&quot;RCINICONZNJXQF…</td><td>&quot;Cytotoxic&quot;</td><td>&quot;Preclinical&quot;</td><td>&quot;HCT116&quot;</td></tr><tr><td>2</td><td>&quot;spher-colo52-v…</td><td>&quot;B04&quot;</td><td>4185</td><td>5532</td><td>&quot;PB000137&quot;</td><td>&quot;PB000137_B04&quot;</td><td>&quot;colo-009&quot;</td><td>&quot;Olaparib (AZD2…</td><td>&quot;dmso&quot;</td><td>3.0</td><td>&quot;µM&quot;</td><td>10.0</td><td>&quot;mM&quot;</td><td>30.0</td><td>&quot;nl&quot;</td><td>40.0</td><td>&quot;µl&quot;</td><td>&quot;trt&quot;</td><td>&quot;S1060&quot;</td><td>&quot;PARP&quot;</td><td>&quot;DNA Damage&quot;</td><td>2.3725625e7</td><td>&quot;FC1=C(C=C(CC2=…</td><td>&quot;FDLYAMZZIXQODN…</td><td>&quot;Targeted&quot;</td><td>&quot;Launched&quot;</td><td>&quot;HCT116&quot;</td></tr><tr><td>3</td><td>&quot;spher-colo52-v…</td><td>&quot;B05&quot;</td><td>4185</td><td>5532</td><td>&quot;PB000137&quot;</td><td>&quot;PB000137_B05&quot;</td><td>&quot;colo-012&quot;</td><td>&quot;SB216763&quot;</td><td>&quot;dmso&quot;</td><td>10.0</td><td>&quot;µM&quot;</td><td>10.0</td><td>&quot;mM&quot;</td><td>100.0</td><td>&quot;nl&quot;</td><td>40.0</td><td>&quot;µl&quot;</td><td>&quot;trt&quot;</td><td>&quot;S1075&quot;</td><td>&quot;GSK-3&quot;</td><td>&quot;PI3K/Akt/mTOR&quot;</td><td>176158.0</td><td>&quot;C[N]1C=C(C2=C1…</td><td>&quot;JCSGFHVFHSKIJH…</td><td>&quot;Targeted&quot;</td><td>&quot;Preclinical&quot;</td><td>&quot;HCT116&quot;</td></tr><tr><td>4</td><td>&quot;spher-colo52-v…</td><td>&quot;B06&quot;</td><td>4185</td><td>5532</td><td>&quot;PB000137&quot;</td><td>&quot;PB000137_B06&quot;</td><td>&quot;colo-008&quot;</td><td>&quot;Vorinostat (SA…</td><td>&quot;dmso&quot;</td><td>3.0</td><td>&quot;µM&quot;</td><td>10.0</td><td>&quot;mM&quot;</td><td>30.0</td><td>&quot;nl&quot;</td><td>40.0</td><td>&quot;µl&quot;</td><td>&quot;trt&quot;</td><td>&quot;S1047&quot;</td><td>&quot;Autophagy,HDAC…</td><td>&quot;Epigenetics&quot;</td><td>5311.0</td><td>&quot;ONC(=O)CCCCCCC…</td><td>&quot;WAEXFXRVDQXREF…</td><td>&quot;Targeted&quot;</td><td>&quot;Launched&quot;</td><td>&quot;HCT116&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 28)\n",
       "┌───────┬─────────────┬─────────┬──────────┬───┬─────────────┬────────────┬────────────┬───────────┐\n",
       "│ index ┆ layout_id   ┆ well_id ┆ image_id ┆ … ┆ inkey       ┆ target_typ ┆ clinical_s ┆ cell_line │\n",
       "│ ---   ┆ ---         ┆ ---     ┆ ---      ┆   ┆ ---         ┆ e          ┆ tatus      ┆ ---       │\n",
       "│ i64   ┆ str         ┆ str     ┆ i64      ┆   ┆ str         ┆ ---        ┆ ---        ┆ str       │\n",
       "│       ┆             ┆         ┆          ┆   ┆             ┆ str        ┆ str        ┆           │\n",
       "╞═══════╪═════════════╪═════════╪══════════╪═══╪═════════════╪════════════╪════════════╪═══════════╡\n",
       "│ 0     ┆ spher-colo5 ┆ B02     ┆ 4185     ┆ … ┆ SUDAHWBOROX ┆ Targeted   ┆ Phase 2    ┆ HCT116    │\n",
       "│       ┆ 2-v1-ULA-PB ┆         ┆          ┆   ┆ ANE-SECBINF ┆            ┆            ┆           │\n",
       "│       ┆ 000137-HCT… ┆         ┆          ┆   ┆ HSA-N       ┆            ┆            ┆           │\n",
       "│ 1     ┆ spher-colo5 ┆ B03     ┆ 4185     ┆ … ┆ RCINICONZNJ ┆ Cytotoxic  ┆ Preclinica ┆ HCT116    │\n",
       "│       ┆ 2-v1-ULA-PB ┆         ┆          ┆   ┆ XQF-VAZQATR ┆            ┆ l          ┆           │\n",
       "│       ┆ 000137-HCT… ┆         ┆          ┆   ┆ QSA-N       ┆            ┆            ┆           │\n",
       "│ 2     ┆ spher-colo5 ┆ B04     ┆ 4185     ┆ … ┆ FDLYAMZZIXQ ┆ Targeted   ┆ Launched   ┆ HCT116    │\n",
       "│       ┆ 2-v1-ULA-PB ┆         ┆          ┆   ┆ ODN-UHFFFAO ┆            ┆            ┆           │\n",
       "│       ┆ 000137-HCT… ┆         ┆          ┆   ┆ YSA-N       ┆            ┆            ┆           │\n",
       "│ 3     ┆ spher-colo5 ┆ B05     ┆ 4185     ┆ … ┆ JCSGFHVFHSK ┆ Targeted   ┆ Preclinica ┆ HCT116    │\n",
       "│       ┆ 2-v1-ULA-PB ┆         ┆          ┆   ┆ IJH-UHFFFAO ┆            ┆ l          ┆           │\n",
       "│       ┆ 000137-HCT… ┆         ┆          ┆   ┆ YSA-N       ┆            ┆            ┆           │\n",
       "│ 4     ┆ spher-colo5 ┆ B06     ┆ 4185     ┆ … ┆ WAEXFXRVDQX ┆ Targeted   ┆ Launched   ┆ HCT116    │\n",
       "│       ┆ 2-v1-ULA-PB ┆         ┆          ┆   ┆ REF-UHFFFAO ┆            ┆            ┆           │\n",
       "│       ┆ 000137-HCT… ┆         ┆          ┆   ┆ YSA-N       ┆            ┆            ┆           │\n",
       "└───────┴─────────────┴─────────┴──────────┴───┴─────────────┴────────────┴────────────┴───────────┘"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metaEx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['index','layout_id','cmpd_code', 'solvent','cmpd_conc','cmpd_conc_unit','stock_conc','stock_conc_unit','cmpd_vol', 'cmpd_vol_unit', 'well_vol', 'well_vol_unit', 'article_id', 'target','pubchemID', 'smiles', 'inkey', 'clinical_status']\n",
    "metaEx = metaEx.drop(cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HCT116', 'HT29']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metaEx.select(pl.col(['cell_line'])).unique().to_series().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_clipping = False\n",
    "\n",
    "std_mean = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lala\n",
      "/share/data/cellprofiler/automation/results/PB000138/4188/5547\n",
      "part1\n",
      "processed metadata for 5547\n",
      "/share/data/cellprofiler/automation/results/PB000142/4191/5574\n",
      "part1\n",
      "processed metadata for 5574\n",
      "/share/data/cellprofiler/automation/results/PB000141/4187/5546\n",
      "part1\n",
      "processed metadata for 5546\n",
      "/share/data/cellprofiler/automation/results/PB000140/4189/5573\n",
      "part1\n",
      "processed metadata for 5573\n",
      "/share/data/cellprofiler/automation/results/PB000137/4185/5532\n",
      "part1\n",
      "processed metadata for 5532\n",
      "/share/data/cellprofiler/automation/results/PB000139/4186/5533\n",
      "part1\n",
      "processed metadata for 5533\n",
      "2024-08-09 15:07:37 dropped NaNs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1411136/908342519.py:124: DeprecationWarning: `map_dict` is deprecated. It has been renamed to `replace`. The default behavior has changed to keep any values not present in the mapping unchanged. Pass `default=None` to keep existing behavior.\n",
      "  std = std.select([pl.col(c).map_dict({0: 1}, default=pl.col(c)) for c in std.columns])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-09 15:07:38 calculated DMSO distribution\n",
      "2024-08-09 15:07:56 binned mean data per well\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1411136/908342519.py:192: DeprecationWarning: `map_dict` is deprecated. It has been renamed to `replace`. The default behavior has changed to keep any values not present in the mapping unchanged. Pass `default=None` to keep existing behavior.\n",
      "  mad = mad.select([pl.col(c).map_dict({0: 0.01}, default=pl.col(c)) for c in mad.columns])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-09 15:08:06 calculated DMSO distribution\n",
      "2024-08-09 15:08:06 MAD normalized to DMSO distribution\n",
      "2024-08-09 15:08:06 num objects (cells) 207924 (0.03% were NaN)\n",
      "2024-08-09 15:08:23 binned median data per well\n",
      "lala\n",
      "/share/data/cellprofiler/automation/results/PB000138/4188/5547\n",
      "part1\n",
      "processed metadata for 5547\n",
      "/share/data/cellprofiler/automation/results/PB000142/4191/5574\n",
      "part1\n",
      "processed metadata for 5574\n",
      "/share/data/cellprofiler/automation/results/PB000141/4187/5546\n",
      "part1\n",
      "processed metadata for 5546\n",
      "/share/data/cellprofiler/automation/results/PB000140/4189/5573\n",
      "part1\n",
      "processed metadata for 5573\n",
      "/share/data/cellprofiler/automation/results/PB000137/4185/5532\n",
      "part1\n",
      "processed metadata for 5532\n",
      "/share/data/cellprofiler/automation/results/PB000139/4186/5533\n",
      "part1\n",
      "processed metadata for 5533\n",
      "2024-08-09 15:10:39 dropped NaNs\n",
      "2024-08-09 15:10:40 calculated DMSO distribution\n",
      "2024-08-09 15:11:15 binned mean data per well\n",
      "2024-08-09 15:11:30 calculated DMSO distribution\n",
      "2024-08-09 15:11:31 MAD normalized to DMSO distribution\n",
      "2024-08-09 15:11:31 num objects (cells) 370680 (0.02% were NaN)\n",
      "2024-08-09 15:12:05 binned median data per well\n"
     ]
    }
   ],
   "source": [
    "ObjectList = ['featICF_nuclei', 'featICF_cells', 'featICF_cytoplasm']\n",
    "\n",
    "for cl in metaEx.select(pl.col(['cell_line'])).unique().to_series().to_list():\n",
    "    print('lala')\n",
    "    df = pl.DataFrame()\n",
    "    for BaseDir in dirlist:\n",
    "        mdf_op = metaEx.filter(pl.col('barcode') == BaseDir.split('/')[-1])\n",
    "        image_id = mdf_op.select(pl.col('image_id')).unique().to_series().to_list()[-1]\n",
    "        cp_id = mdf_op.select(pl.col('cp_id')).unique().to_series().to_list()[-1]\n",
    "        print(f'{BaseDir}/{image_id}/{cp_id}')\n",
    "        BaseDir = f'{BaseDir}/{image_id}/{cp_id}'\n",
    "\n",
    "\n",
    "        # nuclei = pl.read_parquet(BaseDir+f'/{ObjectList[0]}.parquet').add_prefix('Nuclei_').reset_index()\n",
    "        # cytoplasm = pl.read_parquet(BaseDir+f'/{ObjectList[1]}.parquet').add_prefix('Cytoplasm_').reset_index()\n",
    "        # cells = pl.read_parquet(BaseDir+f'/{ObjectList[2]}.parquet').add_prefix('Cells_').reset_index()\n",
    "        # f_df=pl.read_parquet(f)\n",
    "        # f_df=f_df.rename({x:f'{feature_set_name}_{x}' for x in f_df.columns})\n",
    "        \n",
    "\n",
    "        nuclei = pl.read_parquet(BaseDir+f'/{ObjectList[0]}.parquet')\n",
    "        nuclei=nuclei.rename({x:f'Nuclei_{x}' for x in nuclei.columns})\n",
    "        cytoplasm = pl.read_parquet(BaseDir+f'/{ObjectList[1]}.parquet')\n",
    "        cytoplasm=cytoplasm.rename({x:f'Cytoplasm_{x}' for x in cytoplasm.columns})\n",
    "        cells = pl.read_parquet(BaseDir+f'/{ObjectList[2]}.parquet')\n",
    "        cells=cells.rename({x:f'Cells_{x}' for x in cells.columns})\n",
    "        # step 1: Take the mean values of 'multiple nuclei' belonging to one cell\n",
    "\n",
    "        nuclei = nuclei.group_by([\n",
    "            \"Nuclei_Metadata_Barcode\",\"Nuclei_Metadata_Well\",\n",
    "            \"Nuclei_Parent_cells\", 'Nuclei_Metadata_Site'\n",
    "        ]).mean()\n",
    "\n",
    "        df_one = cytoplasm.join(nuclei,\n",
    "                    how='left', \n",
    "                    right_on=['Nuclei_Metadata_Well', 'Nuclei_Metadata_Site', 'Nuclei_Parent_cells', 'Nuclei_Metadata_Barcode'],\n",
    "                    left_on = ['Cytoplasm_Metadata_Well','Cytoplasm_Metadata_Site', 'Cytoplasm_ObjectNumber', 'Cytoplasm_Metadata_Barcode'])\n",
    "                    \n",
    "        df_one = df_one.join(cells, how='left', \n",
    "                        left_on=['Cytoplasm_Metadata_Well','Cytoplasm_Metadata_Site','Cytoplasm_ObjectNumber', 'Cytoplasm_Metadata_Barcode'],\n",
    "                        right_on = ['Cells_Metadata_Well','Cells_Metadata_Site',\"Cells_ObjectNumber\", 'Cells_Metadata_Barcode'])\n",
    "\n",
    "        # print_time(\"initial merging\")\n",
    "        print('part1')\n",
    "\n",
    "        # deduplicate barcode/well/site - renamed cytoplasm_Metadata* to Metadata* and removes nuclei_* etc\n",
    "        unique_metadata_feature_names=['Metadata_Barcode','Metadata_Well','Metadata_Site']\n",
    "        df_one=df_one.rename({f'Cytoplasm_{suffix}':suffix for suffix in unique_metadata_feature_names})\n",
    "        # df = df.filter(pl.col(''))       \n",
    "        # for some reason, the site is parsed as float, even though it really should be an int\n",
    "        if df_one['Metadata_Site'].dtype in [np.dtype('float32'), np.dtype('float64')]:\n",
    "            # sometimes, for some reason, site indices are inf/nan\n",
    "            site_is_nan_mask=np.isnan(df_one['Metadata_Site'])\n",
    "            site_is_inf_mask=np.isinf(df_one['Metadata_Site'])\n",
    "            \n",
    "            try:\n",
    "                num_sites_nan=np.sum(site_is_nan_mask)\n",
    "                num_sites_inf=np.sum(site_is_inf_mask)\n",
    "                assert num_sites_nan==0, f\"found nan site values (n = {num_sites_nan})\"\n",
    "                assert num_sites_inf==0, f\"found inf site values (n = {num_sites_inf})\"\n",
    "            except AssertionError as e:\n",
    "                print(f\"info - this issue was automatically circumvented in the code : {e}\")\n",
    "                df_one=df_one[~(site_is_inf_mask|site_is_nan_mask)]\n",
    "                \n",
    "            num_metadata_site_entries_nonint=np.sum(np.abs(df_one['Metadata_Site']%1.0)>1e-6)\n",
    "            assert num_metadata_site_entries_nonint==0, f\"ERROR : {num_metadata_site_entries_nonint} imaging sites don't have integer indices. that should not be the case, and likely indicates a bug.\"\n",
    "            \n",
    "            #Should use np.round, no? TODO ask patrick. Truncation Errors are annoying.\n",
    "            df_one['Metadata_Site'] = df_one['Metadata_Site'].astype(np.dtype('int32'))\n",
    "        \n",
    "        #Adding Compound Metadata to each row\n",
    "        df_one = df_one.join(mdf_op.rename({x:f\"Metadata_cmpd_{x}\" for x in mdf_op.columns}),left_on='Metadata_Well',right_on='Metadata_cmpd_well_id')\n",
    "        df_one = df_one.filter(pl.col('Metadata_Site')<7)\n",
    "        df = pl.concat([df, df_one])\n",
    "        plate_name = f'processed metadata for {BaseDir.split(\"/\")[-1]}'\n",
    "        print(plate_name)\n",
    "    ###Here should be workable to unify by cell line.\n",
    "    df = df.with_columns((pl.col(\"Metadata_Barcode\") + \"_\" + pl.col(\"Metadata_Well\")).alias(\"Metadata_PlateWell\"))\n",
    "    df = df.filter(pl.col('Metadata_cmpd_cell_line')==cl)\n",
    "    ###End\n",
    "    # drop all rows that contain nan\n",
    "    num_rows_before_nan_trim = df.shape[0]\n",
    "    for col in df.select([pl.col(pl.Float32),pl.col(pl.Float64)]).columns:\n",
    "        before_drop=df.shape[0]\n",
    "        df=df.filter(pl.col(col).is_not_null())\n",
    "        after_drop=df.shape[0]\n",
    "\n",
    "        #num_values_dropped=before_drop-after_drop\n",
    "        #if num_values_dropped>0:\n",
    "        #    print(f\"dropped {num_values_dropped} rows due to NaNs in column {col}\")\n",
    "\n",
    "    num_rows_after_nan_trim = df.shape[0]\n",
    "\n",
    "    print_time(\"dropped NaNs\")\n",
    "\n",
    "    # Clip outliers\n",
    "    if use_clipping:\n",
    "        float_cols = [c for c_name,c_dtype in zip(df.columns,df.dtypes) if \"float\" in str(c_dtype)]\n",
    "        lower_quantile = df.select(float_cols).quantile(0.01)\n",
    "        upper_quantile = df.select(float_cols).quantile(0.99)\n",
    "        print(\"calced quantiles\")\n",
    "\n",
    "        for col in float_cols:\n",
    "            df = df.with_column(\n",
    "                pl.col(col).clip(lower=lower_quantile[col],upper=upper_quantile[col])\n",
    "            )\n",
    "            \n",
    "        print(\"clipped\")\n",
    "    # print(df.head())\n",
    "    # for some reason, DMSO is used as batch id for cells that are not treated with a drug\n",
    "    df_DMSO=df.filter(pl.col('Metadata_cmpd_cmpdname')=='dmso')\n",
    "    assert df_DMSO.shape[0]>0, \"did not find any wells 'treated' with DMSO\"\n",
    "\n",
    "    # Running Means here:\n",
    "    mu = df_DMSO.select(float_columns).mean()\n",
    "    for col in mu.columns:\n",
    "        if mu[col].is_null().any():\n",
    "            raise RuntimeError(f\"some mean value in column {col,i} is nan?!\")\n",
    "        if mu[col].is_infinite().any():\n",
    "            raise RuntimeError(f\"some mean value in column {col,i} is infinite?!\")\n",
    "                \n",
    "    std = df_DMSO.select(float_columns).std()\n",
    "    # replace 0 with 1 (specifically not clip) to avoid div by zero\n",
    "    std = std.select([pl.col(c).map_dict({0: 1}, default=pl.col(c)) for c in std.columns])\n",
    "\n",
    "    for i,col in enumerate(std.columns):\n",
    "        if std[col].is_null().any():\n",
    "            raise RuntimeError(f\"some std value in column {col,i} is nan?!\")\n",
    "        if std[col].is_infinite().any():\n",
    "            raise RuntimeError(f\"some std value in column {col,i} is infinite?!\")\n",
    "        if (std[col]==0).any():\n",
    "            raise RuntimeError(f\"unexpected 0 in column {col}\")\n",
    "\n",
    "    print_time(\"calculated DMSO distribution\")\n",
    "\n",
    "    df_standardized = df.with_columns([(pl.col(c) - mu[c]) / (std[c]+0.01) for c in mu.columns])\n",
    "    found_nan=False\n",
    "    # checking nans:\n",
    "    for i,col in enumerate(mu.columns):\n",
    "        if df_standardized[col].is_null().any():\n",
    "            found_nan=True\n",
    "            print(f\"some value in column {col,i} is nan\")\n",
    "\n",
    "    if found_nan:\n",
    "        raise RuntimeError(\"found nan\")\n",
    "    df_mean=df.with_columns([df_standardized[c] for c in df_standardized.columns])\n",
    "\n",
    "    ScOut = f'{OutputDir}/SingleCell/'\n",
    "    if not os.path.exists(ScOut): \n",
    "        os.makedirs(ScOut)\n",
    "    df_mean.write_parquet(f'{ScOut}/{df.select(pl.col(\"Metadata_cmpd_cell_line\")).unique().item()}_mean.parquet')\n",
    "\n",
    "    # # group/combine by well\n",
    "    # df_agg=df.drop(columns=['Metadata_Site'])\n",
    "    df_agg = df_mean\n",
    "    df_float_columns=set(list(df_agg.select(float_columns).columns))\n",
    "    group_by_columns=['Metadata_PlateWell', 'Metadata_Barcode','Metadata_Well']\n",
    "    other_columns=set(list(df_agg.columns))-df_float_columns-set(group_by_columns)\n",
    "    # # group by mean for all float features, and group by first for all non-float columns (indices and string metadata)\n",
    "    group_by_aggregates=[\n",
    "        *[pl.mean(x) for x in list(df_float_columns)],\n",
    "        *[pl.first(x) for x in list(other_columns)]\n",
    "    ]\n",
    "    df_agg_mean=df_agg.group_by(group_by_columns).agg(group_by_aggregates)\n",
    "    MeanOut = f'{OutputDir}/MeanCell/'\n",
    "    if not os.path.exists(MeanOut): \n",
    "        os.makedirs(MeanOut)\n",
    "    df_agg_mean.write_parquet(f'{MeanOut}/{df.select(pl.col(\"Metadata_cmpd_cell_line\")).unique().item()}.parquet')\n",
    "    print_time(\"binned mean data per well\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Calculating based on Medians:\n",
    "    median = df_DMSO.select(float_columns).median()\n",
    "\n",
    "    # Check for null or infinite medians and raise errors if found\n",
    "    for col in median.columns:\n",
    "        if median[col].is_null().any():\n",
    "            raise RuntimeError(f\"some median value in column {col} is nan?!\")\n",
    "        if median[col].is_infinite().any():\n",
    "            raise RuntimeError(f\"some median value in column {col} is infinite?!\")\n",
    "\n",
    "    # mad = df_DMSO.select([(pl.col(c) - pl.col(c).median()).abs().alias(c) for c in float_columns])\n",
    "    mad = pl.concat([df.select((pl.col(c)-pl.col(c).median()).abs().median()) for c in df.select(float_columns).columns], how='horizontal')\n",
    "    # mad = df_DMSO.select([pl.abs(pl.col(c) - median[c]).median().alias(c) for c in float_columns])\n",
    "\n",
    "\n",
    "    # Ensure MAD values are not zero to avoid division by zero\n",
    "    # Here we replace 0 with a small value (e.g., 0.01) instead of 1 to maintain the scale of MAD\n",
    "    # mad = mad.select([pl.when(pl.col(c) == 0).then(0.01).otherwise(pl.col(c)).alias(c) for c in mad.columns])\n",
    "    mad = mad.select([pl.col(c).map_dict({0: 0.01}, default=pl.col(c)) for c in mad.columns])\n",
    "\n",
    "    # Check for null, infinite, or unexpected zero values in MAD and raise errors if found\n",
    "    for i, col in enumerate(mad.columns):\n",
    "        if mad[col].is_null().any():\n",
    "            raise RuntimeError(f\"some MAD value in column {col,i} is nan?!\")\n",
    "        if mad[col].is_infinite().any():\n",
    "            raise RuntimeError(f\"some MAD value in column {col,i} is infinite?!\")\n",
    "        if (mad[col] == 0).any():\n",
    "            raise RuntimeError(f\"unexpected 0 in column {col}\")\n",
    "\n",
    "    print_time(\"calculated DMSO distribution\")\n",
    "    df_standardized = df.with_columns([(pl.col(c) - median[c]) / (mad[c]) for c in median.columns])\n",
    "    # CHecking for nans:\n",
    "    for i,col in enumerate(median.columns):\n",
    "        if df_standardized[col].is_null().any():\n",
    "            found_nan=True\n",
    "            print(f\"some value in column {col,i} is nan\")\n",
    "\n",
    "    if found_nan:\n",
    "        raise RuntimeError(\"found nan\")\n",
    "    df_mad=df.with_columns([df_standardized[c] for c in df_standardized.columns])    \n",
    "\n",
    "    print_time(\"MAD normalized to DMSO distribution\")\n",
    "\n",
    "    # counts objects identified by segmentation, i.e. should be cells\n",
    "    num_objects = df_mad.shape[0]\n",
    "\n",
    "    fraction_objects_containing_nan=1-(num_rows_after_nan_trim/num_rows_before_nan_trim)\n",
    "    print_time(f\"num objects (cells) {num_objects} ({(fraction_objects_containing_nan*100):.2f}% were NaN)\")\n",
    "\n",
    "    # Save Single Cell Parquets to outputs\n",
    "    ScOut = f'{OutputDir}/SingleCell/'\n",
    "    if not os.path.exists(ScOut): \n",
    "        os.makedirs(ScOut)\n",
    "    df_mad.write_parquet(f'{ScOut}/{df.select(pl.col(\"Metadata_cmpd_cell_line\")).unique().item()}_mad.parquet')\n",
    "\n",
    "\n",
    "    df_agg = df_mad\n",
    "    df_float_columns=set(list(df_agg.select(float_columns).columns))\n",
    "    group_by_columns=['Metadata_Barcode','Metadata_Well']\n",
    "    other_columns=set(list(df_agg.columns))-df_float_columns-set(group_by_columns)\n",
    "    group_by_aggregates=[\n",
    "        *[pl.median(x) for x in list(df_float_columns)],\n",
    "        *[pl.first(x) for x in list(other_columns)]\n",
    "    ]\n",
    "    df_agg_median=df_agg.group_by(group_by_columns).agg(group_by_aggregates)\n",
    "    MedianOut = f'{OutputDir}/MedianCell/'\n",
    "    if not os.path.exists(MedianOut): \n",
    "        os.makedirs(MedianOut)\n",
    "    df_agg_median.write_parquet(f'{MedianOut}/{df.select(pl.col(\"Metadata_cmpd_cell_line\")).unique().item()}.parquet')\n",
    "    print_time(\"binned median data per well\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ObjectList = ['featICF_nuclei', 'featICF_cells', 'featICF_cytoplasm']\n",
    "\n",
    "def data_processing(metaEx, cl, ObjectList, rootDir, sourceDir, OutputDir, sliceLim=7):\n",
    "    #cl in metaEx.select(pl.col(['cell_line'])).unique().to_series().to_list():\n",
    "    #ObjectList = ['featICF_nuclei', 'featICF_cells', 'featICF_cytoplasm']\n",
    "    print('lala')\n",
    "    df = pl.DataFrame()\n",
    "    for BaseDir in dirlist:\n",
    "        mdf_op = metaEx.filter(pl.col('barcode') == BaseDir.split('/')[-1])\n",
    "        image_id = mdf_op.select(pl.col('image_id')).unique().to_series().to_list()[-1]\n",
    "        cp_id = mdf_op.select(pl.col('cp_id')).unique().to_series().to_list()[-1]\n",
    "        print(f'{BaseDir}/{image_id}/{cp_id}')\n",
    "        BaseDir = f'{BaseDir}/{image_id}/{cp_id}'\n",
    "\n",
    "\n",
    "        # nuclei = pl.read_parquet(BaseDir+f'/{ObjectList[0]}.parquet').add_prefix('Nuclei_').reset_index()\n",
    "        # cytoplasm = pl.read_parquet(BaseDir+f'/{ObjectList[1]}.parquet').add_prefix('Cytoplasm_').reset_index()\n",
    "        # cells = pl.read_parquet(BaseDir+f'/{ObjectList[2]}.parquet').add_prefix('Cells_').reset_index()\n",
    "        # f_df=pl.read_parquet(f)\n",
    "        # f_df=f_df.rename({x:f'{feature_set_name}_{x}' for x in f_df.columns})\n",
    "        \n",
    "\n",
    "        nuclei = pl.read_parquet(BaseDir+f'/{ObjectList[0]}.parquet')\n",
    "        nuclei=nuclei.rename({x:f'Nuclei_{x}' for x in nuclei.columns})\n",
    "        cytoplasm = pl.read_parquet(BaseDir+f'/{ObjectList[1]}.parquet')\n",
    "        cytoplasm=cytoplasm.rename({x:f'Cytoplasm_{x}' for x in cytoplasm.columns})\n",
    "        cells = pl.read_parquet(BaseDir+f'/{ObjectList[2]}.parquet')\n",
    "        cells=cells.rename({x:f'Cells_{x}' for x in cells.columns})\n",
    "        # step 1: Take the mean values of 'multiple nuclei' belonging to one cell\n",
    "\n",
    "        nuclei = nuclei.group_by([\n",
    "            \"Nuclei_Metadata_Barcode\",\"Nuclei_Metadata_Well\",\n",
    "            \"Nuclei_Parent_cells\", 'Nuclei_Metadata_Site'\n",
    "        ]).mean()\n",
    "\n",
    "        df_one = cytoplasm.join(nuclei,\n",
    "                    how='left', \n",
    "                    right_on=['Nuclei_Metadata_Well', 'Nuclei_Metadata_Site', 'Nuclei_Parent_cells', 'Nuclei_Metadata_Barcode'],\n",
    "                    left_on = ['Cytoplasm_Metadata_Well','Cytoplasm_Metadata_Site', 'Cytoplasm_ObjectNumber', 'Cytoplasm_Metadata_Barcode'])\n",
    "                    \n",
    "        df_one = df_one.join(cells, how='left', \n",
    "                        left_on=['Cytoplasm_Metadata_Well','Cytoplasm_Metadata_Site','Cytoplasm_ObjectNumber', 'Cytoplasm_Metadata_Barcode'],\n",
    "                        right_on = ['Cells_Metadata_Well','Cells_Metadata_Site',\"Cells_ObjectNumber\", 'Cells_Metadata_Barcode'])\n",
    "\n",
    "        # print_time(\"initial merging\")\n",
    "        print('part1')\n",
    "\n",
    "        # deduplicate barcode/well/site - renamed cytoplasm_Metadata* to Metadata* and removes nuclei_* etc\n",
    "        unique_metadata_feature_names=['Metadata_Barcode','Metadata_Well','Metadata_Site']\n",
    "        df_one=df_one.rename({f'Cytoplasm_{suffix}':suffix for suffix in unique_metadata_feature_names})\n",
    "        # df = df.filter(pl.col(''))       \n",
    "        # for some reason, the site is parsed as float, even though it really should be an int\n",
    "        if df_one['Metadata_Site'].dtype in [np.dtype('float32'), np.dtype('float64')]:\n",
    "            # sometimes, for some reason, site indices are inf/nan\n",
    "            site_is_nan_mask=np.isnan(df_one['Metadata_Site'])\n",
    "            site_is_inf_mask=np.isinf(df_one['Metadata_Site'])\n",
    "            \n",
    "            try:\n",
    "                num_sites_nan=np.sum(site_is_nan_mask)\n",
    "                num_sites_inf=np.sum(site_is_inf_mask)\n",
    "                assert num_sites_nan==0, f\"found nan site values (n = {num_sites_nan})\"\n",
    "                assert num_sites_inf==0, f\"found inf site values (n = {num_sites_inf})\"\n",
    "            except AssertionError as e:\n",
    "                print(f\"info - this issue was automatically circumvented in the code : {e}\")\n",
    "                df_one=df_one[~(site_is_inf_mask|site_is_nan_mask)]\n",
    "                \n",
    "            num_metadata_site_entries_nonint=np.sum(np.abs(df_one['Metadata_Site']%1.0)>1e-6)\n",
    "            assert num_metadata_site_entries_nonint==0, f\"ERROR : {num_metadata_site_entries_nonint} imaging sites don't have integer indices. that should not be the case, and likely indicates a bug.\"\n",
    "            \n",
    "            #Should use np.round, no? TODO ask patrick. Truncation Errors are annoying.\n",
    "            df_one['Metadata_Site'] = df_one['Metadata_Site'].astype(np.dtype('int32'))\n",
    "        \n",
    "        #Adding Compound Metadata to each row\n",
    "        df_one = df_one.join(mdf_op.rename({x:f\"Metadata_cmpd_{x}\" for x in mdf_op.columns}),left_on='Metadata_Well',right_on='Metadata_cmpd_well_id')\n",
    "        df_one = df_one.filter(pl.col('Metadata_Site')<sliceLim)\n",
    "        df = pl.concat([df, df_one])\n",
    "        plate_name = f'processed metadata for {BaseDir.split(\"/\")[-1]}'\n",
    "        print(plate_name)\n",
    "    ###Here should be workable to unify by cell line.\n",
    "    df = df.with_columns((pl.col(\"Metadata_Barcode\") + \"_\" + pl.col(\"Metadata_Well\")).alias(\"Metadata_PlateWell\"))\n",
    "    df = df.filter(pl.col('Metadata_cmpd_cell_line')==cl)\n",
    "    ###End\n",
    "    # drop all rows that contain nan\n",
    "    num_rows_before_nan_trim = df.shape[0]\n",
    "    for col in df.select([pl.col(pl.Float32),pl.col(pl.Float64)]).columns:\n",
    "        before_drop=df.shape[0]\n",
    "        df=df.filter(pl.col(col).is_not_null())\n",
    "        after_drop=df.shape[0]\n",
    "\n",
    "        #num_values_dropped=before_drop-after_drop\n",
    "        #if num_values_dropped>0:\n",
    "        #    print(f\"dropped {num_values_dropped} rows due to NaNs in column {col}\")\n",
    "\n",
    "    num_rows_after_nan_trim = df.shape[0]\n",
    "\n",
    "    print_time(\"dropped NaNs\")\n",
    "\n",
    "    # Clip outliers\n",
    "    if use_clipping:\n",
    "        float_cols = [c for c_name,c_dtype in zip(df.columns,df.dtypes) if \"float\" in str(c_dtype)]\n",
    "        lower_quantile = df.select(float_cols).quantile(0.01)\n",
    "        upper_quantile = df.select(float_cols).quantile(0.99)\n",
    "        print(\"calced quantiles\")\n",
    "\n",
    "        for col in float_cols:\n",
    "            df = df.with_column(\n",
    "                pl.col(col).clip(lower=lower_quantile[col],upper=upper_quantile[col])\n",
    "            )\n",
    "            \n",
    "        print(\"clipped\")\n",
    "    # print(df.head())\n",
    "    # for some reason, DMSO is used as batch id for cells that are not treated with a drug\n",
    "    df_DMSO=df.filter(pl.col('Metadata_cmpd_cmpdname')=='dmso')\n",
    "    assert df_DMSO.shape[0]>0, \"did not find any wells 'treated' with DMSO\"\n",
    "\n",
    "    # Running Means here:\n",
    "    mu = df_DMSO.select(float_columns).mean()\n",
    "    for col in mu.columns:\n",
    "        if mu[col].is_null().any():\n",
    "            raise RuntimeError(f\"some mean value in column {col,i} is nan?!\")\n",
    "        if mu[col].is_infinite().any():\n",
    "            raise RuntimeError(f\"some mean value in column {col,i} is infinite?!\")\n",
    "                \n",
    "    std = df_DMSO.select(float_columns).std()\n",
    "    # replace 0 with 1 (specifically not clip) to avoid div by zero\n",
    "    std = std.select([pl.col(c).map_dict({0: 1}, default=pl.col(c)) for c in std.columns])\n",
    "\n",
    "    for i,col in enumerate(std.columns):\n",
    "        if std[col].is_null().any():\n",
    "            raise RuntimeError(f\"some std value in column {col,i} is nan?!\")\n",
    "        if std[col].is_infinite().any():\n",
    "            raise RuntimeError(f\"some std value in column {col,i} is infinite?!\")\n",
    "        if (std[col]==0).any():\n",
    "            raise RuntimeError(f\"unexpected 0 in column {col}\")\n",
    "\n",
    "    print_time(\"calculated DMSO distribution\")\n",
    "\n",
    "    df_standardized = df.with_columns([(pl.col(c) - mu[c]) / (std[c]+0.01) for c in mu.columns])\n",
    "    found_nan=False\n",
    "    # checking nans:\n",
    "    for i,col in enumerate(mu.columns):\n",
    "        if df_standardized[col].is_null().any():\n",
    "            found_nan=True\n",
    "            print(f\"some value in column {col,i} is nan\")\n",
    "\n",
    "    if found_nan:\n",
    "        raise RuntimeError(\"found nan\")\n",
    "    df_mean=df.with_columns([df_standardized[c] for c in df_standardized.columns])\n",
    "\n",
    "    ScOut = f'{OutputDir}/SingleCell/'\n",
    "    if not os.path.exists(ScOut): \n",
    "        os.makedirs(ScOut)\n",
    "    df_mean.write_parquet(f'{ScOut}/{df.select(pl.col(\"Metadata_cmpd_cell_line\")).unique().item()}_mean.parquet')\n",
    "\n",
    "    # # group/combine by well\n",
    "    # df_agg=df.drop(columns=['Metadata_Site'])\n",
    "    df_agg = df_mean\n",
    "    df_float_columns=set(list(df_agg.select(float_columns).columns))\n",
    "    group_by_columns=['Metadata_PlateWell', 'Metadata_Barcode','Metadata_Well']\n",
    "    other_columns=set(list(df_agg.columns))-df_float_columns-set(group_by_columns)\n",
    "    # # group by mean for all float features, and group by first for all non-float columns (indices and string metadata)\n",
    "    group_by_aggregates=[\n",
    "        *[pl.mean(x) for x in list(df_float_columns)],\n",
    "        *[pl.first(x) for x in list(other_columns)]\n",
    "    ]\n",
    "    df_agg_mean=df_agg.group_by(group_by_columns).agg(group_by_aggregates)\n",
    "    MeanOut = f'{OutputDir}/MeanCell/'\n",
    "    if not os.path.exists(MeanOut): \n",
    "        os.makedirs(MeanOut)\n",
    "    df_agg_mean.write_parquet(f'{MeanOut}/{df.select(pl.col(\"Metadata_cmpd_cell_line\")).unique().item()}.parquet')\n",
    "    print_time(\"binned mean data per well\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Calculating based on Medians:\n",
    "    median = df_DMSO.select(float_columns).median()\n",
    "\n",
    "    # Check for null or infinite medians and raise errors if found\n",
    "    for col in median.columns:\n",
    "        if median[col].is_null().any():\n",
    "            raise RuntimeError(f\"some median value in column {col} is nan?!\")\n",
    "        if median[col].is_infinite().any():\n",
    "            raise RuntimeError(f\"some median value in column {col} is infinite?!\")\n",
    "\n",
    "    # mad = df_DMSO.select([(pl.col(c) - pl.col(c).median()).abs().alias(c) for c in float_columns])\n",
    "    mad = pl.concat([df.select((pl.col(c)-pl.col(c).median()).abs().median()) for c in df.select(float_columns).columns], how='horizontal')\n",
    "    # mad = df_DMSO.select([pl.abs(pl.col(c) - median[c]).median().alias(c) for c in float_columns])\n",
    "\n",
    "\n",
    "    # Ensure MAD values are not zero to avoid division by zero\n",
    "    # Here we replace 0 with a small value (e.g., 0.01) instead of 1 to maintain the scale of MAD\n",
    "    # mad = mad.select([pl.when(pl.col(c) == 0).then(0.01).otherwise(pl.col(c)).alias(c) for c in mad.columns])\n",
    "    mad = mad.select([pl.col(c).map_dict({0: 0.01}, default=pl.col(c)) for c in mad.columns])\n",
    "\n",
    "    # Check for null, infinite, or unexpected zero values in MAD and raise errors if found\n",
    "    for i, col in enumerate(mad.columns):\n",
    "        if mad[col].is_null().any():\n",
    "            raise RuntimeError(f\"some MAD value in column {col,i} is nan?!\")\n",
    "        if mad[col].is_infinite().any():\n",
    "            raise RuntimeError(f\"some MAD value in column {col,i} is infinite?!\")\n",
    "        if (mad[col] == 0).any():\n",
    "            raise RuntimeError(f\"unexpected 0 in column {col}\")\n",
    "\n",
    "    print_time(\"calculated DMSO distribution\")\n",
    "    df_standardized = df.with_columns([(pl.col(c) - median[c]) / (mad[c]) for c in median.columns])\n",
    "    # CHecking for nans:\n",
    "    for i,col in enumerate(median.columns):\n",
    "        if df_standardized[col].is_null().any():\n",
    "            found_nan=True\n",
    "            print(f\"some value in column {col,i} is nan\")\n",
    "\n",
    "    if found_nan:\n",
    "        raise RuntimeError(\"found nan\")\n",
    "    df_mad=df.with_columns([df_standardized[c] for c in df_standardized.columns])    \n",
    "\n",
    "    print_time(\"MAD normalized to DMSO distribution\")\n",
    "\n",
    "    # counts objects identified by segmentation, i.e. should be cells\n",
    "    num_objects = df_mad.shape[0]\n",
    "\n",
    "    fraction_objects_containing_nan=1-(num_rows_after_nan_trim/num_rows_before_nan_trim)\n",
    "    print_time(f\"num objects (cells) {num_objects} ({(fraction_objects_containing_nan*100):.2f}% were NaN)\")\n",
    "\n",
    "    # Save Single Cell Parquets to outputs\n",
    "    ScOut = f'{OutputDir}/SingleCell/'\n",
    "    if not os.path.exists(ScOut): \n",
    "        os.makedirs(ScOut)\n",
    "    df_mad.write_parquet(f'{ScOut}/{df.select(pl.col(\"Metadata_cmpd_cell_line\")).unique().item()}_mad.parquet')\n",
    "\n",
    "\n",
    "    df_agg = df_mad\n",
    "    df_float_columns=set(list(df_agg.select(float_columns).columns))\n",
    "    group_by_columns=['Metadata_Barcode','Metadata_Well']\n",
    "    other_columns=set(list(df_agg.columns))-df_float_columns-set(group_by_columns)\n",
    "    group_by_aggregates=[\n",
    "        *[pl.median(x) for x in list(df_float_columns)],\n",
    "        *[pl.first(x) for x in list(other_columns)]\n",
    "    ]\n",
    "    df_agg_median=df_agg.group_by(group_by_columns).agg(group_by_aggregates)\n",
    "    MedianOut = f'{OutputDir}/MedianCell/'\n",
    "    if not os.path.exists(MedianOut): \n",
    "        os.makedirs(MedianOut)\n",
    "    df_agg_median.write_parquet(f'{MedianOut}/{df.select(pl.col(\"Metadata_cmpd_cell_line\")).unique().item()}.parquet')\n",
    "    print_time(\"binned median data per well\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HT29', 'HCT116']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metaEx.select(pl.col(['cell_line'])).unique().to_series().to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ObjectList = ['featICF_nuclei', 'featICF_cells', 'featICF_cytoplasm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lala\n",
      "/share/data/cellprofiler/automation/results/PB000138/4188/5547\n",
      "part1\n",
      "processed metadata for 5547\n",
      "/share/data/cellprofiler/automation/results/PB000142/4191/5574\n",
      "part1\n",
      "processed metadata for 5574\n",
      "/share/data/cellprofiler/automation/results/PB000141/4187/5546\n",
      "part1\n",
      "processed metadata for 5546\n",
      "/share/data/cellprofiler/automation/results/PB000140/4189/5573\n",
      "part1\n",
      "processed metadata for 5573\n",
      "/share/data/cellprofiler/automation/results/PB000137/4185/5532\n",
      "part1\n",
      "processed metadata for 5532\n",
      "/share/data/cellprofiler/automation/results/PB000139/4186/5533\n",
      "part1\n",
      "processed metadata for 5533\n",
      "2024-08-09 15:47:21 dropped NaNs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1411136/1475054329.py:126: DeprecationWarning: `map_dict` is deprecated. It has been renamed to `replace`. The default behavior has changed to keep any values not present in the mapping unchanged. Pass `default=None` to keep existing behavior.\n",
      "  std = std.select([pl.col(c).map_dict({0: 1}, default=pl.col(c)) for c in std.columns])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-09 15:47:22 calculated DMSO distribution\n",
      "2024-08-09 15:47:55 binned mean data per well\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1411136/1475054329.py:194: DeprecationWarning: `map_dict` is deprecated. It has been renamed to `replace`. The default behavior has changed to keep any values not present in the mapping unchanged. Pass `default=None` to keep existing behavior.\n",
      "  mad = mad.select([pl.col(c).map_dict({0: 0.01}, default=pl.col(c)) for c in mad.columns])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-09 15:48:10 calculated DMSO distribution\n",
      "2024-08-09 15:48:13 MAD normalized to DMSO distribution\n",
      "2024-08-09 15:48:13 num objects (cells) 370680 (0.02% were NaN)\n",
      "2024-08-09 15:48:47 binned median data per well\n"
     ]
    }
   ],
   "source": [
    "data_processing(metaEx, 'HCT116', ObjectList, rootDir, sourceDir, OutputDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lala\n",
      "/share/data/cellprofiler/automation/results/PB000138/4188/5547\n",
      "part1\n",
      "processed metadata for 5547\n",
      "/share/data/cellprofiler/automation/results/PB000142/4191/5574\n",
      "part1\n",
      "processed metadata for 5574\n",
      "/share/data/cellprofiler/automation/results/PB000141/4187/5546\n",
      "part1\n",
      "processed metadata for 5546\n",
      "/share/data/cellprofiler/automation/results/PB000140/4189/5573\n",
      "part1\n",
      "processed metadata for 5573\n",
      "/share/data/cellprofiler/automation/results/PB000137/4185/5532\n",
      "part1\n",
      "processed metadata for 5532\n",
      "/share/data/cellprofiler/automation/results/PB000139/4186/5533\n",
      "part1\n",
      "processed metadata for 5533\n",
      "2024-08-09 15:52:57 dropped NaNs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1411136/1475054329.py:126: DeprecationWarning: `map_dict` is deprecated. It has been renamed to `replace`. The default behavior has changed to keep any values not present in the mapping unchanged. Pass `default=None` to keep existing behavior.\n",
      "  std = std.select([pl.col(c).map_dict({0: 1}, default=pl.col(c)) for c in std.columns])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-09 15:52:58 calculated DMSO distribution\n",
      "2024-08-09 15:53:16 binned mean data per well\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1411136/1475054329.py:194: DeprecationWarning: `map_dict` is deprecated. It has been renamed to `replace`. The default behavior has changed to keep any values not present in the mapping unchanged. Pass `default=None` to keep existing behavior.\n",
      "  mad = mad.select([pl.col(c).map_dict({0: 0.01}, default=pl.col(c)) for c in mad.columns])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-09 15:53:25 calculated DMSO distribution\n",
      "2024-08-09 15:53:26 MAD normalized to DMSO distribution\n",
      "2024-08-09 15:53:26 num objects (cells) 207924 (0.03% were NaN)\n",
      "2024-08-09 15:53:46 binned median data per well\n"
     ]
    }
   ],
   "source": [
    "data_processing(metaEx, 'HT29', ObjectList, rootDir, sourceDir, OutputDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.filter(pl.col('Metadata_Site')<7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.select(pl.col('Metadata_Site')).to_series().unique().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current date and time : \n",
      "2024-08-09 15:12:05\n"
     ]
    }
   ],
   "source": [
    "now = datetime.datetime.now()\n",
    "print ('Current date and time : ')\n",
    "print (now.strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_meanall.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toNpy = df_scall.loc[:,~df_scall.columns.str.contains('Metadata_')]\n",
    "# toNpy.reset_index(inplace=True, drop=True)\n",
    "# toNpy = toNpy.copy()\n",
    "# dataNpy = toNpy.to_numpy()\n",
    "# np.isnan(dataNpy).any()\n",
    "# colnames = toNpy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
